{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!nvidia-smi","metadata":{"id":"gqHnaptr-kuA","outputId":"313aec45-b8cc-4aea-e417-9c27546fb30f","trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Wed Apr 21 03:15:00 2021       \n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 450.51.06    Driver Version: 450.51.06    CUDA Version: 11.0     |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|                               |                      |               MIG M. |\n|===============================+======================+======================|\n|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n| N/A   36C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n                                                                               \n+-----------------------------------------------------------------------------+\n| Processes:                                                                  |\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n|        ID   ID                                                   Usage      |\n|=============================================================================|\n|  No running processes found                                                 |\n+-----------------------------------------------------------------------------+\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nprint(os.listdir(\"../input/drunstratified/content/\"))","metadata":{"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"['non_stratified_dr']\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport os\nimport cv2\nfrom PIL import Image\nimport copy\nimport time\nimport pickle\n\nimport torch\nfrom torchvision import datasets, models, transforms\nfrom torchvision.datasets import ImageFolder\nfrom torch.utils.data import DataLoader, Dataset, TensorDataset, Subset, WeightedRandomSampler\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler","metadata":{"id":"9oGJ2hstm39V","trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# from google.colab import drive\n\n# drive.mount('/gdrive')\n# %cd /gdrive","metadata":{"id":"OwQ_7hZ0nE3b","trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# from google.colab import files\n\n# files.upload()","metadata":{"id":"Nyw3t2gJ-958","outputId":"c310e066-552f-46a6-87ac-8451e279ae40","trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# !ls -lha kaggle.json\n# !pip install -q kaggle\n# !mkdir -p ~/.kaggle\n# !cp kaggle.json ~/.kaggle/\n# !chmod 600 /root/.kaggle/kaggle.json","metadata":{"id":"LbSZYdtI6-ai","outputId":"0ec4aac3-4a5c-42c4-b947-6ceedec9f519","trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# !kaggle datasets download ayushsubedi/drunstratified","metadata":{"id":"sAcmadkx7Ivs","outputId":"2c35c560-db3b-436f-faf4-c2ebf97f646b","trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# !unzip -qq /content/drunstratified.zip","metadata":{"id":"k29e1Tdv8hQO","trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Top level data directory. Here we assume the format of the directory conforms\n#   to the ImageFolder structure\ndata_dir = '../input/drunstratified/content/non_stratified_dr'\n\n# Models to choose from [resnet, alexnet, vgg, squeezenet, densenet, inception]\nmodel_name = \"inception\"\n# inception\ninput_size = 299\n\n# Number of classes in the dataset\nnum_classes = 5\n\n# Batch size for training (change depending on how much memory you have)\nbatch_size = 64\n\n# Number of epochs to train for\nnum_epochs = 5\n\n# Flag for feature extracting. When False, we finetune the whole model,\n#   when True we only update the reshaped layer params\nfeature_extract = False\n\nnum_workers = 2\n\ntrain_size = 0.70\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","metadata":{"id":"u899MaWr-ZF0","trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"class ben_color(object):\n   \n   #     Parameters\n   #    ----------\n   #   img: 2D numpy array\n   #         The original image with format of (h, w, c)\n    \n    def __call__(self, img, sigmaX=10):\n        \"\"\"\n        :param img: PIL): Image \n\n        :return: Normalized image\n        \"\"\"\n\n        img = np.asarray(img)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        img = self.crop_image_from_gray(img)\n        img = cv2.resize(img, (input_size, input_size))\n        img = cv2.addWeighted (img, 4, cv2.GaussianBlur(img, (0,0), sigmaX), -4, 128)\n        return Image.fromarray(img)\n\n    def crop_image_from_gray(self, img, tol=7):\n        if img.ndim ==2:\n            mask = img>tol\n            return img[np.ix_(mask.any(1),mask.any(0))]\n        elif img.ndim==3:\n            gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n            mask = gray_img>tol\n            \n            check_shape = img[:,:,0][np.ix_(mask.any(1),mask.any(0))].shape[0]\n            if (check_shape == 0):\n                return img \n            else:\n                img1=img[:,:,0][np.ix_(mask.any(1),mask.any(0))]\n                img2=img[:,:,1][np.ix_(mask.any(1),mask.any(0))]\n                img3=img[:,:,2][np.ix_(mask.any(1),mask.any(0))]\n                img = np.stack([img1,img2,img3],axis=-1)\n            return img\n\n    def __repr__(self):\n        return self.__class__.__name__+'()'","metadata":{"id":"EQZneeOThiDX","trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Todos: shuffle in validation set\n# add more augmentations  \n\n\ntrain_transform = transforms.Compose([\n        ben_color(),\n        transforms.RandomRotation(degrees=(0, 360)),\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomVerticalFlip(),\n        # transforms.Resize((input_size, input_size)),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n\n\nvalid_transform = transforms.Compose([\n        ben_color(),\n        transforms.Resize((input_size, input_size)),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n\n\nclass DR(Dataset):\n    def __init__(self, dataset, transform=None):\n        self.dataset = dataset\n        self.transform = transform\n\n    def __getitem__(self, index):\n        if self.transform:\n            x = self.transform(dataset[index][0])\n        else:\n            x = dataset[index][0]\n        y = dataset[index][1]\n        return x, y\n    \n    def __len__(self):\n        return len(dataset)\n    \n\ndataset = ImageFolder(data_dir)\n\ntraindataset = DR(dataset, train_transform)\nvaldataset = DR(dataset, valid_transform)\ntestdataset = DR(dataset, valid_transform)\n\n# Create the index splits for training, validation and test\n\nnum_train = len(dataset)\nindices = list(range(num_train))\nsplit = int(np.floor(train_size * num_train))\nsplit2 = int(np.floor((train_size+(1-train_size)/2) * num_train))\nnp.random.shuffle(indices)\ntrain_idx, valid_idx, test_idx = indices[:split], indices[split:split2], indices[split2:]\n\ntraindata = Subset(traindataset, indices=train_idx)\nvaldata = Subset(valdataset, indices=valid_idx)\ntestdata = Subset(testdataset, indices=test_idx)\n\n# class_weights = []\n# for root, subdir, files in os.walk(data_dir):\n#   if len(files)>0:\n#     class_weights.append(1/len(files))\n\n# sample_weights = [0] * len(traindata)\n\n# for idx, (data, label) in enumerate(traindata):\n#   class_weight = class_weights[label]\n#   sample_weights[idx] = class_weight\n\n# with open('/content/drive/MyDrive/weights.pkl', 'rb') as f:\n#     sample_weights = pickle.load(f)\n\n\n\n# sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)\n\ntrainLoader = torch.utils.data.DataLoader(traindata, batch_size=batch_size, \n                                          num_workers=num_workers, drop_last=True)\nvalLoader = torch.utils.data.DataLoader(valdata, batch_size=batch_size, \n                                          num_workers=num_workers, drop_last=True)\ntestLoader = torch.utils.data.DataLoader(testdata, batch_size=batch_size,\n                                          num_workers=num_workers, drop_last=True)\ndataloaders = {'train': trainLoader, 'val': valLoader, 'test': testLoader}","metadata":{"id":"3jj74frLDrZd","trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False):\n    since = time.time()\n\n    val_acc_history = []\n\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n\n    for epoch in range(num_epochs):\n        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n        print('-' * 10)\n\n        # Each epoch has a training and validation phase\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                model.train()  # Set model to training mode\n            else:\n                model.eval()   # Set model to evaluate mode\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            # Iterate over data.\n            for inputs, labels in dataloaders[phase]:\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                # zero the parameter gradients\n                optimizer.zero_grad()\n\n                # forward\n                # track history if only in train\n                with torch.set_grad_enabled(phase == 'train'):\n                    # Get model outputs and calculate loss\n                    # Special case for inception because in training it has an auxiliary output. In train\n                    #   mode we calculate the loss by summing the final output and the auxiliary output\n                    #   but in testing we only consider the final output.\n                    if is_inception and phase == 'train':\n                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n                        outputs, aux_outputs = model(inputs)\n                        loss1 = criterion(outputs, labels)\n                        loss2 = criterion(aux_outputs, labels)\n                        loss = loss1 + 0.4*loss2\n                    else:\n                        outputs = model(inputs)\n                        loss = criterion(outputs, labels)\n\n                    _, preds = torch.max(outputs, 1)\n\n                    # backward + optimize only if in training phase\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n                # statistics\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n\n            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n\n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n\n            # deep copy the model\n            if phase == 'val' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n            if phase == 'val':\n                val_acc_history.append(epoch_acc)\n\n        print()\n\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n    print('Best val Acc: {:4f}'.format(best_acc))\n\n    # load best model weights\n    model.load_state_dict(best_model_wts)\n    return model, val_acc_history","metadata":{"id":"tyThMaR4nbLF","trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def set_parameter_requires_grad(model, feature_extracting):\n    if feature_extracting:\n        for param in model.parameters():\n            param.requires_grad = False","metadata":{"id":"75VdlQ8ln1a9","trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n    # Initialize these variables which will be set in this if statement. Each of these\n    #   variables is model specific.\n    model_ft = None\n    input_size = 0\n\n    if model_name == \"resnet\":\n        \"\"\" Resnet18\n        \"\"\"\n        model_ft = models.resnet18(pretrained=use_pretrained)\n        set_parameter_requires_grad(model_ft, feature_extract)\n        num_ftrs = model_ft.fc.in_features\n        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n        input_size = 224\n\n    elif model_name == \"alexnet\":\n        \"\"\" Alexnet\n        \"\"\"\n        model_ft = models.alexnet(pretrained=use_pretrained)\n        set_parameter_requires_grad(model_ft, feature_extract)\n        num_ftrs = model_ft.classifier[6].in_features\n        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n        input_size = 224\n\n    elif model_name == \"vgg\":\n        \"\"\" VGG11_bn\n        \"\"\"\n        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n        set_parameter_requires_grad(model_ft, feature_extract)\n        num_ftrs = model_ft.classifier[6].in_features\n        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n        input_size = 224\n\n    elif model_name == \"squeezenet\":\n        \"\"\" Squeezenet\n        \"\"\"\n        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n        set_parameter_requires_grad(model_ft, feature_extract)\n        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n        model_ft.num_classes = num_classes\n        input_size = 224\n\n    elif model_name == \"densenet\":\n        \"\"\" Densenet\n        \"\"\"\n        model_ft = models.densenet121(pretrained=use_pretrained)\n        set_parameter_requires_grad(model_ft, feature_extract)\n        num_ftrs = model_ft.classifier.in_features\n        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n        input_size = 224\n\n    elif model_name == \"inception\":\n        \"\"\" Inception v3\n        Be careful, expects (299,299) sized images and has auxiliary output\n        \"\"\"\n        model_ft = models.inception_v3(pretrained=use_pretrained)\n        set_parameter_requires_grad(model_ft, feature_extract)\n        # Handle the auxilary net\n        num_ftrs = model_ft.AuxLogits.fc.in_features\n        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n        # Handle the primary net\n        num_ftrs = model_ft.fc.in_features\n        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n        input_size = 299\n\n    else:\n        print(\"Invalid model name, exiting...\")\n        exit()\n\n    return model_ft, input_size\n\n# Initialize the model for this run\nmodel_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\ntorch.save(model_ft, '_2015_non_stratify_weights.h5')\n\n# Print the model we just instantiated\nprint(model_ft)","metadata":{"id":"Y4O8Uqptn8Sb","outputId":"9dbbe717-80c5-4956-8e25-2d65310b9bbb","trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/inception_v3_google-1a9a5a14.pth\" to /root/.cache/torch/hub/checkpoints/inception_v3_google-1a9a5a14.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0.00/104M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"10b0ec54383844dab9fc2d592d696550"}},"metadata":{}},{"name":"stdout","text":"Inception3(\n  (Conv2d_1a_3x3): BasicConv2d(\n    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  )\n  (Conv2d_2a_3x3): BasicConv2d(\n    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  )\n  (Conv2d_2b_3x3): BasicConv2d(\n    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  )\n  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (Conv2d_3b_1x1): BasicConv2d(\n    (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  )\n  (Conv2d_4a_3x3): BasicConv2d(\n    (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  )\n  (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (Mixed_5b): InceptionA(\n    (branch1x1): BasicConv2d(\n      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch5x5_1): BasicConv2d(\n      (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch5x5_2): BasicConv2d(\n      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch3x3dbl_1): BasicConv2d(\n      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch3x3dbl_2): BasicConv2d(\n      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch3x3dbl_3): BasicConv2d(\n      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch_pool): BasicConv2d(\n      (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (Mixed_5c): InceptionA(\n    (branch1x1): BasicConv2d(\n      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch5x5_1): BasicConv2d(\n      (conv): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch5x5_2): BasicConv2d(\n      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch3x3dbl_1): BasicConv2d(\n      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch3x3dbl_2): BasicConv2d(\n      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch3x3dbl_3): BasicConv2d(\n      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch_pool): BasicConv2d(\n      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (Mixed_5d): InceptionA(\n    (branch1x1): BasicConv2d(\n      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch5x5_1): BasicConv2d(\n      (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch5x5_2): BasicConv2d(\n      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch3x3dbl_1): BasicConv2d(\n      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch3x3dbl_2): BasicConv2d(\n      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch3x3dbl_3): BasicConv2d(\n      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch_pool): BasicConv2d(\n      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (Mixed_6a): InceptionB(\n    (branch3x3): BasicConv2d(\n      (conv): Conv2d(288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch3x3dbl_1): BasicConv2d(\n      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch3x3dbl_2): BasicConv2d(\n      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch3x3dbl_3): BasicConv2d(\n      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (Mixed_6b): InceptionC(\n    (branch1x1): BasicConv2d(\n      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch7x7_1): BasicConv2d(\n      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch7x7_2): BasicConv2d(\n      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch7x7_3): BasicConv2d(\n      (conv): Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch7x7dbl_1): BasicConv2d(\n      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch7x7dbl_2): BasicConv2d(\n      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch7x7dbl_3): BasicConv2d(\n      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch7x7dbl_4): BasicConv2d(\n      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch7x7dbl_5): BasicConv2d(\n      (conv): Conv2d(128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch_pool): BasicConv2d(\n      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (Mixed_6c): InceptionC(\n    (branch1x1): BasicConv2d(\n      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch7x7_1): BasicConv2d(\n      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch7x7_2): BasicConv2d(\n      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch7x7_3): BasicConv2d(\n      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch7x7dbl_1): BasicConv2d(\n      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch7x7dbl_2): BasicConv2d(\n      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch7x7dbl_3): BasicConv2d(\n      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch7x7dbl_4): BasicConv2d(\n      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch7x7dbl_5): BasicConv2d(\n      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch_pool): BasicConv2d(\n      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (Mixed_6d): InceptionC(\n    (branch1x1): BasicConv2d(\n      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch7x7_1): BasicConv2d(\n      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch7x7_2): BasicConv2d(\n      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch7x7_3): BasicConv2d(\n      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch7x7dbl_1): BasicConv2d(\n      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch7x7dbl_2): BasicConv2d(\n      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch7x7dbl_3): BasicConv2d(\n      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch7x7dbl_4): BasicConv2d(\n      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch7x7dbl_5): BasicConv2d(\n      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch_pool): BasicConv2d(\n      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (Mixed_6e): InceptionC(\n    (branch1x1): BasicConv2d(\n      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch7x7_1): BasicConv2d(\n      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch7x7_2): BasicConv2d(\n      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch7x7_3): BasicConv2d(\n      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch7x7dbl_1): BasicConv2d(\n      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch7x7dbl_2): BasicConv2d(\n      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch7x7dbl_3): BasicConv2d(\n      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch7x7dbl_4): BasicConv2d(\n      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch7x7dbl_5): BasicConv2d(\n      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch_pool): BasicConv2d(\n      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (AuxLogits): InceptionAux(\n    (conv0): BasicConv2d(\n      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (conv1): BasicConv2d(\n      (conv): Conv2d(128, 768, kernel_size=(5, 5), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (fc): Linear(in_features=768, out_features=5, bias=True)\n  )\n  (Mixed_7a): InceptionD(\n    (branch3x3_1): BasicConv2d(\n      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch3x3_2): BasicConv2d(\n      (conv): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)\n      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch7x7x3_1): BasicConv2d(\n      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch7x7x3_2): BasicConv2d(\n      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch7x7x3_3): BasicConv2d(\n      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch7x7x3_4): BasicConv2d(\n      (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (Mixed_7b): InceptionE(\n    (branch1x1): BasicConv2d(\n      (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch3x3_1): BasicConv2d(\n      (conv): Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch3x3_2a): BasicConv2d(\n      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch3x3_2b): BasicConv2d(\n      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch3x3dbl_1): BasicConv2d(\n      (conv): Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch3x3dbl_2): BasicConv2d(\n      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch3x3dbl_3a): BasicConv2d(\n      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch3x3dbl_3b): BasicConv2d(\n      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch_pool): BasicConv2d(\n      (conv): Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (Mixed_7c): InceptionE(\n    (branch1x1): BasicConv2d(\n      (conv): Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch3x3_1): BasicConv2d(\n      (conv): Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch3x3_2a): BasicConv2d(\n      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch3x3_2b): BasicConv2d(\n      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch3x3dbl_1): BasicConv2d(\n      (conv): Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch3x3dbl_2): BasicConv2d(\n      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch3x3dbl_3a): BasicConv2d(\n      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch3x3dbl_3b): BasicConv2d(\n      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch_pool): BasicConv2d(\n      (conv): Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (dropout): Dropout(p=0.5, inplace=False)\n  (fc): Linear(in_features=2048, out_features=5, bias=True)\n)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Send the model to GPU\nmodel_ft = model_ft.to(device)\n\n# Gather the parameters to be optimized/updated in this run. If we are\n#  finetuning we will be updating all parameters. However, if we are\n#  doing feature extract method, we will only update the parameters\n#  that we have just initialized, i.e. the parameters with requires_grad\n#  is True.\nparams_to_update = model_ft.parameters()\nprint(\"Params to learn:\")\nif feature_extract:\n    params_to_update = []\n    for name,param in model_ft.named_parameters():\n        if param.requires_grad == True:\n            params_to_update.append(param)\n            print(\"\\t\",name)\nelse:\n    for name,param in model_ft.named_parameters():\n        if param.requires_grad == True:\n            print(\"\\t\",name)\n\n# Observe that all parameters are being optimized\noptimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)","metadata":{"id":"I6151ULNdzuq","outputId":"6d98f554-2897-4765-ccb5-dfa9c015ded9","trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Params to learn:\n\t Conv2d_1a_3x3.conv.weight\n\t Conv2d_1a_3x3.bn.weight\n\t Conv2d_1a_3x3.bn.bias\n\t Conv2d_2a_3x3.conv.weight\n\t Conv2d_2a_3x3.bn.weight\n\t Conv2d_2a_3x3.bn.bias\n\t Conv2d_2b_3x3.conv.weight\n\t Conv2d_2b_3x3.bn.weight\n\t Conv2d_2b_3x3.bn.bias\n\t Conv2d_3b_1x1.conv.weight\n\t Conv2d_3b_1x1.bn.weight\n\t Conv2d_3b_1x1.bn.bias\n\t Conv2d_4a_3x3.conv.weight\n\t Conv2d_4a_3x3.bn.weight\n\t Conv2d_4a_3x3.bn.bias\n\t Mixed_5b.branch1x1.conv.weight\n\t Mixed_5b.branch1x1.bn.weight\n\t Mixed_5b.branch1x1.bn.bias\n\t Mixed_5b.branch5x5_1.conv.weight\n\t Mixed_5b.branch5x5_1.bn.weight\n\t Mixed_5b.branch5x5_1.bn.bias\n\t Mixed_5b.branch5x5_2.conv.weight\n\t Mixed_5b.branch5x5_2.bn.weight\n\t Mixed_5b.branch5x5_2.bn.bias\n\t Mixed_5b.branch3x3dbl_1.conv.weight\n\t Mixed_5b.branch3x3dbl_1.bn.weight\n\t Mixed_5b.branch3x3dbl_1.bn.bias\n\t Mixed_5b.branch3x3dbl_2.conv.weight\n\t Mixed_5b.branch3x3dbl_2.bn.weight\n\t Mixed_5b.branch3x3dbl_2.bn.bias\n\t Mixed_5b.branch3x3dbl_3.conv.weight\n\t Mixed_5b.branch3x3dbl_3.bn.weight\n\t Mixed_5b.branch3x3dbl_3.bn.bias\n\t Mixed_5b.branch_pool.conv.weight\n\t Mixed_5b.branch_pool.bn.weight\n\t Mixed_5b.branch_pool.bn.bias\n\t Mixed_5c.branch1x1.conv.weight\n\t Mixed_5c.branch1x1.bn.weight\n\t Mixed_5c.branch1x1.bn.bias\n\t Mixed_5c.branch5x5_1.conv.weight\n\t Mixed_5c.branch5x5_1.bn.weight\n\t Mixed_5c.branch5x5_1.bn.bias\n\t Mixed_5c.branch5x5_2.conv.weight\n\t Mixed_5c.branch5x5_2.bn.weight\n\t Mixed_5c.branch5x5_2.bn.bias\n\t Mixed_5c.branch3x3dbl_1.conv.weight\n\t Mixed_5c.branch3x3dbl_1.bn.weight\n\t Mixed_5c.branch3x3dbl_1.bn.bias\n\t Mixed_5c.branch3x3dbl_2.conv.weight\n\t Mixed_5c.branch3x3dbl_2.bn.weight\n\t Mixed_5c.branch3x3dbl_2.bn.bias\n\t Mixed_5c.branch3x3dbl_3.conv.weight\n\t Mixed_5c.branch3x3dbl_3.bn.weight\n\t Mixed_5c.branch3x3dbl_3.bn.bias\n\t Mixed_5c.branch_pool.conv.weight\n\t Mixed_5c.branch_pool.bn.weight\n\t Mixed_5c.branch_pool.bn.bias\n\t Mixed_5d.branch1x1.conv.weight\n\t Mixed_5d.branch1x1.bn.weight\n\t Mixed_5d.branch1x1.bn.bias\n\t Mixed_5d.branch5x5_1.conv.weight\n\t Mixed_5d.branch5x5_1.bn.weight\n\t Mixed_5d.branch5x5_1.bn.bias\n\t Mixed_5d.branch5x5_2.conv.weight\n\t Mixed_5d.branch5x5_2.bn.weight\n\t Mixed_5d.branch5x5_2.bn.bias\n\t Mixed_5d.branch3x3dbl_1.conv.weight\n\t Mixed_5d.branch3x3dbl_1.bn.weight\n\t Mixed_5d.branch3x3dbl_1.bn.bias\n\t Mixed_5d.branch3x3dbl_2.conv.weight\n\t Mixed_5d.branch3x3dbl_2.bn.weight\n\t Mixed_5d.branch3x3dbl_2.bn.bias\n\t Mixed_5d.branch3x3dbl_3.conv.weight\n\t Mixed_5d.branch3x3dbl_3.bn.weight\n\t Mixed_5d.branch3x3dbl_3.bn.bias\n\t Mixed_5d.branch_pool.conv.weight\n\t Mixed_5d.branch_pool.bn.weight\n\t Mixed_5d.branch_pool.bn.bias\n\t Mixed_6a.branch3x3.conv.weight\n\t Mixed_6a.branch3x3.bn.weight\n\t Mixed_6a.branch3x3.bn.bias\n\t Mixed_6a.branch3x3dbl_1.conv.weight\n\t Mixed_6a.branch3x3dbl_1.bn.weight\n\t Mixed_6a.branch3x3dbl_1.bn.bias\n\t Mixed_6a.branch3x3dbl_2.conv.weight\n\t Mixed_6a.branch3x3dbl_2.bn.weight\n\t Mixed_6a.branch3x3dbl_2.bn.bias\n\t Mixed_6a.branch3x3dbl_3.conv.weight\n\t Mixed_6a.branch3x3dbl_3.bn.weight\n\t Mixed_6a.branch3x3dbl_3.bn.bias\n\t Mixed_6b.branch1x1.conv.weight\n\t Mixed_6b.branch1x1.bn.weight\n\t Mixed_6b.branch1x1.bn.bias\n\t Mixed_6b.branch7x7_1.conv.weight\n\t Mixed_6b.branch7x7_1.bn.weight\n\t Mixed_6b.branch7x7_1.bn.bias\n\t Mixed_6b.branch7x7_2.conv.weight\n\t Mixed_6b.branch7x7_2.bn.weight\n\t Mixed_6b.branch7x7_2.bn.bias\n\t Mixed_6b.branch7x7_3.conv.weight\n\t Mixed_6b.branch7x7_3.bn.weight\n\t Mixed_6b.branch7x7_3.bn.bias\n\t Mixed_6b.branch7x7dbl_1.conv.weight\n\t Mixed_6b.branch7x7dbl_1.bn.weight\n\t Mixed_6b.branch7x7dbl_1.bn.bias\n\t Mixed_6b.branch7x7dbl_2.conv.weight\n\t Mixed_6b.branch7x7dbl_2.bn.weight\n\t Mixed_6b.branch7x7dbl_2.bn.bias\n\t Mixed_6b.branch7x7dbl_3.conv.weight\n\t Mixed_6b.branch7x7dbl_3.bn.weight\n\t Mixed_6b.branch7x7dbl_3.bn.bias\n\t Mixed_6b.branch7x7dbl_4.conv.weight\n\t Mixed_6b.branch7x7dbl_4.bn.weight\n\t Mixed_6b.branch7x7dbl_4.bn.bias\n\t Mixed_6b.branch7x7dbl_5.conv.weight\n\t Mixed_6b.branch7x7dbl_5.bn.weight\n\t Mixed_6b.branch7x7dbl_5.bn.bias\n\t Mixed_6b.branch_pool.conv.weight\n\t Mixed_6b.branch_pool.bn.weight\n\t Mixed_6b.branch_pool.bn.bias\n\t Mixed_6c.branch1x1.conv.weight\n\t Mixed_6c.branch1x1.bn.weight\n\t Mixed_6c.branch1x1.bn.bias\n\t Mixed_6c.branch7x7_1.conv.weight\n\t Mixed_6c.branch7x7_1.bn.weight\n\t Mixed_6c.branch7x7_1.bn.bias\n\t Mixed_6c.branch7x7_2.conv.weight\n\t Mixed_6c.branch7x7_2.bn.weight\n\t Mixed_6c.branch7x7_2.bn.bias\n\t Mixed_6c.branch7x7_3.conv.weight\n\t Mixed_6c.branch7x7_3.bn.weight\n\t Mixed_6c.branch7x7_3.bn.bias\n\t Mixed_6c.branch7x7dbl_1.conv.weight\n\t Mixed_6c.branch7x7dbl_1.bn.weight\n\t Mixed_6c.branch7x7dbl_1.bn.bias\n\t Mixed_6c.branch7x7dbl_2.conv.weight\n\t Mixed_6c.branch7x7dbl_2.bn.weight\n\t Mixed_6c.branch7x7dbl_2.bn.bias\n\t Mixed_6c.branch7x7dbl_3.conv.weight\n\t Mixed_6c.branch7x7dbl_3.bn.weight\n\t Mixed_6c.branch7x7dbl_3.bn.bias\n\t Mixed_6c.branch7x7dbl_4.conv.weight\n\t Mixed_6c.branch7x7dbl_4.bn.weight\n\t Mixed_6c.branch7x7dbl_4.bn.bias\n\t Mixed_6c.branch7x7dbl_5.conv.weight\n\t Mixed_6c.branch7x7dbl_5.bn.weight\n\t Mixed_6c.branch7x7dbl_5.bn.bias\n\t Mixed_6c.branch_pool.conv.weight\n\t Mixed_6c.branch_pool.bn.weight\n\t Mixed_6c.branch_pool.bn.bias\n\t Mixed_6d.branch1x1.conv.weight\n\t Mixed_6d.branch1x1.bn.weight\n\t Mixed_6d.branch1x1.bn.bias\n\t Mixed_6d.branch7x7_1.conv.weight\n\t Mixed_6d.branch7x7_1.bn.weight\n\t Mixed_6d.branch7x7_1.bn.bias\n\t Mixed_6d.branch7x7_2.conv.weight\n\t Mixed_6d.branch7x7_2.bn.weight\n\t Mixed_6d.branch7x7_2.bn.bias\n\t Mixed_6d.branch7x7_3.conv.weight\n\t Mixed_6d.branch7x7_3.bn.weight\n\t Mixed_6d.branch7x7_3.bn.bias\n\t Mixed_6d.branch7x7dbl_1.conv.weight\n\t Mixed_6d.branch7x7dbl_1.bn.weight\n\t Mixed_6d.branch7x7dbl_1.bn.bias\n\t Mixed_6d.branch7x7dbl_2.conv.weight\n\t Mixed_6d.branch7x7dbl_2.bn.weight\n\t Mixed_6d.branch7x7dbl_2.bn.bias\n\t Mixed_6d.branch7x7dbl_3.conv.weight\n\t Mixed_6d.branch7x7dbl_3.bn.weight\n\t Mixed_6d.branch7x7dbl_3.bn.bias\n\t Mixed_6d.branch7x7dbl_4.conv.weight\n\t Mixed_6d.branch7x7dbl_4.bn.weight\n\t Mixed_6d.branch7x7dbl_4.bn.bias\n\t Mixed_6d.branch7x7dbl_5.conv.weight\n\t Mixed_6d.branch7x7dbl_5.bn.weight\n\t Mixed_6d.branch7x7dbl_5.bn.bias\n\t Mixed_6d.branch_pool.conv.weight\n\t Mixed_6d.branch_pool.bn.weight\n\t Mixed_6d.branch_pool.bn.bias\n\t Mixed_6e.branch1x1.conv.weight\n\t Mixed_6e.branch1x1.bn.weight\n\t Mixed_6e.branch1x1.bn.bias\n\t Mixed_6e.branch7x7_1.conv.weight\n\t Mixed_6e.branch7x7_1.bn.weight\n\t Mixed_6e.branch7x7_1.bn.bias\n\t Mixed_6e.branch7x7_2.conv.weight\n\t Mixed_6e.branch7x7_2.bn.weight\n\t Mixed_6e.branch7x7_2.bn.bias\n\t Mixed_6e.branch7x7_3.conv.weight\n\t Mixed_6e.branch7x7_3.bn.weight\n\t Mixed_6e.branch7x7_3.bn.bias\n\t Mixed_6e.branch7x7dbl_1.conv.weight\n\t Mixed_6e.branch7x7dbl_1.bn.weight\n\t Mixed_6e.branch7x7dbl_1.bn.bias\n\t Mixed_6e.branch7x7dbl_2.conv.weight\n\t Mixed_6e.branch7x7dbl_2.bn.weight\n\t Mixed_6e.branch7x7dbl_2.bn.bias\n\t Mixed_6e.branch7x7dbl_3.conv.weight\n\t Mixed_6e.branch7x7dbl_3.bn.weight\n\t Mixed_6e.branch7x7dbl_3.bn.bias\n\t Mixed_6e.branch7x7dbl_4.conv.weight\n\t Mixed_6e.branch7x7dbl_4.bn.weight\n\t Mixed_6e.branch7x7dbl_4.bn.bias\n\t Mixed_6e.branch7x7dbl_5.conv.weight\n\t Mixed_6e.branch7x7dbl_5.bn.weight\n\t Mixed_6e.branch7x7dbl_5.bn.bias\n\t Mixed_6e.branch_pool.conv.weight\n\t Mixed_6e.branch_pool.bn.weight\n\t Mixed_6e.branch_pool.bn.bias\n\t AuxLogits.conv0.conv.weight\n\t AuxLogits.conv0.bn.weight\n\t AuxLogits.conv0.bn.bias\n\t AuxLogits.conv1.conv.weight\n\t AuxLogits.conv1.bn.weight\n\t AuxLogits.conv1.bn.bias\n\t AuxLogits.fc.weight\n\t AuxLogits.fc.bias\n\t Mixed_7a.branch3x3_1.conv.weight\n\t Mixed_7a.branch3x3_1.bn.weight\n\t Mixed_7a.branch3x3_1.bn.bias\n\t Mixed_7a.branch3x3_2.conv.weight\n\t Mixed_7a.branch3x3_2.bn.weight\n\t Mixed_7a.branch3x3_2.bn.bias\n\t Mixed_7a.branch7x7x3_1.conv.weight\n\t Mixed_7a.branch7x7x3_1.bn.weight\n\t Mixed_7a.branch7x7x3_1.bn.bias\n\t Mixed_7a.branch7x7x3_2.conv.weight\n\t Mixed_7a.branch7x7x3_2.bn.weight\n\t Mixed_7a.branch7x7x3_2.bn.bias\n\t Mixed_7a.branch7x7x3_3.conv.weight\n\t Mixed_7a.branch7x7x3_3.bn.weight\n\t Mixed_7a.branch7x7x3_3.bn.bias\n\t Mixed_7a.branch7x7x3_4.conv.weight\n\t Mixed_7a.branch7x7x3_4.bn.weight\n\t Mixed_7a.branch7x7x3_4.bn.bias\n\t Mixed_7b.branch1x1.conv.weight\n\t Mixed_7b.branch1x1.bn.weight\n\t Mixed_7b.branch1x1.bn.bias\n\t Mixed_7b.branch3x3_1.conv.weight\n\t Mixed_7b.branch3x3_1.bn.weight\n\t Mixed_7b.branch3x3_1.bn.bias\n\t Mixed_7b.branch3x3_2a.conv.weight\n\t Mixed_7b.branch3x3_2a.bn.weight\n\t Mixed_7b.branch3x3_2a.bn.bias\n\t Mixed_7b.branch3x3_2b.conv.weight\n\t Mixed_7b.branch3x3_2b.bn.weight\n\t Mixed_7b.branch3x3_2b.bn.bias\n\t Mixed_7b.branch3x3dbl_1.conv.weight\n\t Mixed_7b.branch3x3dbl_1.bn.weight\n\t Mixed_7b.branch3x3dbl_1.bn.bias\n\t Mixed_7b.branch3x3dbl_2.conv.weight\n\t Mixed_7b.branch3x3dbl_2.bn.weight\n\t Mixed_7b.branch3x3dbl_2.bn.bias\n\t Mixed_7b.branch3x3dbl_3a.conv.weight\n\t Mixed_7b.branch3x3dbl_3a.bn.weight\n\t Mixed_7b.branch3x3dbl_3a.bn.bias\n\t Mixed_7b.branch3x3dbl_3b.conv.weight\n\t Mixed_7b.branch3x3dbl_3b.bn.weight\n\t Mixed_7b.branch3x3dbl_3b.bn.bias\n\t Mixed_7b.branch_pool.conv.weight\n\t Mixed_7b.branch_pool.bn.weight\n\t Mixed_7b.branch_pool.bn.bias\n\t Mixed_7c.branch1x1.conv.weight\n\t Mixed_7c.branch1x1.bn.weight\n\t Mixed_7c.branch1x1.bn.bias\n\t Mixed_7c.branch3x3_1.conv.weight\n\t Mixed_7c.branch3x3_1.bn.weight\n\t Mixed_7c.branch3x3_1.bn.bias\n\t Mixed_7c.branch3x3_2a.conv.weight\n\t Mixed_7c.branch3x3_2a.bn.weight\n\t Mixed_7c.branch3x3_2a.bn.bias\n\t Mixed_7c.branch3x3_2b.conv.weight\n\t Mixed_7c.branch3x3_2b.bn.weight\n\t Mixed_7c.branch3x3_2b.bn.bias\n\t Mixed_7c.branch3x3dbl_1.conv.weight\n\t Mixed_7c.branch3x3dbl_1.bn.weight\n\t Mixed_7c.branch3x3dbl_1.bn.bias\n\t Mixed_7c.branch3x3dbl_2.conv.weight\n\t Mixed_7c.branch3x3dbl_2.bn.weight\n\t Mixed_7c.branch3x3dbl_2.bn.bias\n\t Mixed_7c.branch3x3dbl_3a.conv.weight\n\t Mixed_7c.branch3x3dbl_3a.bn.weight\n\t Mixed_7c.branch3x3dbl_3a.bn.bias\n\t Mixed_7c.branch3x3dbl_3b.conv.weight\n\t Mixed_7c.branch3x3dbl_3b.bn.weight\n\t Mixed_7c.branch3x3dbl_3b.bn.bias\n\t Mixed_7c.branch_pool.conv.weight\n\t Mixed_7c.branch_pool.bn.weight\n\t Mixed_7c.branch_pool.bn.bias\n\t fc.weight\n\t fc.bias\n","output_type":"stream"}]},{"cell_type":"code","source":"# Setup the loss fxn\ncriterion = nn.CrossEntropyLoss(weight=torch.FloatTensor([1.0, 9.841, 5.117, 34.466, 37.930]).cuda())\n\n# Train and evaluate\nmodel_ft, hist = train_model(model_ft, dataloaders, criterion, optimizer_ft, num_epochs=num_epochs, is_inception=(model_name==\"inception\"))","metadata":{"id":"QXg5BAG1oo-f","outputId":"56971d33-4368-4983-e5ca-fdb6df98cbcf","trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Epoch 0/4\n----------\ntrain Loss: 1.7181 Acc: 0.4378\nval Loss: 1.1071 Acc: 0.3889\n\nEpoch 1/4\n----------\ntrain Loss: 1.4952 Acc: 0.5173\nval Loss: 1.0481 Acc: 0.4607\n\nEpoch 2/4\n----------\ntrain Loss: 1.4259 Acc: 0.5413\nval Loss: 1.0220 Acc: 0.4687\n\nEpoch 3/4\n----------\ntrain Loss: 1.3653 Acc: 0.5530\nval Loss: 1.0119 Acc: 0.5950\n\nEpoch 4/4\n----------\ntrain Loss: 1.3293 Acc: 0.5633\nval Loss: 0.9957 Acc: 0.4814\n\nTraining complete in 293m 58s\nBest val Acc: 0.595005\n","output_type":"stream"}]},{"cell_type":"code","source":"import seaborn as sns\nnb_classes = num_classes\nconfusion_matrix = np.zeros((nb_classes, nb_classes))\nwith torch.no_grad():\n    for i, (inputs, classes) in enumerate(dataloaders['test']):\n        inputs = inputs.to(device)\n        classes = classes.to(device)\n        outputs = model_ft(inputs)\n        _, preds = torch.max(outputs, 1)\n        for t, p in zip(classes.view(-1), preds.view(-1)):\n                confusion_matrix[t.long(), p.long()] += 1\n\nplt.figure(figsize=(15,10))\n\nclass_names = ['0', '1', '2', '3', '4']\ndf_cm = pd.DataFrame(confusion_matrix, index=class_names, columns=class_names).astype(int)\nheatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n\nheatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right',fontsize=15)\nheatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right',fontsize=15)\nplt.ylabel('True label')\nplt.xlabel('Predicted label')","metadata":{"id":"YpGRminVjRIY","trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"Text(0.5, 69.0, 'Predicted label')"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 1080x720 with 2 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":" # done","metadata":{"id":"-Emzn5VAnJKU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"ZH2KZyQOMPTM"},"execution_count":null,"outputs":[]}]}