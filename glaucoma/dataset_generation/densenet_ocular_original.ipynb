{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "densenet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqHnaptr-kuA",
        "outputId": "d5b518e7-38d0-4636-fbf5-326c148b27fc"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue May 11 04:57:44 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   72C    P0    75W / 149W |   5196MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7-9XFsaZnKQ"
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oGJ2hstm39V"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from imutils import contours\n",
        "from skimage import measure\n",
        "import imutils\n",
        "import os\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import copy\n",
        "import time\n",
        "\n",
        "import torch\n",
        "from torchvision import datasets, models, transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader, Dataset, TensorDataset, Subset, WeightedRandomSampler\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import pickle\n",
        "from collections import OrderedDict"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u899MaWr-ZF0"
      },
      "source": [
        "# Top level data directory. Here we assume the format of the directory conforms\n",
        "#   to the ImageFolder structure\n",
        "data_dir = '/content/drive/MyDrive/ocular_clean'\n",
        "\n",
        "# Models to choose from [resnet, alexnet, vgg, squeezenet, densenet, inception]\n",
        "model_name = \"densenet\"\n",
        "# inception\n",
        "input_size = 224\n",
        "\n",
        "# Number of classes in the dataset\n",
        "num_classes = 2\n",
        "\n",
        "# Batch size for training (change depending on how much memory you have)\n",
        "batch_size = 32\n",
        "\n",
        "# Number of epochs to train for\n",
        "num_epochs = 10\n",
        "\n",
        "# Flag for feature extracting. When False, we finetune the whole model,\n",
        "#   when True we only update the reshaped layer params\n",
        "feature_extract = False\n",
        "\n",
        "num_workers = 2\n",
        "\n",
        "train_size = 0.60\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYnO7mxJZywE"
      },
      "source": [
        "\n",
        "class ben_color(object):\n",
        "    def __call__(self, img, sigmaX=10):\n",
        "        \"\"\"\n",
        "        :param img: PIL): Image \n",
        "\n",
        "        :return: Normalized image\n",
        "        \"\"\"\n",
        "\n",
        "        img = np.asarray(img)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        img = self.crop_image_from_gray(img)\n",
        "        img = cv2.resize(img, (input_size, input_size))\n",
        "        img = cv2.addWeighted (img, 4, cv2.GaussianBlur(img, (0,0), sigmaX), -4, 128)\n",
        "        return Image.fromarray(img)\n",
        "\n",
        "    def crop_image_from_gray(self, img, tol=7):\n",
        "        if img.ndim ==2:\n",
        "            mask = img>tol\n",
        "            return img[np.ix_(mask.any(1),mask.any(0))]\n",
        "        elif img.ndim==3:\n",
        "            gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "            mask = gray_img>tol\n",
        "            \n",
        "            check_shape = img[:,:,0][np.ix_(mask.any(1),mask.any(0))].shape[0]\n",
        "            if (check_shape == 0):\n",
        "                return img \n",
        "            else:\n",
        "                img1=img[:,:,0][np.ix_(mask.any(1),mask.any(0))]\n",
        "                img2=img[:,:,1][np.ix_(mask.any(1),mask.any(0))]\n",
        "                img3=img[:,:,2][np.ix_(mask.any(1),mask.any(0))]\n",
        "                img = np.stack([img1,img2,img3],axis=-1)\n",
        "            return img\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__+'()'"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jj74frLDrZd"
      },
      "source": [
        "# Todos: shuffle in validation set\n",
        "# add more augmentations  \n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "        ben_color(),\n",
        "        transforms.RandomRotation(degrees=(0, 360)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.Resize((input_size, input_size)),\n",
        "        transforms.ToTensor(),\n",
        "        # transforms.Normalize((0.5,), (0.5,))])\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "\n",
        "\n",
        "valid_transform = transforms.Compose([\n",
        "        ben_color(),\n",
        "        transforms.Resize((input_size, input_size)),\n",
        "        transforms.ToTensor(),\n",
        "        # transforms.Normalize((0.5,), (0.5,))])\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "\n",
        "\n",
        "class DR(Dataset):\n",
        "    def __init__(self, dataset, transform=None):\n",
        "        self.dataset = dataset\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        if self.transform:\n",
        "            x = self.transform(dataset[index][0])\n",
        "        else:\n",
        "            x = dataset[index][0]\n",
        "        y = dataset[index][1]\n",
        "        return x, y\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(dataset)\n",
        "    \n",
        "\n",
        "dataset = ImageFolder(data_dir)\n",
        "\n",
        "traindataset = DR(dataset, train_transform)\n",
        "valdataset = DR(dataset, valid_transform)\n",
        "testdataset = DR(dataset, valid_transform)\n",
        "\n",
        "# Create the index splits for training, validation and test\n",
        "\n",
        "num_train = len(dataset)\n",
        "indices = list(range(num_train))\n",
        "split = int(np.floor(train_size * num_train))\n",
        "split2 = int(np.floor((train_size+(1-train_size)/2) * num_train))\n",
        "np.random.shuffle(indices)\n",
        "train_idx, valid_idx, test_idx = indices[:split], indices[split:split2], indices[split2:]\n",
        "\n",
        "traindata = Subset(traindataset, indices=train_idx)\n",
        "valdata = Subset(valdataset, indices=valid_idx)\n",
        "testdata = Subset(testdataset, indices=test_idx)\n",
        "\n",
        "class_weights = []\n",
        "for root, subdir, files in os.walk(data_dir):\n",
        "  if len(files)>0:\n",
        "    class_weights.append(1/len(files))\n",
        "\n",
        "sample_weights = [0] * len(traindata)\n",
        "\n",
        "for idx, (data, label) in enumerate(traindata):\n",
        "  class_weight = class_weights[label]\n",
        "  sample_weights[idx] = class_weight\n",
        "\n",
        "\n",
        "# with open('/content/drive/MyDrive/clean_weights.pkl', 'wb') as f:\n",
        "#   pickle.dump(sample_weights, f)\n",
        "\n",
        "# with open('/content/drive/MyDrive/clean_weights.pkl', 'rb') as f:\n",
        "#   sample_weights = pickle.load(f)\n",
        "\n",
        "sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)\n",
        "\n",
        "trainLoader = torch.utils.data.DataLoader(traindata, sampler=sampler, batch_size=batch_size, \n",
        "                                          num_workers=num_workers, drop_last=True)\n",
        "valLoader = torch.utils.data.DataLoader(valdata, batch_size=batch_size, \n",
        "                                          num_workers=num_workers, drop_last=True)\n",
        "testLoader = torch.utils.data.DataLoader(testdata, batch_size=batch_size,\n",
        "                                          num_workers=num_workers, drop_last=True)\n",
        "dataloaders = {'train': trainLoader, 'val': valLoader, 'test': testLoader}"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyThMaR4nbLF"
      },
      "source": [
        "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False):\n",
        "    since = time.time()\n",
        "\n",
        "    val_acc_history = []\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    # Get model outputs and calculate loss\n",
        "                    # Special case for inception because in training it has an auxiliary output. In train\n",
        "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
        "                    #   but in testing we only consider the final output.\n",
        "                    if is_inception and phase == 'train':\n",
        "                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
        "                        outputs, aux_outputs = model(inputs)\n",
        "                        loss1 = criterion(outputs, labels)\n",
        "                        loss2 = criterion(aux_outputs, labels)\n",
        "                        loss = loss1 + 0.4*loss2\n",
        "                    else:\n",
        "                        outputs = model(inputs)\n",
        "                        loss = criterion(outputs, labels)\n",
        "\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
        "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            if phase == 'val':\n",
        "                val_acc_history.append(epoch_acc)\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, val_acc_history"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75VdlQ8ln1a9"
      },
      "source": [
        "def set_parameter_requires_grad(model, feature_extracting):\n",
        "    if feature_extracting:\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4O8Uqptn8Sb",
        "outputId": "c06f9f0f-cc1b-4270-a5a3-ff32623b1093"
      },
      "source": [
        "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
        "    # Initialize these variables which will be set in this if statement. Each of these\n",
        "    #   variables is model specific.\n",
        "    model_ft = None\n",
        "    input_size = 0\n",
        "\n",
        "    if model_name == \"resnet\":\n",
        "        \"\"\" Resnet18\n",
        "        \"\"\"\n",
        "        model_ft = models.resnet18(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.fc.in_features\n",
        "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"alexnet\":\n",
        "        \"\"\" Alexnet\n",
        "        \"\"\"\n",
        "        model_ft = models.alexnet(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.classifier[6].in_features\n",
        "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"vgg\":\n",
        "        \"\"\" VGG11_bn\n",
        "        \"\"\"\n",
        "        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.classifier[6].in_features\n",
        "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"squeezenet\":\n",
        "        \"\"\" Squeezenet\n",
        "        \"\"\"\n",
        "        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
        "        model_ft.num_classes = num_classes\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"densenet\":\n",
        "        \"\"\" Densenet\n",
        "        \"\"\"\n",
        "        model_ft = models.densenet121(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.classifier.in_features\n",
        "        # model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n",
        "        input_size = 224\n",
        "        classifier_dict = OrderedDict([\n",
        "            ('fc1', nn.Linear(1024, 512)),\n",
        "            ('relu1', nn.ReLU()),\n",
        "            ('dropout1', nn.Dropout(p=0.2)),\n",
        "            ('fc2', nn.Linear(512, 128)),\n",
        "            ('relu2', nn.ReLU()),\n",
        "            ('dropout2', nn.Dropout(p=0.2)),\n",
        "            ('fc3', nn.Linear(128, num_classes)),\n",
        "            ('output', nn.LogSoftmax(dim=1)),\n",
        "            ])\n",
        "            \n",
        "        # creating the classifier for our usage using the ordered dictionary\n",
        "        classifier = nn.Sequential(classifier_dict)\n",
        "\n",
        "        # replacing the pretrained model classifier with our classifier\n",
        "        model_ft.classifier = classifier\n",
        "\n",
        "    elif model_name == \"inception\":\n",
        "        \"\"\" Inception v3\n",
        "        Be careful, expects (299,299) sized images and has auxiliary output\n",
        "        \"\"\"\n",
        "        model_ft = models.inception_v3(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        # Handle the auxilary net\n",
        "        num_ftrs = model_ft.AuxLogits.fc.in_features\n",
        "        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n",
        "        # Handle the primary net\n",
        "        num_ftrs = model_ft.fc.in_features\n",
        "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
        "        input_size = 299\n",
        "\n",
        "    else:\n",
        "        print(\"Invalid model name, exiting...\")\n",
        "        exit()\n",
        "\n",
        "    return model_ft, input_size\n",
        "\n",
        "# Initialize the model for this run\n",
        "model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n",
        "\n",
        "# Print the model we just instantiated\n",
        "print(model_ft)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DenseNet(\n",
            "  (features): Sequential(\n",
            "    (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "    (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu0): ReLU(inplace=True)\n",
            "    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (denseblock1): _DenseBlock(\n",
            "      (denselayer1): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer2): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer3): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer4): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer5): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer6): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (transition1): _Transition(\n",
            "      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "    )\n",
            "    (denseblock2): _DenseBlock(\n",
            "      (denselayer1): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer2): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer3): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer4): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer5): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer6): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer7): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer8): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer9): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer10): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer11): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer12): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (transition2): _Transition(\n",
            "      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "    )\n",
            "    (denseblock3): _DenseBlock(\n",
            "      (denselayer1): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer2): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer3): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer4): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer5): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer6): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer7): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer8): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer9): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer10): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer11): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer12): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer13): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer14): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer15): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer16): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer17): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer18): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer19): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer20): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer21): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer22): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer23): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer24): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (transition3): _Transition(\n",
            "      (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "    )\n",
            "    (denseblock4): _DenseBlock(\n",
            "      (denselayer1): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer2): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer3): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer4): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer5): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer6): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer7): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer8): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer9): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer10): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer11): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer12): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer13): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer14): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer15): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer16): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (fc1): Linear(in_features=1024, out_features=512, bias=True)\n",
            "    (relu1): ReLU()\n",
            "    (dropout1): Dropout(p=0.2, inplace=False)\n",
            "    (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
            "    (relu2): ReLU()\n",
            "    (dropout2): Dropout(p=0.2, inplace=False)\n",
            "    (fc3): Linear(in_features=128, out_features=2, bias=True)\n",
            "    (output): LogSoftmax(dim=1)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6151ULNdzuq",
        "outputId": "f7b7a0fe-8fb9-4ecc-ee64-a72e528ba83d"
      },
      "source": [
        "# Send the model to GPU\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "# Gather the parameters to be optimized/updated in this run. If we are\n",
        "#  finetuning we will be updating all parameters. However, if we are\n",
        "#  doing feature extract method, we will only update the parameters\n",
        "#  that we have just initialized, i.e. the parameters with requires_grad\n",
        "#  is True.\n",
        "params_to_update = model_ft.parameters()\n",
        "print(\"Params to learn:\")\n",
        "if feature_extract:\n",
        "    params_to_update = []\n",
        "    for name,param in model_ft.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            params_to_update.append(param)\n",
        "            print(\"\\t\",name)\n",
        "else:\n",
        "    for name,param in model_ft.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            print(\"\\t\",name)\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Params to learn:\n",
            "\t features.conv0.weight\n",
            "\t features.norm0.weight\n",
            "\t features.norm0.bias\n",
            "\t features.denseblock1.denselayer1.norm1.weight\n",
            "\t features.denseblock1.denselayer1.norm1.bias\n",
            "\t features.denseblock1.denselayer1.conv1.weight\n",
            "\t features.denseblock1.denselayer1.norm2.weight\n",
            "\t features.denseblock1.denselayer1.norm2.bias\n",
            "\t features.denseblock1.denselayer1.conv2.weight\n",
            "\t features.denseblock1.denselayer2.norm1.weight\n",
            "\t features.denseblock1.denselayer2.norm1.bias\n",
            "\t features.denseblock1.denselayer2.conv1.weight\n",
            "\t features.denseblock1.denselayer2.norm2.weight\n",
            "\t features.denseblock1.denselayer2.norm2.bias\n",
            "\t features.denseblock1.denselayer2.conv2.weight\n",
            "\t features.denseblock1.denselayer3.norm1.weight\n",
            "\t features.denseblock1.denselayer3.norm1.bias\n",
            "\t features.denseblock1.denselayer3.conv1.weight\n",
            "\t features.denseblock1.denselayer3.norm2.weight\n",
            "\t features.denseblock1.denselayer3.norm2.bias\n",
            "\t features.denseblock1.denselayer3.conv2.weight\n",
            "\t features.denseblock1.denselayer4.norm1.weight\n",
            "\t features.denseblock1.denselayer4.norm1.bias\n",
            "\t features.denseblock1.denselayer4.conv1.weight\n",
            "\t features.denseblock1.denselayer4.norm2.weight\n",
            "\t features.denseblock1.denselayer4.norm2.bias\n",
            "\t features.denseblock1.denselayer4.conv2.weight\n",
            "\t features.denseblock1.denselayer5.norm1.weight\n",
            "\t features.denseblock1.denselayer5.norm1.bias\n",
            "\t features.denseblock1.denselayer5.conv1.weight\n",
            "\t features.denseblock1.denselayer5.norm2.weight\n",
            "\t features.denseblock1.denselayer5.norm2.bias\n",
            "\t features.denseblock1.denselayer5.conv2.weight\n",
            "\t features.denseblock1.denselayer6.norm1.weight\n",
            "\t features.denseblock1.denselayer6.norm1.bias\n",
            "\t features.denseblock1.denselayer6.conv1.weight\n",
            "\t features.denseblock1.denselayer6.norm2.weight\n",
            "\t features.denseblock1.denselayer6.norm2.bias\n",
            "\t features.denseblock1.denselayer6.conv2.weight\n",
            "\t features.transition1.norm.weight\n",
            "\t features.transition1.norm.bias\n",
            "\t features.transition1.conv.weight\n",
            "\t features.denseblock2.denselayer1.norm1.weight\n",
            "\t features.denseblock2.denselayer1.norm1.bias\n",
            "\t features.denseblock2.denselayer1.conv1.weight\n",
            "\t features.denseblock2.denselayer1.norm2.weight\n",
            "\t features.denseblock2.denselayer1.norm2.bias\n",
            "\t features.denseblock2.denselayer1.conv2.weight\n",
            "\t features.denseblock2.denselayer2.norm1.weight\n",
            "\t features.denseblock2.denselayer2.norm1.bias\n",
            "\t features.denseblock2.denselayer2.conv1.weight\n",
            "\t features.denseblock2.denselayer2.norm2.weight\n",
            "\t features.denseblock2.denselayer2.norm2.bias\n",
            "\t features.denseblock2.denselayer2.conv2.weight\n",
            "\t features.denseblock2.denselayer3.norm1.weight\n",
            "\t features.denseblock2.denselayer3.norm1.bias\n",
            "\t features.denseblock2.denselayer3.conv1.weight\n",
            "\t features.denseblock2.denselayer3.norm2.weight\n",
            "\t features.denseblock2.denselayer3.norm2.bias\n",
            "\t features.denseblock2.denselayer3.conv2.weight\n",
            "\t features.denseblock2.denselayer4.norm1.weight\n",
            "\t features.denseblock2.denselayer4.norm1.bias\n",
            "\t features.denseblock2.denselayer4.conv1.weight\n",
            "\t features.denseblock2.denselayer4.norm2.weight\n",
            "\t features.denseblock2.denselayer4.norm2.bias\n",
            "\t features.denseblock2.denselayer4.conv2.weight\n",
            "\t features.denseblock2.denselayer5.norm1.weight\n",
            "\t features.denseblock2.denselayer5.norm1.bias\n",
            "\t features.denseblock2.denselayer5.conv1.weight\n",
            "\t features.denseblock2.denselayer5.norm2.weight\n",
            "\t features.denseblock2.denselayer5.norm2.bias\n",
            "\t features.denseblock2.denselayer5.conv2.weight\n",
            "\t features.denseblock2.denselayer6.norm1.weight\n",
            "\t features.denseblock2.denselayer6.norm1.bias\n",
            "\t features.denseblock2.denselayer6.conv1.weight\n",
            "\t features.denseblock2.denselayer6.norm2.weight\n",
            "\t features.denseblock2.denselayer6.norm2.bias\n",
            "\t features.denseblock2.denselayer6.conv2.weight\n",
            "\t features.denseblock2.denselayer7.norm1.weight\n",
            "\t features.denseblock2.denselayer7.norm1.bias\n",
            "\t features.denseblock2.denselayer7.conv1.weight\n",
            "\t features.denseblock2.denselayer7.norm2.weight\n",
            "\t features.denseblock2.denselayer7.norm2.bias\n",
            "\t features.denseblock2.denselayer7.conv2.weight\n",
            "\t features.denseblock2.denselayer8.norm1.weight\n",
            "\t features.denseblock2.denselayer8.norm1.bias\n",
            "\t features.denseblock2.denselayer8.conv1.weight\n",
            "\t features.denseblock2.denselayer8.norm2.weight\n",
            "\t features.denseblock2.denselayer8.norm2.bias\n",
            "\t features.denseblock2.denselayer8.conv2.weight\n",
            "\t features.denseblock2.denselayer9.norm1.weight\n",
            "\t features.denseblock2.denselayer9.norm1.bias\n",
            "\t features.denseblock2.denselayer9.conv1.weight\n",
            "\t features.denseblock2.denselayer9.norm2.weight\n",
            "\t features.denseblock2.denselayer9.norm2.bias\n",
            "\t features.denseblock2.denselayer9.conv2.weight\n",
            "\t features.denseblock2.denselayer10.norm1.weight\n",
            "\t features.denseblock2.denselayer10.norm1.bias\n",
            "\t features.denseblock2.denselayer10.conv1.weight\n",
            "\t features.denseblock2.denselayer10.norm2.weight\n",
            "\t features.denseblock2.denselayer10.norm2.bias\n",
            "\t features.denseblock2.denselayer10.conv2.weight\n",
            "\t features.denseblock2.denselayer11.norm1.weight\n",
            "\t features.denseblock2.denselayer11.norm1.bias\n",
            "\t features.denseblock2.denselayer11.conv1.weight\n",
            "\t features.denseblock2.denselayer11.norm2.weight\n",
            "\t features.denseblock2.denselayer11.norm2.bias\n",
            "\t features.denseblock2.denselayer11.conv2.weight\n",
            "\t features.denseblock2.denselayer12.norm1.weight\n",
            "\t features.denseblock2.denselayer12.norm1.bias\n",
            "\t features.denseblock2.denselayer12.conv1.weight\n",
            "\t features.denseblock2.denselayer12.norm2.weight\n",
            "\t features.denseblock2.denselayer12.norm2.bias\n",
            "\t features.denseblock2.denselayer12.conv2.weight\n",
            "\t features.transition2.norm.weight\n",
            "\t features.transition2.norm.bias\n",
            "\t features.transition2.conv.weight\n",
            "\t features.denseblock3.denselayer1.norm1.weight\n",
            "\t features.denseblock3.denselayer1.norm1.bias\n",
            "\t features.denseblock3.denselayer1.conv1.weight\n",
            "\t features.denseblock3.denselayer1.norm2.weight\n",
            "\t features.denseblock3.denselayer1.norm2.bias\n",
            "\t features.denseblock3.denselayer1.conv2.weight\n",
            "\t features.denseblock3.denselayer2.norm1.weight\n",
            "\t features.denseblock3.denselayer2.norm1.bias\n",
            "\t features.denseblock3.denselayer2.conv1.weight\n",
            "\t features.denseblock3.denselayer2.norm2.weight\n",
            "\t features.denseblock3.denselayer2.norm2.bias\n",
            "\t features.denseblock3.denselayer2.conv2.weight\n",
            "\t features.denseblock3.denselayer3.norm1.weight\n",
            "\t features.denseblock3.denselayer3.norm1.bias\n",
            "\t features.denseblock3.denselayer3.conv1.weight\n",
            "\t features.denseblock3.denselayer3.norm2.weight\n",
            "\t features.denseblock3.denselayer3.norm2.bias\n",
            "\t features.denseblock3.denselayer3.conv2.weight\n",
            "\t features.denseblock3.denselayer4.norm1.weight\n",
            "\t features.denseblock3.denselayer4.norm1.bias\n",
            "\t features.denseblock3.denselayer4.conv1.weight\n",
            "\t features.denseblock3.denselayer4.norm2.weight\n",
            "\t features.denseblock3.denselayer4.norm2.bias\n",
            "\t features.denseblock3.denselayer4.conv2.weight\n",
            "\t features.denseblock3.denselayer5.norm1.weight\n",
            "\t features.denseblock3.denselayer5.norm1.bias\n",
            "\t features.denseblock3.denselayer5.conv1.weight\n",
            "\t features.denseblock3.denselayer5.norm2.weight\n",
            "\t features.denseblock3.denselayer5.norm2.bias\n",
            "\t features.denseblock3.denselayer5.conv2.weight\n",
            "\t features.denseblock3.denselayer6.norm1.weight\n",
            "\t features.denseblock3.denselayer6.norm1.bias\n",
            "\t features.denseblock3.denselayer6.conv1.weight\n",
            "\t features.denseblock3.denselayer6.norm2.weight\n",
            "\t features.denseblock3.denselayer6.norm2.bias\n",
            "\t features.denseblock3.denselayer6.conv2.weight\n",
            "\t features.denseblock3.denselayer7.norm1.weight\n",
            "\t features.denseblock3.denselayer7.norm1.bias\n",
            "\t features.denseblock3.denselayer7.conv1.weight\n",
            "\t features.denseblock3.denselayer7.norm2.weight\n",
            "\t features.denseblock3.denselayer7.norm2.bias\n",
            "\t features.denseblock3.denselayer7.conv2.weight\n",
            "\t features.denseblock3.denselayer8.norm1.weight\n",
            "\t features.denseblock3.denselayer8.norm1.bias\n",
            "\t features.denseblock3.denselayer8.conv1.weight\n",
            "\t features.denseblock3.denselayer8.norm2.weight\n",
            "\t features.denseblock3.denselayer8.norm2.bias\n",
            "\t features.denseblock3.denselayer8.conv2.weight\n",
            "\t features.denseblock3.denselayer9.norm1.weight\n",
            "\t features.denseblock3.denselayer9.norm1.bias\n",
            "\t features.denseblock3.denselayer9.conv1.weight\n",
            "\t features.denseblock3.denselayer9.norm2.weight\n",
            "\t features.denseblock3.denselayer9.norm2.bias\n",
            "\t features.denseblock3.denselayer9.conv2.weight\n",
            "\t features.denseblock3.denselayer10.norm1.weight\n",
            "\t features.denseblock3.denselayer10.norm1.bias\n",
            "\t features.denseblock3.denselayer10.conv1.weight\n",
            "\t features.denseblock3.denselayer10.norm2.weight\n",
            "\t features.denseblock3.denselayer10.norm2.bias\n",
            "\t features.denseblock3.denselayer10.conv2.weight\n",
            "\t features.denseblock3.denselayer11.norm1.weight\n",
            "\t features.denseblock3.denselayer11.norm1.bias\n",
            "\t features.denseblock3.denselayer11.conv1.weight\n",
            "\t features.denseblock3.denselayer11.norm2.weight\n",
            "\t features.denseblock3.denselayer11.norm2.bias\n",
            "\t features.denseblock3.denselayer11.conv2.weight\n",
            "\t features.denseblock3.denselayer12.norm1.weight\n",
            "\t features.denseblock3.denselayer12.norm1.bias\n",
            "\t features.denseblock3.denselayer12.conv1.weight\n",
            "\t features.denseblock3.denselayer12.norm2.weight\n",
            "\t features.denseblock3.denselayer12.norm2.bias\n",
            "\t features.denseblock3.denselayer12.conv2.weight\n",
            "\t features.denseblock3.denselayer13.norm1.weight\n",
            "\t features.denseblock3.denselayer13.norm1.bias\n",
            "\t features.denseblock3.denselayer13.conv1.weight\n",
            "\t features.denseblock3.denselayer13.norm2.weight\n",
            "\t features.denseblock3.denselayer13.norm2.bias\n",
            "\t features.denseblock3.denselayer13.conv2.weight\n",
            "\t features.denseblock3.denselayer14.norm1.weight\n",
            "\t features.denseblock3.denselayer14.norm1.bias\n",
            "\t features.denseblock3.denselayer14.conv1.weight\n",
            "\t features.denseblock3.denselayer14.norm2.weight\n",
            "\t features.denseblock3.denselayer14.norm2.bias\n",
            "\t features.denseblock3.denselayer14.conv2.weight\n",
            "\t features.denseblock3.denselayer15.norm1.weight\n",
            "\t features.denseblock3.denselayer15.norm1.bias\n",
            "\t features.denseblock3.denselayer15.conv1.weight\n",
            "\t features.denseblock3.denselayer15.norm2.weight\n",
            "\t features.denseblock3.denselayer15.norm2.bias\n",
            "\t features.denseblock3.denselayer15.conv2.weight\n",
            "\t features.denseblock3.denselayer16.norm1.weight\n",
            "\t features.denseblock3.denselayer16.norm1.bias\n",
            "\t features.denseblock3.denselayer16.conv1.weight\n",
            "\t features.denseblock3.denselayer16.norm2.weight\n",
            "\t features.denseblock3.denselayer16.norm2.bias\n",
            "\t features.denseblock3.denselayer16.conv2.weight\n",
            "\t features.denseblock3.denselayer17.norm1.weight\n",
            "\t features.denseblock3.denselayer17.norm1.bias\n",
            "\t features.denseblock3.denselayer17.conv1.weight\n",
            "\t features.denseblock3.denselayer17.norm2.weight\n",
            "\t features.denseblock3.denselayer17.norm2.bias\n",
            "\t features.denseblock3.denselayer17.conv2.weight\n",
            "\t features.denseblock3.denselayer18.norm1.weight\n",
            "\t features.denseblock3.denselayer18.norm1.bias\n",
            "\t features.denseblock3.denselayer18.conv1.weight\n",
            "\t features.denseblock3.denselayer18.norm2.weight\n",
            "\t features.denseblock3.denselayer18.norm2.bias\n",
            "\t features.denseblock3.denselayer18.conv2.weight\n",
            "\t features.denseblock3.denselayer19.norm1.weight\n",
            "\t features.denseblock3.denselayer19.norm1.bias\n",
            "\t features.denseblock3.denselayer19.conv1.weight\n",
            "\t features.denseblock3.denselayer19.norm2.weight\n",
            "\t features.denseblock3.denselayer19.norm2.bias\n",
            "\t features.denseblock3.denselayer19.conv2.weight\n",
            "\t features.denseblock3.denselayer20.norm1.weight\n",
            "\t features.denseblock3.denselayer20.norm1.bias\n",
            "\t features.denseblock3.denselayer20.conv1.weight\n",
            "\t features.denseblock3.denselayer20.norm2.weight\n",
            "\t features.denseblock3.denselayer20.norm2.bias\n",
            "\t features.denseblock3.denselayer20.conv2.weight\n",
            "\t features.denseblock3.denselayer21.norm1.weight\n",
            "\t features.denseblock3.denselayer21.norm1.bias\n",
            "\t features.denseblock3.denselayer21.conv1.weight\n",
            "\t features.denseblock3.denselayer21.norm2.weight\n",
            "\t features.denseblock3.denselayer21.norm2.bias\n",
            "\t features.denseblock3.denselayer21.conv2.weight\n",
            "\t features.denseblock3.denselayer22.norm1.weight\n",
            "\t features.denseblock3.denselayer22.norm1.bias\n",
            "\t features.denseblock3.denselayer22.conv1.weight\n",
            "\t features.denseblock3.denselayer22.norm2.weight\n",
            "\t features.denseblock3.denselayer22.norm2.bias\n",
            "\t features.denseblock3.denselayer22.conv2.weight\n",
            "\t features.denseblock3.denselayer23.norm1.weight\n",
            "\t features.denseblock3.denselayer23.norm1.bias\n",
            "\t features.denseblock3.denselayer23.conv1.weight\n",
            "\t features.denseblock3.denselayer23.norm2.weight\n",
            "\t features.denseblock3.denselayer23.norm2.bias\n",
            "\t features.denseblock3.denselayer23.conv2.weight\n",
            "\t features.denseblock3.denselayer24.norm1.weight\n",
            "\t features.denseblock3.denselayer24.norm1.bias\n",
            "\t features.denseblock3.denselayer24.conv1.weight\n",
            "\t features.denseblock3.denselayer24.norm2.weight\n",
            "\t features.denseblock3.denselayer24.norm2.bias\n",
            "\t features.denseblock3.denselayer24.conv2.weight\n",
            "\t features.transition3.norm.weight\n",
            "\t features.transition3.norm.bias\n",
            "\t features.transition3.conv.weight\n",
            "\t features.denseblock4.denselayer1.norm1.weight\n",
            "\t features.denseblock4.denselayer1.norm1.bias\n",
            "\t features.denseblock4.denselayer1.conv1.weight\n",
            "\t features.denseblock4.denselayer1.norm2.weight\n",
            "\t features.denseblock4.denselayer1.norm2.bias\n",
            "\t features.denseblock4.denselayer1.conv2.weight\n",
            "\t features.denseblock4.denselayer2.norm1.weight\n",
            "\t features.denseblock4.denselayer2.norm1.bias\n",
            "\t features.denseblock4.denselayer2.conv1.weight\n",
            "\t features.denseblock4.denselayer2.norm2.weight\n",
            "\t features.denseblock4.denselayer2.norm2.bias\n",
            "\t features.denseblock4.denselayer2.conv2.weight\n",
            "\t features.denseblock4.denselayer3.norm1.weight\n",
            "\t features.denseblock4.denselayer3.norm1.bias\n",
            "\t features.denseblock4.denselayer3.conv1.weight\n",
            "\t features.denseblock4.denselayer3.norm2.weight\n",
            "\t features.denseblock4.denselayer3.norm2.bias\n",
            "\t features.denseblock4.denselayer3.conv2.weight\n",
            "\t features.denseblock4.denselayer4.norm1.weight\n",
            "\t features.denseblock4.denselayer4.norm1.bias\n",
            "\t features.denseblock4.denselayer4.conv1.weight\n",
            "\t features.denseblock4.denselayer4.norm2.weight\n",
            "\t features.denseblock4.denselayer4.norm2.bias\n",
            "\t features.denseblock4.denselayer4.conv2.weight\n",
            "\t features.denseblock4.denselayer5.norm1.weight\n",
            "\t features.denseblock4.denselayer5.norm1.bias\n",
            "\t features.denseblock4.denselayer5.conv1.weight\n",
            "\t features.denseblock4.denselayer5.norm2.weight\n",
            "\t features.denseblock4.denselayer5.norm2.bias\n",
            "\t features.denseblock4.denselayer5.conv2.weight\n",
            "\t features.denseblock4.denselayer6.norm1.weight\n",
            "\t features.denseblock4.denselayer6.norm1.bias\n",
            "\t features.denseblock4.denselayer6.conv1.weight\n",
            "\t features.denseblock4.denselayer6.norm2.weight\n",
            "\t features.denseblock4.denselayer6.norm2.bias\n",
            "\t features.denseblock4.denselayer6.conv2.weight\n",
            "\t features.denseblock4.denselayer7.norm1.weight\n",
            "\t features.denseblock4.denselayer7.norm1.bias\n",
            "\t features.denseblock4.denselayer7.conv1.weight\n",
            "\t features.denseblock4.denselayer7.norm2.weight\n",
            "\t features.denseblock4.denselayer7.norm2.bias\n",
            "\t features.denseblock4.denselayer7.conv2.weight\n",
            "\t features.denseblock4.denselayer8.norm1.weight\n",
            "\t features.denseblock4.denselayer8.norm1.bias\n",
            "\t features.denseblock4.denselayer8.conv1.weight\n",
            "\t features.denseblock4.denselayer8.norm2.weight\n",
            "\t features.denseblock4.denselayer8.norm2.bias\n",
            "\t features.denseblock4.denselayer8.conv2.weight\n",
            "\t features.denseblock4.denselayer9.norm1.weight\n",
            "\t features.denseblock4.denselayer9.norm1.bias\n",
            "\t features.denseblock4.denselayer9.conv1.weight\n",
            "\t features.denseblock4.denselayer9.norm2.weight\n",
            "\t features.denseblock4.denselayer9.norm2.bias\n",
            "\t features.denseblock4.denselayer9.conv2.weight\n",
            "\t features.denseblock4.denselayer10.norm1.weight\n",
            "\t features.denseblock4.denselayer10.norm1.bias\n",
            "\t features.denseblock4.denselayer10.conv1.weight\n",
            "\t features.denseblock4.denselayer10.norm2.weight\n",
            "\t features.denseblock4.denselayer10.norm2.bias\n",
            "\t features.denseblock4.denselayer10.conv2.weight\n",
            "\t features.denseblock4.denselayer11.norm1.weight\n",
            "\t features.denseblock4.denselayer11.norm1.bias\n",
            "\t features.denseblock4.denselayer11.conv1.weight\n",
            "\t features.denseblock4.denselayer11.norm2.weight\n",
            "\t features.denseblock4.denselayer11.norm2.bias\n",
            "\t features.denseblock4.denselayer11.conv2.weight\n",
            "\t features.denseblock4.denselayer12.norm1.weight\n",
            "\t features.denseblock4.denselayer12.norm1.bias\n",
            "\t features.denseblock4.denselayer12.conv1.weight\n",
            "\t features.denseblock4.denselayer12.norm2.weight\n",
            "\t features.denseblock4.denselayer12.norm2.bias\n",
            "\t features.denseblock4.denselayer12.conv2.weight\n",
            "\t features.denseblock4.denselayer13.norm1.weight\n",
            "\t features.denseblock4.denselayer13.norm1.bias\n",
            "\t features.denseblock4.denselayer13.conv1.weight\n",
            "\t features.denseblock4.denselayer13.norm2.weight\n",
            "\t features.denseblock4.denselayer13.norm2.bias\n",
            "\t features.denseblock4.denselayer13.conv2.weight\n",
            "\t features.denseblock4.denselayer14.norm1.weight\n",
            "\t features.denseblock4.denselayer14.norm1.bias\n",
            "\t features.denseblock4.denselayer14.conv1.weight\n",
            "\t features.denseblock4.denselayer14.norm2.weight\n",
            "\t features.denseblock4.denselayer14.norm2.bias\n",
            "\t features.denseblock4.denselayer14.conv2.weight\n",
            "\t features.denseblock4.denselayer15.norm1.weight\n",
            "\t features.denseblock4.denselayer15.norm1.bias\n",
            "\t features.denseblock4.denselayer15.conv1.weight\n",
            "\t features.denseblock4.denselayer15.norm2.weight\n",
            "\t features.denseblock4.denselayer15.norm2.bias\n",
            "\t features.denseblock4.denselayer15.conv2.weight\n",
            "\t features.denseblock4.denselayer16.norm1.weight\n",
            "\t features.denseblock4.denselayer16.norm1.bias\n",
            "\t features.denseblock4.denselayer16.conv1.weight\n",
            "\t features.denseblock4.denselayer16.norm2.weight\n",
            "\t features.denseblock4.denselayer16.norm2.bias\n",
            "\t features.denseblock4.denselayer16.conv2.weight\n",
            "\t features.norm5.weight\n",
            "\t features.norm5.bias\n",
            "\t classifier.fc1.weight\n",
            "\t classifier.fc1.bias\n",
            "\t classifier.fc2.weight\n",
            "\t classifier.fc2.bias\n",
            "\t classifier.fc3.weight\n",
            "\t classifier.fc3.bias\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXg5BAG1oo-f",
        "outputId": "2d676499-8741-4b7a-eb9d-3f45bc897ccd"
      },
      "source": [
        "# # Setup the loss fxn\n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# NLLLoss because our output is LogSoftmax\n",
        "criterion = nn.NLLLoss()\n",
        "\n",
        "# Adam optimizer with a learning rate\n",
        "optimizer_ft = optim.Adam(model_ft.classifier.parameters(), lr = 0.001)\n",
        "\n",
        "\n",
        "# Train and evaluate\n",
        "model_ft, hist = train_model(model_ft, dataloaders, criterion, optimizer_ft, num_epochs=num_epochs, is_inception=(model_name==\"inception\"))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/9\n",
            "----------\n",
            "train Loss: 0.5623 Acc: 0.7052\n",
            "val Loss: 0.4247 Acc: 0.8109\n",
            "\n",
            "Epoch 1/9\n",
            "----------\n",
            "train Loss: 0.4999 Acc: 0.7540\n",
            "val Loss: 0.7793 Acc: 0.5576\n",
            "\n",
            "Epoch 2/9\n",
            "----------\n",
            "train Loss: 0.4831 Acc: 0.7715\n",
            "val Loss: 0.5521 Acc: 0.7401\n",
            "\n",
            "Epoch 3/9\n",
            "----------\n",
            "train Loss: 0.4756 Acc: 0.7814\n",
            "val Loss: 0.5057 Acc: 0.7632\n",
            "\n",
            "Epoch 4/9\n",
            "----------\n",
            "train Loss: 0.4737 Acc: 0.7808\n",
            "val Loss: 0.3113 Acc: 0.8668\n",
            "\n",
            "Epoch 5/9\n",
            "----------\n",
            "train Loss: 0.4315 Acc: 0.7984\n",
            "val Loss: 0.2984 Acc: 0.8388\n",
            "\n",
            "Epoch 6/9\n",
            "----------\n",
            "train Loss: 0.4396 Acc: 0.8022\n",
            "val Loss: 0.2813 Acc: 0.8701\n",
            "\n",
            "Epoch 7/9\n",
            "----------\n",
            "train Loss: 0.4278 Acc: 0.8088\n",
            "val Loss: 0.3268 Acc: 0.8322\n",
            "\n",
            "Epoch 8/9\n",
            "----------\n",
            "train Loss: 0.4393 Acc: 0.7929\n",
            "val Loss: 0.3756 Acc: 0.8306\n",
            "\n",
            "Epoch 9/9\n",
            "----------\n",
            "train Loss: 0.4245 Acc: 0.8110\n",
            "val Loss: 0.2539 Acc: 0.8914\n",
            "\n",
            "Training complete in 85m 54s\n",
            "Best val Acc: 0.891447\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgYraiAjiys8"
      },
      "source": [
        "torch.save(model_ft,'/content/drive/MyDrive/saved_models/densenet_ordered_dict_ocular_clean.h5')"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpGRminVjRIY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "128abb98-447c-46c6-fcfe-263184d6c176"
      },
      "source": [
        "import seaborn as sns\n",
        "nb_classes = num_classes\n",
        "confusion_matrix = np.zeros((nb_classes, nb_classes))\n",
        "with torch.no_grad():\n",
        "    for i, (inputs, classes) in enumerate(dataloaders['test']):\n",
        "        inputs = inputs.to(device)\n",
        "        classes = classes.to(device)\n",
        "        outputs = model_ft(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        print (preds)\n",
        "        for t, p in zip(classes.view(-1), preds.view(-1)):\n",
        "                confusion_matrix[t.long(), p.long()] += 1\n",
        "\n",
        "plt.figure(figsize=(15,10))\n",
        "\n",
        "class_names = ['Normal', 'Glaucoma']\n",
        "df_cm = pd.DataFrame(confusion_matrix, index=class_names, columns=class_names).astype(int)\n",
        "heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
        "\n",
        "heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right',fontsize=15)\n",
        "heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right',fontsize=15)\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 1, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "tensor([0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "tensor([0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 1, 1, 0, 0, 0, 0, 1], device='cuda:0')\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 1], device='cuda:0')\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        1, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "tensor([1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "tensor([1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
            "        0, 1, 0, 1, 0, 0, 1, 0], device='cuda:0')\n",
            "tensor([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "tensor([0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 1, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "tensor([0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "tensor([0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        1, 1, 0, 1, 0, 0, 0, 0], device='cuda:0')\n",
            "tensor([0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 1, 0, 0, 0, 0, 1, 0], device='cuda:0')\n",
            "tensor([0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
            "        1, 1, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 1, 0, 0, 0, 0], device='cuda:0')\n",
            "tensor([0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 1, 0, 0, 0, 0, 0, 0], device='cuda:0')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 69.0, 'Predicted label')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x720 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EyL4HDhTKDa"
      },
      "source": [
        "confusion_matrix = np.zeros((nb_classes, nb_classes))\n",
        "with torch.no_grad():\n",
        "    for i, (inputs, classes) in enumerate(dataloaders['train']):\n",
        "        inputs = inputs.to(device)\n",
        "        classes = classes.to(device)\n",
        "        outputs = model_ft(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        for t, p in zip(classes.view(-1), preds.view(-1)):\n",
        "                confusion_matrix[t.long(), p.long()] += 1\n",
        "\n",
        "plt.figure(figsize=(15,10))\n",
        "\n",
        "class_names = ['Normal', 'Glaucoma']\n",
        "df_cm = pd.DataFrame(confusion_matrix, index=class_names, columns=class_names).astype(int)\n",
        "heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
        "\n",
        "heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right',fontsize=15)\n",
        "heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right',fontsize=15)\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pryRZOM_O64w"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}