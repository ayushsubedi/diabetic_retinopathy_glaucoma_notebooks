{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "inceptionv3_ben.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqHnaptr-kuA",
        "outputId": "d9ad81e2-ee8a-47ef-948f-c87e94f2ef6f"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon May 10 10:34:32 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   77C    P0    33W /  70W |   5682MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7-9XFsaZnKQ"
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oGJ2hstm39V"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from imutils import contours\n",
        "from skimage import measure\n",
        "import imutils\n",
        "import os\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import copy\n",
        "import time\n",
        "\n",
        "import torch\n",
        "from torchvision import datasets, models, transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader, Dataset, TensorDataset, Subset, WeightedRandomSampler\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import pickle"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u899MaWr-ZF0"
      },
      "source": [
        "# Top level data directory. Here we assume the format of the directory conforms\n",
        "#   to the ImageFolder structure\n",
        "data_dir = '/content/drive/MyDrive/disk_dataset_kaggle_2'\n",
        "\n",
        "# Models to choose from [resnet, alexnet, vgg, squeezenet, densenet, inception]\n",
        "model_name = \"inception\"\n",
        "# inception\n",
        "input_size = 299\n",
        "\n",
        "# Number of classes in the dataset\n",
        "num_classes = 2\n",
        "\n",
        "# Batch size for training (change depending on how much memory you have)\n",
        "batch_size = 32\n",
        "\n",
        "# Number of epochs to train for\n",
        "num_epochs = 10\n",
        "\n",
        "# Flag for feature extracting. When False, we finetune the whole model,\n",
        "#   when True we only update the reshaped layer params\n",
        "feature_extract = False\n",
        "\n",
        "num_workers = 2\n",
        "\n",
        "train_size = 0.60\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYnO7mxJZywE"
      },
      "source": [
        "\n",
        "class ben_color(object):\n",
        "    def __call__(self, img, sigmaX=10):\n",
        "        \"\"\"\n",
        "        :param img: PIL): Image \n",
        "\n",
        "        :return: Normalized image\n",
        "        \"\"\"\n",
        "\n",
        "        img = np.asarray(img)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        img = self.crop_image_from_gray(img)\n",
        "        img = cv2.resize(img, (input_size, input_size))\n",
        "        img = cv2.addWeighted (img, 4, cv2.GaussianBlur(img, (0,0), sigmaX), -4, 128)\n",
        "        return Image.fromarray(img)\n",
        "\n",
        "    def crop_image_from_gray(self, img, tol=7):\n",
        "        if img.ndim ==2:\n",
        "            mask = img>tol\n",
        "            return img[np.ix_(mask.any(1),mask.any(0))]\n",
        "        elif img.ndim==3:\n",
        "            gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "            mask = gray_img>tol\n",
        "            \n",
        "            check_shape = img[:,:,0][np.ix_(mask.any(1),mask.any(0))].shape[0]\n",
        "            if (check_shape == 0):\n",
        "                return img \n",
        "            else:\n",
        "                img1=img[:,:,0][np.ix_(mask.any(1),mask.any(0))]\n",
        "                img2=img[:,:,1][np.ix_(mask.any(1),mask.any(0))]\n",
        "                img3=img[:,:,2][np.ix_(mask.any(1),mask.any(0))]\n",
        "                img = np.stack([img1,img2,img3],axis=-1)\n",
        "            return img\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__+'()'"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jj74frLDrZd"
      },
      "source": [
        "# Todos: shuffle in validation set\n",
        "# add more augmentations  \n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "        ben_color(),\n",
        "        transforms.RandomRotation(degrees=(0, 360)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.Resize((input_size, input_size)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "\n",
        "\n",
        "valid_transform = transforms.Compose([\n",
        "        ben_color(),\n",
        "        transforms.Resize((input_size, input_size)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "\n",
        "\n",
        "class DR(Dataset):\n",
        "    def __init__(self, dataset, transform=None):\n",
        "        self.dataset = dataset\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        if self.transform:\n",
        "            x = self.transform(dataset[index][0])\n",
        "        else:\n",
        "            x = dataset[index][0]\n",
        "        y = dataset[index][1]\n",
        "        return x, y\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(dataset)\n",
        "    \n",
        "\n",
        "dataset = ImageFolder(data_dir)\n",
        "\n",
        "traindataset = DR(dataset, train_transform)\n",
        "valdataset = DR(dataset, valid_transform)\n",
        "testdataset = DR(dataset, valid_transform)\n",
        "\n",
        "# Create the index splits for training, validation and test\n",
        "\n",
        "num_train = len(dataset)\n",
        "indices = list(range(num_train))\n",
        "split = int(np.floor(train_size * num_train))\n",
        "split2 = int(np.floor((train_size+(1-train_size)/2) * num_train))\n",
        "np.random.shuffle(indices)\n",
        "train_idx, valid_idx, test_idx = indices[:split], indices[split:split2], indices[split2:]\n",
        "\n",
        "traindata = Subset(traindataset, indices=train_idx)\n",
        "valdata = Subset(valdataset, indices=valid_idx)\n",
        "testdata = Subset(testdataset, indices=test_idx)\n",
        "\n",
        "class_weights = []\n",
        "for root, subdir, files in os.walk(data_dir):\n",
        "  if len(files)>0:\n",
        "    class_weights.append(1/len(files))\n",
        "\n",
        "sample_weights = [0] * len(traindata)\n",
        "\n",
        "for idx, (data, label) in enumerate(traindata):\n",
        "  class_weight = class_weights[label]\n",
        "  sample_weights[idx] = class_weight\n",
        "\n",
        "\n",
        "with open('/content/drive/MyDrive/clean_weights.pkl', 'wb') as f:\n",
        "  pickle.dump(sample_weights, f)\n",
        "\n",
        "with open('/content/drive/MyDrive/clean_weights.pkl', 'rb') as f:\n",
        "  sample_weights = pickle.load(f)\n",
        "\n",
        "sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)\n",
        "\n",
        "trainLoader = torch.utils.data.DataLoader(traindata, sampler=sampler, batch_size=batch_size, \n",
        "                                          num_workers=num_workers, drop_last=True)\n",
        "valLoader = torch.utils.data.DataLoader(valdata, batch_size=batch_size, \n",
        "                                          num_workers=num_workers, drop_last=True)\n",
        "testLoader = torch.utils.data.DataLoader(testdata, batch_size=batch_size,\n",
        "                                          num_workers=num_workers, drop_last=True)\n",
        "dataloaders = {'train': trainLoader, 'val': valLoader, 'test': testLoader}"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyThMaR4nbLF"
      },
      "source": [
        "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False):\n",
        "    since = time.time()\n",
        "\n",
        "    val_acc_history = []\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    # Get model outputs and calculate loss\n",
        "                    # Special case for inception because in training it has an auxiliary output. In train\n",
        "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
        "                    #   but in testing we only consider the final output.\n",
        "                    if is_inception and phase == 'train':\n",
        "                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
        "                        outputs, aux_outputs = model(inputs)\n",
        "                        loss1 = criterion(outputs, labels)\n",
        "                        loss2 = criterion(aux_outputs, labels)\n",
        "                        loss = loss1 + 0.4*loss2\n",
        "                    else:\n",
        "                        outputs = model(inputs)\n",
        "                        loss = criterion(outputs, labels)\n",
        "\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
        "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            if phase == 'val':\n",
        "                val_acc_history.append(epoch_acc)\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, val_acc_history"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75VdlQ8ln1a9"
      },
      "source": [
        "def set_parameter_requires_grad(model, feature_extracting):\n",
        "    if feature_extracting:\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4O8Uqptn8Sb",
        "outputId": "a9ef53bb-9c54-4d56-cf29-e4a239aebf6a"
      },
      "source": [
        "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
        "    # Initialize these variables which will be set in this if statement. Each of these\n",
        "    #   variables is model specific.\n",
        "    model_ft = None\n",
        "    input_size = 0\n",
        "\n",
        "    if model_name == \"resnet\":\n",
        "        \"\"\" Resnet18\n",
        "        \"\"\"\n",
        "        model_ft = models.resnet18(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.fc.in_features\n",
        "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"alexnet\":\n",
        "        \"\"\" Alexnet\n",
        "        \"\"\"\n",
        "        model_ft = models.alexnet(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.classifier[6].in_features\n",
        "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"vgg\":\n",
        "        \"\"\" VGG11_bn\n",
        "        \"\"\"\n",
        "        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.classifier[6].in_features\n",
        "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"squeezenet\":\n",
        "        \"\"\" Squeezenet\n",
        "        \"\"\"\n",
        "        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
        "        model_ft.num_classes = num_classes\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"densenet\":\n",
        "        \"\"\" Densenet\n",
        "        \"\"\"\n",
        "        model_ft = models.densenet121(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.classifier.in_features\n",
        "        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"inception\":\n",
        "        \"\"\" Inception v3\n",
        "        Be careful, expects (299,299) sized images and has auxiliary output\n",
        "        \"\"\"\n",
        "        model_ft = models.inception_v3(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        # Handle the auxilary net\n",
        "        num_ftrs = model_ft.AuxLogits.fc.in_features\n",
        "        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n",
        "        # Handle the primary net\n",
        "        num_ftrs = model_ft.fc.in_features\n",
        "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
        "        input_size = 299\n",
        "\n",
        "    else:\n",
        "        print(\"Invalid model name, exiting...\")\n",
        "        exit()\n",
        "\n",
        "    return model_ft, input_size\n",
        "\n",
        "# Initialize the model for this run\n",
        "model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n",
        "\n",
        "# Print the model we just instantiated\n",
        "print(model_ft)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Inception3(\n",
            "  (Conv2d_1a_3x3): BasicConv2d(\n",
            "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
            "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (Conv2d_2a_3x3): BasicConv2d(\n",
            "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (Conv2d_2b_3x3): BasicConv2d(\n",
            "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (Conv2d_3b_1x1): BasicConv2d(\n",
            "    (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (Conv2d_4a_3x3): BasicConv2d(\n",
            "    (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (Mixed_5b): InceptionA(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_1): BasicConv2d(\n",
            "      (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_2): BasicConv2d(\n",
            "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_5c): InceptionA(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_1): BasicConv2d(\n",
            "      (conv): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_2): BasicConv2d(\n",
            "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_5d): InceptionA(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_1): BasicConv2d(\n",
            "      (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_2): BasicConv2d(\n",
            "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_6a): InceptionB(\n",
            "    (branch3x3): BasicConv2d(\n",
            "      (conv): Conv2d(288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_6b): InceptionC(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_2): BasicConv2d(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_3): BasicConv2d(\n",
            "      (conv): Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_4): BasicConv2d(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_5): BasicConv2d(\n",
            "      (conv): Conv2d(128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_6c): InceptionC(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_2): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_3): BasicConv2d(\n",
            "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_4): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_5): BasicConv2d(\n",
            "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_6d): InceptionC(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_2): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_3): BasicConv2d(\n",
            "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_4): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_5): BasicConv2d(\n",
            "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_6e): InceptionC(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_2): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_3): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_4): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_5): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (AuxLogits): InceptionAux(\n",
            "    (conv0): BasicConv2d(\n",
            "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (conv1): BasicConv2d(\n",
            "      (conv): Conv2d(128, 768, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fc): Linear(in_features=768, out_features=2, bias=True)\n",
            "  )\n",
            "  (Mixed_7a): InceptionD(\n",
            "    (branch3x3_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_2): BasicConv2d(\n",
            "      (conv): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7x3_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7x3_2): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7x3_3): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7x3_4): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_7b): InceptionE(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_1): BasicConv2d(\n",
            "      (conv): Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_2a): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_2b): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3a): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3b): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_7c): InceptionE(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_1): BasicConv2d(\n",
            "      (conv): Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_2a): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_2b): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3a): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3b): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (fc): Linear(in_features=2048, out_features=2, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6151ULNdzuq",
        "outputId": "3c79b97c-853f-483a-b625-f993ff7820b0"
      },
      "source": [
        "# Send the model to GPU\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "# Gather the parameters to be optimized/updated in this run. If we are\n",
        "#  finetuning we will be updating all parameters. However, if we are\n",
        "#  doing feature extract method, we will only update the parameters\n",
        "#  that we have just initialized, i.e. the parameters with requires_grad\n",
        "#  is True.\n",
        "params_to_update = model_ft.parameters()\n",
        "print(\"Params to learn:\")\n",
        "if feature_extract:\n",
        "    params_to_update = []\n",
        "    for name,param in model_ft.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            params_to_update.append(param)\n",
        "            print(\"\\t\",name)\n",
        "else:\n",
        "    for name,param in model_ft.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            print(\"\\t\",name)\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Params to learn:\n",
            "\t Conv2d_1a_3x3.conv.weight\n",
            "\t Conv2d_1a_3x3.bn.weight\n",
            "\t Conv2d_1a_3x3.bn.bias\n",
            "\t Conv2d_2a_3x3.conv.weight\n",
            "\t Conv2d_2a_3x3.bn.weight\n",
            "\t Conv2d_2a_3x3.bn.bias\n",
            "\t Conv2d_2b_3x3.conv.weight\n",
            "\t Conv2d_2b_3x3.bn.weight\n",
            "\t Conv2d_2b_3x3.bn.bias\n",
            "\t Conv2d_3b_1x1.conv.weight\n",
            "\t Conv2d_3b_1x1.bn.weight\n",
            "\t Conv2d_3b_1x1.bn.bias\n",
            "\t Conv2d_4a_3x3.conv.weight\n",
            "\t Conv2d_4a_3x3.bn.weight\n",
            "\t Conv2d_4a_3x3.bn.bias\n",
            "\t Mixed_5b.branch1x1.conv.weight\n",
            "\t Mixed_5b.branch1x1.bn.weight\n",
            "\t Mixed_5b.branch1x1.bn.bias\n",
            "\t Mixed_5b.branch5x5_1.conv.weight\n",
            "\t Mixed_5b.branch5x5_1.bn.weight\n",
            "\t Mixed_5b.branch5x5_1.bn.bias\n",
            "\t Mixed_5b.branch5x5_2.conv.weight\n",
            "\t Mixed_5b.branch5x5_2.bn.weight\n",
            "\t Mixed_5b.branch5x5_2.bn.bias\n",
            "\t Mixed_5b.branch3x3dbl_1.conv.weight\n",
            "\t Mixed_5b.branch3x3dbl_1.bn.weight\n",
            "\t Mixed_5b.branch3x3dbl_1.bn.bias\n",
            "\t Mixed_5b.branch3x3dbl_2.conv.weight\n",
            "\t Mixed_5b.branch3x3dbl_2.bn.weight\n",
            "\t Mixed_5b.branch3x3dbl_2.bn.bias\n",
            "\t Mixed_5b.branch3x3dbl_3.conv.weight\n",
            "\t Mixed_5b.branch3x3dbl_3.bn.weight\n",
            "\t Mixed_5b.branch3x3dbl_3.bn.bias\n",
            "\t Mixed_5b.branch_pool.conv.weight\n",
            "\t Mixed_5b.branch_pool.bn.weight\n",
            "\t Mixed_5b.branch_pool.bn.bias\n",
            "\t Mixed_5c.branch1x1.conv.weight\n",
            "\t Mixed_5c.branch1x1.bn.weight\n",
            "\t Mixed_5c.branch1x1.bn.bias\n",
            "\t Mixed_5c.branch5x5_1.conv.weight\n",
            "\t Mixed_5c.branch5x5_1.bn.weight\n",
            "\t Mixed_5c.branch5x5_1.bn.bias\n",
            "\t Mixed_5c.branch5x5_2.conv.weight\n",
            "\t Mixed_5c.branch5x5_2.bn.weight\n",
            "\t Mixed_5c.branch5x5_2.bn.bias\n",
            "\t Mixed_5c.branch3x3dbl_1.conv.weight\n",
            "\t Mixed_5c.branch3x3dbl_1.bn.weight\n",
            "\t Mixed_5c.branch3x3dbl_1.bn.bias\n",
            "\t Mixed_5c.branch3x3dbl_2.conv.weight\n",
            "\t Mixed_5c.branch3x3dbl_2.bn.weight\n",
            "\t Mixed_5c.branch3x3dbl_2.bn.bias\n",
            "\t Mixed_5c.branch3x3dbl_3.conv.weight\n",
            "\t Mixed_5c.branch3x3dbl_3.bn.weight\n",
            "\t Mixed_5c.branch3x3dbl_3.bn.bias\n",
            "\t Mixed_5c.branch_pool.conv.weight\n",
            "\t Mixed_5c.branch_pool.bn.weight\n",
            "\t Mixed_5c.branch_pool.bn.bias\n",
            "\t Mixed_5d.branch1x1.conv.weight\n",
            "\t Mixed_5d.branch1x1.bn.weight\n",
            "\t Mixed_5d.branch1x1.bn.bias\n",
            "\t Mixed_5d.branch5x5_1.conv.weight\n",
            "\t Mixed_5d.branch5x5_1.bn.weight\n",
            "\t Mixed_5d.branch5x5_1.bn.bias\n",
            "\t Mixed_5d.branch5x5_2.conv.weight\n",
            "\t Mixed_5d.branch5x5_2.bn.weight\n",
            "\t Mixed_5d.branch5x5_2.bn.bias\n",
            "\t Mixed_5d.branch3x3dbl_1.conv.weight\n",
            "\t Mixed_5d.branch3x3dbl_1.bn.weight\n",
            "\t Mixed_5d.branch3x3dbl_1.bn.bias\n",
            "\t Mixed_5d.branch3x3dbl_2.conv.weight\n",
            "\t Mixed_5d.branch3x3dbl_2.bn.weight\n",
            "\t Mixed_5d.branch3x3dbl_2.bn.bias\n",
            "\t Mixed_5d.branch3x3dbl_3.conv.weight\n",
            "\t Mixed_5d.branch3x3dbl_3.bn.weight\n",
            "\t Mixed_5d.branch3x3dbl_3.bn.bias\n",
            "\t Mixed_5d.branch_pool.conv.weight\n",
            "\t Mixed_5d.branch_pool.bn.weight\n",
            "\t Mixed_5d.branch_pool.bn.bias\n",
            "\t Mixed_6a.branch3x3.conv.weight\n",
            "\t Mixed_6a.branch3x3.bn.weight\n",
            "\t Mixed_6a.branch3x3.bn.bias\n",
            "\t Mixed_6a.branch3x3dbl_1.conv.weight\n",
            "\t Mixed_6a.branch3x3dbl_1.bn.weight\n",
            "\t Mixed_6a.branch3x3dbl_1.bn.bias\n",
            "\t Mixed_6a.branch3x3dbl_2.conv.weight\n",
            "\t Mixed_6a.branch3x3dbl_2.bn.weight\n",
            "\t Mixed_6a.branch3x3dbl_2.bn.bias\n",
            "\t Mixed_6a.branch3x3dbl_3.conv.weight\n",
            "\t Mixed_6a.branch3x3dbl_3.bn.weight\n",
            "\t Mixed_6a.branch3x3dbl_3.bn.bias\n",
            "\t Mixed_6b.branch1x1.conv.weight\n",
            "\t Mixed_6b.branch1x1.bn.weight\n",
            "\t Mixed_6b.branch1x1.bn.bias\n",
            "\t Mixed_6b.branch7x7_1.conv.weight\n",
            "\t Mixed_6b.branch7x7_1.bn.weight\n",
            "\t Mixed_6b.branch7x7_1.bn.bias\n",
            "\t Mixed_6b.branch7x7_2.conv.weight\n",
            "\t Mixed_6b.branch7x7_2.bn.weight\n",
            "\t Mixed_6b.branch7x7_2.bn.bias\n",
            "\t Mixed_6b.branch7x7_3.conv.weight\n",
            "\t Mixed_6b.branch7x7_3.bn.weight\n",
            "\t Mixed_6b.branch7x7_3.bn.bias\n",
            "\t Mixed_6b.branch7x7dbl_1.conv.weight\n",
            "\t Mixed_6b.branch7x7dbl_1.bn.weight\n",
            "\t Mixed_6b.branch7x7dbl_1.bn.bias\n",
            "\t Mixed_6b.branch7x7dbl_2.conv.weight\n",
            "\t Mixed_6b.branch7x7dbl_2.bn.weight\n",
            "\t Mixed_6b.branch7x7dbl_2.bn.bias\n",
            "\t Mixed_6b.branch7x7dbl_3.conv.weight\n",
            "\t Mixed_6b.branch7x7dbl_3.bn.weight\n",
            "\t Mixed_6b.branch7x7dbl_3.bn.bias\n",
            "\t Mixed_6b.branch7x7dbl_4.conv.weight\n",
            "\t Mixed_6b.branch7x7dbl_4.bn.weight\n",
            "\t Mixed_6b.branch7x7dbl_4.bn.bias\n",
            "\t Mixed_6b.branch7x7dbl_5.conv.weight\n",
            "\t Mixed_6b.branch7x7dbl_5.bn.weight\n",
            "\t Mixed_6b.branch7x7dbl_5.bn.bias\n",
            "\t Mixed_6b.branch_pool.conv.weight\n",
            "\t Mixed_6b.branch_pool.bn.weight\n",
            "\t Mixed_6b.branch_pool.bn.bias\n",
            "\t Mixed_6c.branch1x1.conv.weight\n",
            "\t Mixed_6c.branch1x1.bn.weight\n",
            "\t Mixed_6c.branch1x1.bn.bias\n",
            "\t Mixed_6c.branch7x7_1.conv.weight\n",
            "\t Mixed_6c.branch7x7_1.bn.weight\n",
            "\t Mixed_6c.branch7x7_1.bn.bias\n",
            "\t Mixed_6c.branch7x7_2.conv.weight\n",
            "\t Mixed_6c.branch7x7_2.bn.weight\n",
            "\t Mixed_6c.branch7x7_2.bn.bias\n",
            "\t Mixed_6c.branch7x7_3.conv.weight\n",
            "\t Mixed_6c.branch7x7_3.bn.weight\n",
            "\t Mixed_6c.branch7x7_3.bn.bias\n",
            "\t Mixed_6c.branch7x7dbl_1.conv.weight\n",
            "\t Mixed_6c.branch7x7dbl_1.bn.weight\n",
            "\t Mixed_6c.branch7x7dbl_1.bn.bias\n",
            "\t Mixed_6c.branch7x7dbl_2.conv.weight\n",
            "\t Mixed_6c.branch7x7dbl_2.bn.weight\n",
            "\t Mixed_6c.branch7x7dbl_2.bn.bias\n",
            "\t Mixed_6c.branch7x7dbl_3.conv.weight\n",
            "\t Mixed_6c.branch7x7dbl_3.bn.weight\n",
            "\t Mixed_6c.branch7x7dbl_3.bn.bias\n",
            "\t Mixed_6c.branch7x7dbl_4.conv.weight\n",
            "\t Mixed_6c.branch7x7dbl_4.bn.weight\n",
            "\t Mixed_6c.branch7x7dbl_4.bn.bias\n",
            "\t Mixed_6c.branch7x7dbl_5.conv.weight\n",
            "\t Mixed_6c.branch7x7dbl_5.bn.weight\n",
            "\t Mixed_6c.branch7x7dbl_5.bn.bias\n",
            "\t Mixed_6c.branch_pool.conv.weight\n",
            "\t Mixed_6c.branch_pool.bn.weight\n",
            "\t Mixed_6c.branch_pool.bn.bias\n",
            "\t Mixed_6d.branch1x1.conv.weight\n",
            "\t Mixed_6d.branch1x1.bn.weight\n",
            "\t Mixed_6d.branch1x1.bn.bias\n",
            "\t Mixed_6d.branch7x7_1.conv.weight\n",
            "\t Mixed_6d.branch7x7_1.bn.weight\n",
            "\t Mixed_6d.branch7x7_1.bn.bias\n",
            "\t Mixed_6d.branch7x7_2.conv.weight\n",
            "\t Mixed_6d.branch7x7_2.bn.weight\n",
            "\t Mixed_6d.branch7x7_2.bn.bias\n",
            "\t Mixed_6d.branch7x7_3.conv.weight\n",
            "\t Mixed_6d.branch7x7_3.bn.weight\n",
            "\t Mixed_6d.branch7x7_3.bn.bias\n",
            "\t Mixed_6d.branch7x7dbl_1.conv.weight\n",
            "\t Mixed_6d.branch7x7dbl_1.bn.weight\n",
            "\t Mixed_6d.branch7x7dbl_1.bn.bias\n",
            "\t Mixed_6d.branch7x7dbl_2.conv.weight\n",
            "\t Mixed_6d.branch7x7dbl_2.bn.weight\n",
            "\t Mixed_6d.branch7x7dbl_2.bn.bias\n",
            "\t Mixed_6d.branch7x7dbl_3.conv.weight\n",
            "\t Mixed_6d.branch7x7dbl_3.bn.weight\n",
            "\t Mixed_6d.branch7x7dbl_3.bn.bias\n",
            "\t Mixed_6d.branch7x7dbl_4.conv.weight\n",
            "\t Mixed_6d.branch7x7dbl_4.bn.weight\n",
            "\t Mixed_6d.branch7x7dbl_4.bn.bias\n",
            "\t Mixed_6d.branch7x7dbl_5.conv.weight\n",
            "\t Mixed_6d.branch7x7dbl_5.bn.weight\n",
            "\t Mixed_6d.branch7x7dbl_5.bn.bias\n",
            "\t Mixed_6d.branch_pool.conv.weight\n",
            "\t Mixed_6d.branch_pool.bn.weight\n",
            "\t Mixed_6d.branch_pool.bn.bias\n",
            "\t Mixed_6e.branch1x1.conv.weight\n",
            "\t Mixed_6e.branch1x1.bn.weight\n",
            "\t Mixed_6e.branch1x1.bn.bias\n",
            "\t Mixed_6e.branch7x7_1.conv.weight\n",
            "\t Mixed_6e.branch7x7_1.bn.weight\n",
            "\t Mixed_6e.branch7x7_1.bn.bias\n",
            "\t Mixed_6e.branch7x7_2.conv.weight\n",
            "\t Mixed_6e.branch7x7_2.bn.weight\n",
            "\t Mixed_6e.branch7x7_2.bn.bias\n",
            "\t Mixed_6e.branch7x7_3.conv.weight\n",
            "\t Mixed_6e.branch7x7_3.bn.weight\n",
            "\t Mixed_6e.branch7x7_3.bn.bias\n",
            "\t Mixed_6e.branch7x7dbl_1.conv.weight\n",
            "\t Mixed_6e.branch7x7dbl_1.bn.weight\n",
            "\t Mixed_6e.branch7x7dbl_1.bn.bias\n",
            "\t Mixed_6e.branch7x7dbl_2.conv.weight\n",
            "\t Mixed_6e.branch7x7dbl_2.bn.weight\n",
            "\t Mixed_6e.branch7x7dbl_2.bn.bias\n",
            "\t Mixed_6e.branch7x7dbl_3.conv.weight\n",
            "\t Mixed_6e.branch7x7dbl_3.bn.weight\n",
            "\t Mixed_6e.branch7x7dbl_3.bn.bias\n",
            "\t Mixed_6e.branch7x7dbl_4.conv.weight\n",
            "\t Mixed_6e.branch7x7dbl_4.bn.weight\n",
            "\t Mixed_6e.branch7x7dbl_4.bn.bias\n",
            "\t Mixed_6e.branch7x7dbl_5.conv.weight\n",
            "\t Mixed_6e.branch7x7dbl_5.bn.weight\n",
            "\t Mixed_6e.branch7x7dbl_5.bn.bias\n",
            "\t Mixed_6e.branch_pool.conv.weight\n",
            "\t Mixed_6e.branch_pool.bn.weight\n",
            "\t Mixed_6e.branch_pool.bn.bias\n",
            "\t AuxLogits.conv0.conv.weight\n",
            "\t AuxLogits.conv0.bn.weight\n",
            "\t AuxLogits.conv0.bn.bias\n",
            "\t AuxLogits.conv1.conv.weight\n",
            "\t AuxLogits.conv1.bn.weight\n",
            "\t AuxLogits.conv1.bn.bias\n",
            "\t AuxLogits.fc.weight\n",
            "\t AuxLogits.fc.bias\n",
            "\t Mixed_7a.branch3x3_1.conv.weight\n",
            "\t Mixed_7a.branch3x3_1.bn.weight\n",
            "\t Mixed_7a.branch3x3_1.bn.bias\n",
            "\t Mixed_7a.branch3x3_2.conv.weight\n",
            "\t Mixed_7a.branch3x3_2.bn.weight\n",
            "\t Mixed_7a.branch3x3_2.bn.bias\n",
            "\t Mixed_7a.branch7x7x3_1.conv.weight\n",
            "\t Mixed_7a.branch7x7x3_1.bn.weight\n",
            "\t Mixed_7a.branch7x7x3_1.bn.bias\n",
            "\t Mixed_7a.branch7x7x3_2.conv.weight\n",
            "\t Mixed_7a.branch7x7x3_2.bn.weight\n",
            "\t Mixed_7a.branch7x7x3_2.bn.bias\n",
            "\t Mixed_7a.branch7x7x3_3.conv.weight\n",
            "\t Mixed_7a.branch7x7x3_3.bn.weight\n",
            "\t Mixed_7a.branch7x7x3_3.bn.bias\n",
            "\t Mixed_7a.branch7x7x3_4.conv.weight\n",
            "\t Mixed_7a.branch7x7x3_4.bn.weight\n",
            "\t Mixed_7a.branch7x7x3_4.bn.bias\n",
            "\t Mixed_7b.branch1x1.conv.weight\n",
            "\t Mixed_7b.branch1x1.bn.weight\n",
            "\t Mixed_7b.branch1x1.bn.bias\n",
            "\t Mixed_7b.branch3x3_1.conv.weight\n",
            "\t Mixed_7b.branch3x3_1.bn.weight\n",
            "\t Mixed_7b.branch3x3_1.bn.bias\n",
            "\t Mixed_7b.branch3x3_2a.conv.weight\n",
            "\t Mixed_7b.branch3x3_2a.bn.weight\n",
            "\t Mixed_7b.branch3x3_2a.bn.bias\n",
            "\t Mixed_7b.branch3x3_2b.conv.weight\n",
            "\t Mixed_7b.branch3x3_2b.bn.weight\n",
            "\t Mixed_7b.branch3x3_2b.bn.bias\n",
            "\t Mixed_7b.branch3x3dbl_1.conv.weight\n",
            "\t Mixed_7b.branch3x3dbl_1.bn.weight\n",
            "\t Mixed_7b.branch3x3dbl_1.bn.bias\n",
            "\t Mixed_7b.branch3x3dbl_2.conv.weight\n",
            "\t Mixed_7b.branch3x3dbl_2.bn.weight\n",
            "\t Mixed_7b.branch3x3dbl_2.bn.bias\n",
            "\t Mixed_7b.branch3x3dbl_3a.conv.weight\n",
            "\t Mixed_7b.branch3x3dbl_3a.bn.weight\n",
            "\t Mixed_7b.branch3x3dbl_3a.bn.bias\n",
            "\t Mixed_7b.branch3x3dbl_3b.conv.weight\n",
            "\t Mixed_7b.branch3x3dbl_3b.bn.weight\n",
            "\t Mixed_7b.branch3x3dbl_3b.bn.bias\n",
            "\t Mixed_7b.branch_pool.conv.weight\n",
            "\t Mixed_7b.branch_pool.bn.weight\n",
            "\t Mixed_7b.branch_pool.bn.bias\n",
            "\t Mixed_7c.branch1x1.conv.weight\n",
            "\t Mixed_7c.branch1x1.bn.weight\n",
            "\t Mixed_7c.branch1x1.bn.bias\n",
            "\t Mixed_7c.branch3x3_1.conv.weight\n",
            "\t Mixed_7c.branch3x3_1.bn.weight\n",
            "\t Mixed_7c.branch3x3_1.bn.bias\n",
            "\t Mixed_7c.branch3x3_2a.conv.weight\n",
            "\t Mixed_7c.branch3x3_2a.bn.weight\n",
            "\t Mixed_7c.branch3x3_2a.bn.bias\n",
            "\t Mixed_7c.branch3x3_2b.conv.weight\n",
            "\t Mixed_7c.branch3x3_2b.bn.weight\n",
            "\t Mixed_7c.branch3x3_2b.bn.bias\n",
            "\t Mixed_7c.branch3x3dbl_1.conv.weight\n",
            "\t Mixed_7c.branch3x3dbl_1.bn.weight\n",
            "\t Mixed_7c.branch3x3dbl_1.bn.bias\n",
            "\t Mixed_7c.branch3x3dbl_2.conv.weight\n",
            "\t Mixed_7c.branch3x3dbl_2.bn.weight\n",
            "\t Mixed_7c.branch3x3dbl_2.bn.bias\n",
            "\t Mixed_7c.branch3x3dbl_3a.conv.weight\n",
            "\t Mixed_7c.branch3x3dbl_3a.bn.weight\n",
            "\t Mixed_7c.branch3x3dbl_3a.bn.bias\n",
            "\t Mixed_7c.branch3x3dbl_3b.conv.weight\n",
            "\t Mixed_7c.branch3x3dbl_3b.bn.weight\n",
            "\t Mixed_7c.branch3x3dbl_3b.bn.bias\n",
            "\t Mixed_7c.branch_pool.conv.weight\n",
            "\t Mixed_7c.branch_pool.bn.weight\n",
            "\t Mixed_7c.branch_pool.bn.bias\n",
            "\t fc.weight\n",
            "\t fc.bias\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXg5BAG1oo-f",
        "outputId": "ba5c3b2f-1c42-477e-c653-48571401d97b"
      },
      "source": [
        "# Setup the loss fxn\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Train and evaluate\n",
        "model_ft, hist = train_model(model_ft, dataloaders, criterion, optimizer_ft, num_epochs=num_epochs, is_inception=(model_name==\"inception\"))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/9\n",
            "----------\n",
            "train Loss: 0.3382 Acc: 0.9306\n",
            "val Loss: 1.2231 Acc: 0.7385\n",
            "\n",
            "Epoch 1/9\n",
            "----------\n",
            "train Loss: 0.0099 Acc: 0.9871\n",
            "val Loss: 1.6908 Acc: 0.7385\n",
            "\n",
            "Epoch 2/9\n",
            "----------\n",
            "train Loss: 0.0028 Acc: 0.9871\n",
            "val Loss: 1.8355 Acc: 0.7385\n",
            "\n",
            "Epoch 3/9\n",
            "----------\n",
            "train Loss: 0.0017 Acc: 0.9871\n",
            "val Loss: 1.8669 Acc: 0.7385\n",
            "\n",
            "Epoch 4/9\n",
            "----------\n",
            "train Loss: 0.0016 Acc: 0.9871\n",
            "val Loss: 1.8826 Acc: 0.7385\n",
            "\n",
            "Epoch 5/9\n",
            "----------\n",
            "train Loss: 0.0545 Acc: 0.9820\n",
            "val Loss: 1.8938 Acc: 0.7385\n",
            "\n",
            "Epoch 6/9\n",
            "----------\n",
            "train Loss: 0.0327 Acc: 0.9846\n",
            "val Loss: 1.8870 Acc: 0.7385\n",
            "\n",
            "Epoch 7/9\n",
            "----------\n",
            "train Loss: 0.0016 Acc: 0.9871\n",
            "val Loss: 1.8915 Acc: 0.7385\n",
            "\n",
            "Epoch 8/9\n",
            "----------\n",
            "train Loss: 0.0017 Acc: 0.9871\n",
            "val Loss: 1.8840 Acc: 0.7385\n",
            "\n",
            "Epoch 9/9\n",
            "----------\n",
            "train Loss: 0.0537 Acc: 0.9820\n",
            "val Loss: 1.8809 Acc: 0.7385\n",
            "\n",
            "Training complete in 2m 15s\n",
            "Best val Acc: 0.738462\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgYraiAjiys8"
      },
      "source": [
        "torch.save(model_ft,'/content/drive/MyDrive/saved_models/kaggle_recropped_disk.h5')"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpGRminVjRIY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "outputId": "1e0545a2-ae1f-4036-bf67-015276ab9120"
      },
      "source": [
        "import seaborn as sns\n",
        "nb_classes = num_classes\n",
        "confusion_matrix = np.zeros((nb_classes, nb_classes))\n",
        "with torch.no_grad():\n",
        "    for i, (inputs, classes) in enumerate(dataloaders['test']):\n",
        "        inputs = inputs.to(device)\n",
        "        classes = classes.to(device)\n",
        "        outputs = model_ft(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        for t, p in zip(classes.view(-1), preds.view(-1)):\n",
        "                confusion_matrix[t.long(), p.long()] += 1\n",
        "\n",
        "plt.figure(figsize=(15,10))\n",
        "\n",
        "class_names = ['Normal', 'Glaucoma']\n",
        "df_cm = pd.DataFrame(confusion_matrix, index=class_names, columns=class_names).astype(int)\n",
        "heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
        "\n",
        "heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right',fontsize=15)\n",
        "heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right',fontsize=15)\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 69.0, 'Predicted label')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x720 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EyL4HDhTKDa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "outputId": "45561bfa-223b-4db1-ec69-0de899b0f2f2"
      },
      "source": [
        "confusion_matrix = np.zeros((nb_classes, nb_classes))\n",
        "with torch.no_grad():\n",
        "    for i, (inputs, classes) in enumerate(dataloaders['train']):\n",
        "        inputs = inputs.to(device)\n",
        "        classes = classes.to(device)\n",
        "        outputs = model_ft(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        for t, p in zip(classes.view(-1), preds.view(-1)):\n",
        "                confusion_matrix[t.long(), p.long()] += 1\n",
        "\n",
        "plt.figure(figsize=(15,10))\n",
        "\n",
        "class_names = ['Normal', 'Glaucoma']\n",
        "df_cm = pd.DataFrame(confusion_matrix, index=class_names, columns=class_names).astype(int)\n",
        "heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
        "\n",
        "heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right',fontsize=15)\n",
        "heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right',fontsize=15)\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 69.0, 'Predicted label')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x720 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}