{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "inceptionv3_ben.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqHnaptr-kuA",
        "outputId": "31d35f54-629b-4695-a3c8-5fcd1aba221f"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon May 10 10:44:45 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   77C    P0    34W /  70W |   5682MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7-9XFsaZnKQ"
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oGJ2hstm39V"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from imutils import contours\n",
        "from skimage import measure\n",
        "import imutils\n",
        "import os\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import copy\n",
        "import time\n",
        "\n",
        "import torch\n",
        "from torchvision import datasets, models, transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader, Dataset, TensorDataset, Subset, WeightedRandomSampler\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import pickle"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u899MaWr-ZF0"
      },
      "source": [
        "# Top level data directory. Here we assume the format of the directory conforms\n",
        "#   to the ImageFolder structure\n",
        "data_dir = '/content/drive/MyDrive/disk_dataset_ocular_0'\n",
        "\n",
        "# Models to choose from [resnet, alexnet, vgg, squeezenet, densenet, inception]\n",
        "model_name = \"inception\"\n",
        "# inception\n",
        "input_size = 299\n",
        "\n",
        "# Number of classes in the dataset\n",
        "num_classes = 2\n",
        "\n",
        "# Batch size for training (change depending on how much memory you have)\n",
        "batch_size = 32\n",
        "\n",
        "# Number of epochs to train for\n",
        "num_epochs = 10\n",
        "\n",
        "# Flag for feature extracting. When False, we finetune the whole model,\n",
        "#   when True we only update the reshaped layer params\n",
        "feature_extract = False\n",
        "\n",
        "num_workers = 2\n",
        "\n",
        "train_size = 0.60\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYnO7mxJZywE"
      },
      "source": [
        "\n",
        "class ben_color(object):\n",
        "    def __call__(self, img, sigmaX=10):\n",
        "        \"\"\"\n",
        "        :param img: PIL): Image \n",
        "\n",
        "        :return: Normalized image\n",
        "        \"\"\"\n",
        "\n",
        "        img = np.asarray(img)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        img = self.crop_image_from_gray(img)\n",
        "        img = cv2.resize(img, (input_size, input_size))\n",
        "        img = cv2.addWeighted (img, 4, cv2.GaussianBlur(img, (0,0), sigmaX), -4, 128)\n",
        "        return Image.fromarray(img)\n",
        "\n",
        "    def crop_image_from_gray(self, img, tol=7):\n",
        "        if img.ndim ==2:\n",
        "            mask = img>tol\n",
        "            return img[np.ix_(mask.any(1),mask.any(0))]\n",
        "        elif img.ndim==3:\n",
        "            gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "            mask = gray_img>tol\n",
        "            \n",
        "            check_shape = img[:,:,0][np.ix_(mask.any(1),mask.any(0))].shape[0]\n",
        "            if (check_shape == 0):\n",
        "                return img \n",
        "            else:\n",
        "                img1=img[:,:,0][np.ix_(mask.any(1),mask.any(0))]\n",
        "                img2=img[:,:,1][np.ix_(mask.any(1),mask.any(0))]\n",
        "                img3=img[:,:,2][np.ix_(mask.any(1),mask.any(0))]\n",
        "                img = np.stack([img1,img2,img3],axis=-1)\n",
        "            return img\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__+'()'"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jj74frLDrZd"
      },
      "source": [
        "# Todos: shuffle in validation set\n",
        "# add more augmentations  \n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "        ben_color(),\n",
        "        transforms.RandomRotation(degrees=(0, 360)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.Resize((input_size, input_size)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "\n",
        "\n",
        "valid_transform = transforms.Compose([\n",
        "        ben_color(),\n",
        "        transforms.Resize((input_size, input_size)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "\n",
        "\n",
        "class DR(Dataset):\n",
        "    def __init__(self, dataset, transform=None):\n",
        "        self.dataset = dataset\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        if self.transform:\n",
        "            x = self.transform(dataset[index][0])\n",
        "        else:\n",
        "            x = dataset[index][0]\n",
        "        y = dataset[index][1]\n",
        "        return x, y\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(dataset)\n",
        "    \n",
        "\n",
        "dataset = ImageFolder(data_dir)\n",
        "\n",
        "traindataset = DR(dataset, train_transform)\n",
        "valdataset = DR(dataset, valid_transform)\n",
        "testdataset = DR(dataset, valid_transform)\n",
        "\n",
        "# Create the index splits for training, validation and test\n",
        "\n",
        "num_train = len(dataset)\n",
        "indices = list(range(num_train))\n",
        "split = int(np.floor(train_size * num_train))\n",
        "split2 = int(np.floor((train_size+(1-train_size)/2) * num_train))\n",
        "np.random.shuffle(indices)\n",
        "train_idx, valid_idx, test_idx = indices[:split], indices[split:split2], indices[split2:]\n",
        "\n",
        "traindata = Subset(traindataset, indices=train_idx)\n",
        "valdata = Subset(valdataset, indices=valid_idx)\n",
        "testdata = Subset(testdataset, indices=test_idx)\n",
        "\n",
        "class_weights = []\n",
        "for root, subdir, files in os.walk(data_dir):\n",
        "  if len(files)>0:\n",
        "    class_weights.append(1/len(files))\n",
        "\n",
        "sample_weights = [0] * len(traindata)\n",
        "\n",
        "for idx, (data, label) in enumerate(traindata):\n",
        "  class_weight = class_weights[label]\n",
        "  sample_weights[idx] = class_weight\n",
        "\n",
        "\n",
        "with open('/content/drive/MyDrive/clean_weights.pkl', 'wb') as f:\n",
        "  pickle.dump(sample_weights, f)\n",
        "\n",
        "with open('/content/drive/MyDrive/clean_weights.pkl', 'rb') as f:\n",
        "  sample_weights = pickle.load(f)\n",
        "\n",
        "sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)\n",
        "\n",
        "trainLoader = torch.utils.data.DataLoader(traindata, sampler=sampler, batch_size=batch_size, \n",
        "                                          num_workers=num_workers, drop_last=True)\n",
        "valLoader = torch.utils.data.DataLoader(valdata, batch_size=batch_size, \n",
        "                                          num_workers=num_workers, drop_last=True)\n",
        "testLoader = torch.utils.data.DataLoader(testdata, batch_size=batch_size,\n",
        "                                          num_workers=num_workers, drop_last=True)\n",
        "dataloaders = {'train': trainLoader, 'val': valLoader, 'test': testLoader}"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyThMaR4nbLF"
      },
      "source": [
        "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False):\n",
        "    since = time.time()\n",
        "\n",
        "    val_acc_history = []\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    # Get model outputs and calculate loss\n",
        "                    # Special case for inception because in training it has an auxiliary output. In train\n",
        "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
        "                    #   but in testing we only consider the final output.\n",
        "                    if is_inception and phase == 'train':\n",
        "                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
        "                        outputs, aux_outputs = model(inputs)\n",
        "                        loss1 = criterion(outputs, labels)\n",
        "                        loss2 = criterion(aux_outputs, labels)\n",
        "                        loss = loss1 + 0.4*loss2\n",
        "                    else:\n",
        "                        outputs = model(inputs)\n",
        "                        loss = criterion(outputs, labels)\n",
        "\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
        "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            if phase == 'val':\n",
        "                val_acc_history.append(epoch_acc)\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, val_acc_history"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75VdlQ8ln1a9"
      },
      "source": [
        "def set_parameter_requires_grad(model, feature_extracting):\n",
        "    if feature_extracting:\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4O8Uqptn8Sb",
        "outputId": "56550fd0-74bc-483a-c270-b49dde0d9150"
      },
      "source": [
        "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
        "    # Initialize these variables which will be set in this if statement. Each of these\n",
        "    #   variables is model specific.\n",
        "    model_ft = None\n",
        "    input_size = 0\n",
        "\n",
        "    if model_name == \"resnet\":\n",
        "        \"\"\" Resnet18\n",
        "        \"\"\"\n",
        "        model_ft = models.resnet18(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.fc.in_features\n",
        "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"alexnet\":\n",
        "        \"\"\" Alexnet\n",
        "        \"\"\"\n",
        "        model_ft = models.alexnet(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.classifier[6].in_features\n",
        "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"vgg\":\n",
        "        \"\"\" VGG11_bn\n",
        "        \"\"\"\n",
        "        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.classifier[6].in_features\n",
        "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"squeezenet\":\n",
        "        \"\"\" Squeezenet\n",
        "        \"\"\"\n",
        "        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
        "        model_ft.num_classes = num_classes\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"densenet\":\n",
        "        \"\"\" Densenet\n",
        "        \"\"\"\n",
        "        model_ft = models.densenet121(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.classifier.in_features\n",
        "        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"inception\":\n",
        "        \"\"\" Inception v3\n",
        "        Be careful, expects (299,299) sized images and has auxiliary output\n",
        "        \"\"\"\n",
        "        model_ft = models.inception_v3(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        # Handle the auxilary net\n",
        "        num_ftrs = model_ft.AuxLogits.fc.in_features\n",
        "        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n",
        "        # Handle the primary net\n",
        "        num_ftrs = model_ft.fc.in_features\n",
        "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
        "        input_size = 299\n",
        "\n",
        "    else:\n",
        "        print(\"Invalid model name, exiting...\")\n",
        "        exit()\n",
        "\n",
        "    return model_ft, input_size\n",
        "\n",
        "# Initialize the model for this run\n",
        "model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n",
        "\n",
        "# Print the model we just instantiated\n",
        "print(model_ft)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Inception3(\n",
            "  (Conv2d_1a_3x3): BasicConv2d(\n",
            "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
            "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (Conv2d_2a_3x3): BasicConv2d(\n",
            "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (Conv2d_2b_3x3): BasicConv2d(\n",
            "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (Conv2d_3b_1x1): BasicConv2d(\n",
            "    (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (Conv2d_4a_3x3): BasicConv2d(\n",
            "    (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (Mixed_5b): InceptionA(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_1): BasicConv2d(\n",
            "      (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_2): BasicConv2d(\n",
            "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_5c): InceptionA(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_1): BasicConv2d(\n",
            "      (conv): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_2): BasicConv2d(\n",
            "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_5d): InceptionA(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_1): BasicConv2d(\n",
            "      (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_2): BasicConv2d(\n",
            "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_6a): InceptionB(\n",
            "    (branch3x3): BasicConv2d(\n",
            "      (conv): Conv2d(288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_6b): InceptionC(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_2): BasicConv2d(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_3): BasicConv2d(\n",
            "      (conv): Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_4): BasicConv2d(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_5): BasicConv2d(\n",
            "      (conv): Conv2d(128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_6c): InceptionC(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_2): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_3): BasicConv2d(\n",
            "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_4): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_5): BasicConv2d(\n",
            "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_6d): InceptionC(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_2): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_3): BasicConv2d(\n",
            "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_4): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_5): BasicConv2d(\n",
            "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_6e): InceptionC(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_2): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_3): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_4): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_5): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (AuxLogits): InceptionAux(\n",
            "    (conv0): BasicConv2d(\n",
            "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (conv1): BasicConv2d(\n",
            "      (conv): Conv2d(128, 768, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fc): Linear(in_features=768, out_features=2, bias=True)\n",
            "  )\n",
            "  (Mixed_7a): InceptionD(\n",
            "    (branch3x3_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_2): BasicConv2d(\n",
            "      (conv): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7x3_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7x3_2): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7x3_3): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7x3_4): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_7b): InceptionE(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_1): BasicConv2d(\n",
            "      (conv): Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_2a): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_2b): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3a): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3b): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_7c): InceptionE(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_1): BasicConv2d(\n",
            "      (conv): Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_2a): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_2b): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3a): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3b): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (fc): Linear(in_features=2048, out_features=2, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6151ULNdzuq",
        "outputId": "22466477-b85b-4f38-bee8-7706712cc4c0"
      },
      "source": [
        "# Send the model to GPU\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "# Gather the parameters to be optimized/updated in this run. If we are\n",
        "#  finetuning we will be updating all parameters. However, if we are\n",
        "#  doing feature extract method, we will only update the parameters\n",
        "#  that we have just initialized, i.e. the parameters with requires_grad\n",
        "#  is True.\n",
        "params_to_update = model_ft.parameters()\n",
        "print(\"Params to learn:\")\n",
        "if feature_extract:\n",
        "    params_to_update = []\n",
        "    for name,param in model_ft.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            params_to_update.append(param)\n",
        "            print(\"\\t\",name)\n",
        "else:\n",
        "    for name,param in model_ft.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            print(\"\\t\",name)\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Params to learn:\n",
            "\t Conv2d_1a_3x3.conv.weight\n",
            "\t Conv2d_1a_3x3.bn.weight\n",
            "\t Conv2d_1a_3x3.bn.bias\n",
            "\t Conv2d_2a_3x3.conv.weight\n",
            "\t Conv2d_2a_3x3.bn.weight\n",
            "\t Conv2d_2a_3x3.bn.bias\n",
            "\t Conv2d_2b_3x3.conv.weight\n",
            "\t Conv2d_2b_3x3.bn.weight\n",
            "\t Conv2d_2b_3x3.bn.bias\n",
            "\t Conv2d_3b_1x1.conv.weight\n",
            "\t Conv2d_3b_1x1.bn.weight\n",
            "\t Conv2d_3b_1x1.bn.bias\n",
            "\t Conv2d_4a_3x3.conv.weight\n",
            "\t Conv2d_4a_3x3.bn.weight\n",
            "\t Conv2d_4a_3x3.bn.bias\n",
            "\t Mixed_5b.branch1x1.conv.weight\n",
            "\t Mixed_5b.branch1x1.bn.weight\n",
            "\t Mixed_5b.branch1x1.bn.bias\n",
            "\t Mixed_5b.branch5x5_1.conv.weight\n",
            "\t Mixed_5b.branch5x5_1.bn.weight\n",
            "\t Mixed_5b.branch5x5_1.bn.bias\n",
            "\t Mixed_5b.branch5x5_2.conv.weight\n",
            "\t Mixed_5b.branch5x5_2.bn.weight\n",
            "\t Mixed_5b.branch5x5_2.bn.bias\n",
            "\t Mixed_5b.branch3x3dbl_1.conv.weight\n",
            "\t Mixed_5b.branch3x3dbl_1.bn.weight\n",
            "\t Mixed_5b.branch3x3dbl_1.bn.bias\n",
            "\t Mixed_5b.branch3x3dbl_2.conv.weight\n",
            "\t Mixed_5b.branch3x3dbl_2.bn.weight\n",
            "\t Mixed_5b.branch3x3dbl_2.bn.bias\n",
            "\t Mixed_5b.branch3x3dbl_3.conv.weight\n",
            "\t Mixed_5b.branch3x3dbl_3.bn.weight\n",
            "\t Mixed_5b.branch3x3dbl_3.bn.bias\n",
            "\t Mixed_5b.branch_pool.conv.weight\n",
            "\t Mixed_5b.branch_pool.bn.weight\n",
            "\t Mixed_5b.branch_pool.bn.bias\n",
            "\t Mixed_5c.branch1x1.conv.weight\n",
            "\t Mixed_5c.branch1x1.bn.weight\n",
            "\t Mixed_5c.branch1x1.bn.bias\n",
            "\t Mixed_5c.branch5x5_1.conv.weight\n",
            "\t Mixed_5c.branch5x5_1.bn.weight\n",
            "\t Mixed_5c.branch5x5_1.bn.bias\n",
            "\t Mixed_5c.branch5x5_2.conv.weight\n",
            "\t Mixed_5c.branch5x5_2.bn.weight\n",
            "\t Mixed_5c.branch5x5_2.bn.bias\n",
            "\t Mixed_5c.branch3x3dbl_1.conv.weight\n",
            "\t Mixed_5c.branch3x3dbl_1.bn.weight\n",
            "\t Mixed_5c.branch3x3dbl_1.bn.bias\n",
            "\t Mixed_5c.branch3x3dbl_2.conv.weight\n",
            "\t Mixed_5c.branch3x3dbl_2.bn.weight\n",
            "\t Mixed_5c.branch3x3dbl_2.bn.bias\n",
            "\t Mixed_5c.branch3x3dbl_3.conv.weight\n",
            "\t Mixed_5c.branch3x3dbl_3.bn.weight\n",
            "\t Mixed_5c.branch3x3dbl_3.bn.bias\n",
            "\t Mixed_5c.branch_pool.conv.weight\n",
            "\t Mixed_5c.branch_pool.bn.weight\n",
            "\t Mixed_5c.branch_pool.bn.bias\n",
            "\t Mixed_5d.branch1x1.conv.weight\n",
            "\t Mixed_5d.branch1x1.bn.weight\n",
            "\t Mixed_5d.branch1x1.bn.bias\n",
            "\t Mixed_5d.branch5x5_1.conv.weight\n",
            "\t Mixed_5d.branch5x5_1.bn.weight\n",
            "\t Mixed_5d.branch5x5_1.bn.bias\n",
            "\t Mixed_5d.branch5x5_2.conv.weight\n",
            "\t Mixed_5d.branch5x5_2.bn.weight\n",
            "\t Mixed_5d.branch5x5_2.bn.bias\n",
            "\t Mixed_5d.branch3x3dbl_1.conv.weight\n",
            "\t Mixed_5d.branch3x3dbl_1.bn.weight\n",
            "\t Mixed_5d.branch3x3dbl_1.bn.bias\n",
            "\t Mixed_5d.branch3x3dbl_2.conv.weight\n",
            "\t Mixed_5d.branch3x3dbl_2.bn.weight\n",
            "\t Mixed_5d.branch3x3dbl_2.bn.bias\n",
            "\t Mixed_5d.branch3x3dbl_3.conv.weight\n",
            "\t Mixed_5d.branch3x3dbl_3.bn.weight\n",
            "\t Mixed_5d.branch3x3dbl_3.bn.bias\n",
            "\t Mixed_5d.branch_pool.conv.weight\n",
            "\t Mixed_5d.branch_pool.bn.weight\n",
            "\t Mixed_5d.branch_pool.bn.bias\n",
            "\t Mixed_6a.branch3x3.conv.weight\n",
            "\t Mixed_6a.branch3x3.bn.weight\n",
            "\t Mixed_6a.branch3x3.bn.bias\n",
            "\t Mixed_6a.branch3x3dbl_1.conv.weight\n",
            "\t Mixed_6a.branch3x3dbl_1.bn.weight\n",
            "\t Mixed_6a.branch3x3dbl_1.bn.bias\n",
            "\t Mixed_6a.branch3x3dbl_2.conv.weight\n",
            "\t Mixed_6a.branch3x3dbl_2.bn.weight\n",
            "\t Mixed_6a.branch3x3dbl_2.bn.bias\n",
            "\t Mixed_6a.branch3x3dbl_3.conv.weight\n",
            "\t Mixed_6a.branch3x3dbl_3.bn.weight\n",
            "\t Mixed_6a.branch3x3dbl_3.bn.bias\n",
            "\t Mixed_6b.branch1x1.conv.weight\n",
            "\t Mixed_6b.branch1x1.bn.weight\n",
            "\t Mixed_6b.branch1x1.bn.bias\n",
            "\t Mixed_6b.branch7x7_1.conv.weight\n",
            "\t Mixed_6b.branch7x7_1.bn.weight\n",
            "\t Mixed_6b.branch7x7_1.bn.bias\n",
            "\t Mixed_6b.branch7x7_2.conv.weight\n",
            "\t Mixed_6b.branch7x7_2.bn.weight\n",
            "\t Mixed_6b.branch7x7_2.bn.bias\n",
            "\t Mixed_6b.branch7x7_3.conv.weight\n",
            "\t Mixed_6b.branch7x7_3.bn.weight\n",
            "\t Mixed_6b.branch7x7_3.bn.bias\n",
            "\t Mixed_6b.branch7x7dbl_1.conv.weight\n",
            "\t Mixed_6b.branch7x7dbl_1.bn.weight\n",
            "\t Mixed_6b.branch7x7dbl_1.bn.bias\n",
            "\t Mixed_6b.branch7x7dbl_2.conv.weight\n",
            "\t Mixed_6b.branch7x7dbl_2.bn.weight\n",
            "\t Mixed_6b.branch7x7dbl_2.bn.bias\n",
            "\t Mixed_6b.branch7x7dbl_3.conv.weight\n",
            "\t Mixed_6b.branch7x7dbl_3.bn.weight\n",
            "\t Mixed_6b.branch7x7dbl_3.bn.bias\n",
            "\t Mixed_6b.branch7x7dbl_4.conv.weight\n",
            "\t Mixed_6b.branch7x7dbl_4.bn.weight\n",
            "\t Mixed_6b.branch7x7dbl_4.bn.bias\n",
            "\t Mixed_6b.branch7x7dbl_5.conv.weight\n",
            "\t Mixed_6b.branch7x7dbl_5.bn.weight\n",
            "\t Mixed_6b.branch7x7dbl_5.bn.bias\n",
            "\t Mixed_6b.branch_pool.conv.weight\n",
            "\t Mixed_6b.branch_pool.bn.weight\n",
            "\t Mixed_6b.branch_pool.bn.bias\n",
            "\t Mixed_6c.branch1x1.conv.weight\n",
            "\t Mixed_6c.branch1x1.bn.weight\n",
            "\t Mixed_6c.branch1x1.bn.bias\n",
            "\t Mixed_6c.branch7x7_1.conv.weight\n",
            "\t Mixed_6c.branch7x7_1.bn.weight\n",
            "\t Mixed_6c.branch7x7_1.bn.bias\n",
            "\t Mixed_6c.branch7x7_2.conv.weight\n",
            "\t Mixed_6c.branch7x7_2.bn.weight\n",
            "\t Mixed_6c.branch7x7_2.bn.bias\n",
            "\t Mixed_6c.branch7x7_3.conv.weight\n",
            "\t Mixed_6c.branch7x7_3.bn.weight\n",
            "\t Mixed_6c.branch7x7_3.bn.bias\n",
            "\t Mixed_6c.branch7x7dbl_1.conv.weight\n",
            "\t Mixed_6c.branch7x7dbl_1.bn.weight\n",
            "\t Mixed_6c.branch7x7dbl_1.bn.bias\n",
            "\t Mixed_6c.branch7x7dbl_2.conv.weight\n",
            "\t Mixed_6c.branch7x7dbl_2.bn.weight\n",
            "\t Mixed_6c.branch7x7dbl_2.bn.bias\n",
            "\t Mixed_6c.branch7x7dbl_3.conv.weight\n",
            "\t Mixed_6c.branch7x7dbl_3.bn.weight\n",
            "\t Mixed_6c.branch7x7dbl_3.bn.bias\n",
            "\t Mixed_6c.branch7x7dbl_4.conv.weight\n",
            "\t Mixed_6c.branch7x7dbl_4.bn.weight\n",
            "\t Mixed_6c.branch7x7dbl_4.bn.bias\n",
            "\t Mixed_6c.branch7x7dbl_5.conv.weight\n",
            "\t Mixed_6c.branch7x7dbl_5.bn.weight\n",
            "\t Mixed_6c.branch7x7dbl_5.bn.bias\n",
            "\t Mixed_6c.branch_pool.conv.weight\n",
            "\t Mixed_6c.branch_pool.bn.weight\n",
            "\t Mixed_6c.branch_pool.bn.bias\n",
            "\t Mixed_6d.branch1x1.conv.weight\n",
            "\t Mixed_6d.branch1x1.bn.weight\n",
            "\t Mixed_6d.branch1x1.bn.bias\n",
            "\t Mixed_6d.branch7x7_1.conv.weight\n",
            "\t Mixed_6d.branch7x7_1.bn.weight\n",
            "\t Mixed_6d.branch7x7_1.bn.bias\n",
            "\t Mixed_6d.branch7x7_2.conv.weight\n",
            "\t Mixed_6d.branch7x7_2.bn.weight\n",
            "\t Mixed_6d.branch7x7_2.bn.bias\n",
            "\t Mixed_6d.branch7x7_3.conv.weight\n",
            "\t Mixed_6d.branch7x7_3.bn.weight\n",
            "\t Mixed_6d.branch7x7_3.bn.bias\n",
            "\t Mixed_6d.branch7x7dbl_1.conv.weight\n",
            "\t Mixed_6d.branch7x7dbl_1.bn.weight\n",
            "\t Mixed_6d.branch7x7dbl_1.bn.bias\n",
            "\t Mixed_6d.branch7x7dbl_2.conv.weight\n",
            "\t Mixed_6d.branch7x7dbl_2.bn.weight\n",
            "\t Mixed_6d.branch7x7dbl_2.bn.bias\n",
            "\t Mixed_6d.branch7x7dbl_3.conv.weight\n",
            "\t Mixed_6d.branch7x7dbl_3.bn.weight\n",
            "\t Mixed_6d.branch7x7dbl_3.bn.bias\n",
            "\t Mixed_6d.branch7x7dbl_4.conv.weight\n",
            "\t Mixed_6d.branch7x7dbl_4.bn.weight\n",
            "\t Mixed_6d.branch7x7dbl_4.bn.bias\n",
            "\t Mixed_6d.branch7x7dbl_5.conv.weight\n",
            "\t Mixed_6d.branch7x7dbl_5.bn.weight\n",
            "\t Mixed_6d.branch7x7dbl_5.bn.bias\n",
            "\t Mixed_6d.branch_pool.conv.weight\n",
            "\t Mixed_6d.branch_pool.bn.weight\n",
            "\t Mixed_6d.branch_pool.bn.bias\n",
            "\t Mixed_6e.branch1x1.conv.weight\n",
            "\t Mixed_6e.branch1x1.bn.weight\n",
            "\t Mixed_6e.branch1x1.bn.bias\n",
            "\t Mixed_6e.branch7x7_1.conv.weight\n",
            "\t Mixed_6e.branch7x7_1.bn.weight\n",
            "\t Mixed_6e.branch7x7_1.bn.bias\n",
            "\t Mixed_6e.branch7x7_2.conv.weight\n",
            "\t Mixed_6e.branch7x7_2.bn.weight\n",
            "\t Mixed_6e.branch7x7_2.bn.bias\n",
            "\t Mixed_6e.branch7x7_3.conv.weight\n",
            "\t Mixed_6e.branch7x7_3.bn.weight\n",
            "\t Mixed_6e.branch7x7_3.bn.bias\n",
            "\t Mixed_6e.branch7x7dbl_1.conv.weight\n",
            "\t Mixed_6e.branch7x7dbl_1.bn.weight\n",
            "\t Mixed_6e.branch7x7dbl_1.bn.bias\n",
            "\t Mixed_6e.branch7x7dbl_2.conv.weight\n",
            "\t Mixed_6e.branch7x7dbl_2.bn.weight\n",
            "\t Mixed_6e.branch7x7dbl_2.bn.bias\n",
            "\t Mixed_6e.branch7x7dbl_3.conv.weight\n",
            "\t Mixed_6e.branch7x7dbl_3.bn.weight\n",
            "\t Mixed_6e.branch7x7dbl_3.bn.bias\n",
            "\t Mixed_6e.branch7x7dbl_4.conv.weight\n",
            "\t Mixed_6e.branch7x7dbl_4.bn.weight\n",
            "\t Mixed_6e.branch7x7dbl_4.bn.bias\n",
            "\t Mixed_6e.branch7x7dbl_5.conv.weight\n",
            "\t Mixed_6e.branch7x7dbl_5.bn.weight\n",
            "\t Mixed_6e.branch7x7dbl_5.bn.bias\n",
            "\t Mixed_6e.branch_pool.conv.weight\n",
            "\t Mixed_6e.branch_pool.bn.weight\n",
            "\t Mixed_6e.branch_pool.bn.bias\n",
            "\t AuxLogits.conv0.conv.weight\n",
            "\t AuxLogits.conv0.bn.weight\n",
            "\t AuxLogits.conv0.bn.bias\n",
            "\t AuxLogits.conv1.conv.weight\n",
            "\t AuxLogits.conv1.bn.weight\n",
            "\t AuxLogits.conv1.bn.bias\n",
            "\t AuxLogits.fc.weight\n",
            "\t AuxLogits.fc.bias\n",
            "\t Mixed_7a.branch3x3_1.conv.weight\n",
            "\t Mixed_7a.branch3x3_1.bn.weight\n",
            "\t Mixed_7a.branch3x3_1.bn.bias\n",
            "\t Mixed_7a.branch3x3_2.conv.weight\n",
            "\t Mixed_7a.branch3x3_2.bn.weight\n",
            "\t Mixed_7a.branch3x3_2.bn.bias\n",
            "\t Mixed_7a.branch7x7x3_1.conv.weight\n",
            "\t Mixed_7a.branch7x7x3_1.bn.weight\n",
            "\t Mixed_7a.branch7x7x3_1.bn.bias\n",
            "\t Mixed_7a.branch7x7x3_2.conv.weight\n",
            "\t Mixed_7a.branch7x7x3_2.bn.weight\n",
            "\t Mixed_7a.branch7x7x3_2.bn.bias\n",
            "\t Mixed_7a.branch7x7x3_3.conv.weight\n",
            "\t Mixed_7a.branch7x7x3_3.bn.weight\n",
            "\t Mixed_7a.branch7x7x3_3.bn.bias\n",
            "\t Mixed_7a.branch7x7x3_4.conv.weight\n",
            "\t Mixed_7a.branch7x7x3_4.bn.weight\n",
            "\t Mixed_7a.branch7x7x3_4.bn.bias\n",
            "\t Mixed_7b.branch1x1.conv.weight\n",
            "\t Mixed_7b.branch1x1.bn.weight\n",
            "\t Mixed_7b.branch1x1.bn.bias\n",
            "\t Mixed_7b.branch3x3_1.conv.weight\n",
            "\t Mixed_7b.branch3x3_1.bn.weight\n",
            "\t Mixed_7b.branch3x3_1.bn.bias\n",
            "\t Mixed_7b.branch3x3_2a.conv.weight\n",
            "\t Mixed_7b.branch3x3_2a.bn.weight\n",
            "\t Mixed_7b.branch3x3_2a.bn.bias\n",
            "\t Mixed_7b.branch3x3_2b.conv.weight\n",
            "\t Mixed_7b.branch3x3_2b.bn.weight\n",
            "\t Mixed_7b.branch3x3_2b.bn.bias\n",
            "\t Mixed_7b.branch3x3dbl_1.conv.weight\n",
            "\t Mixed_7b.branch3x3dbl_1.bn.weight\n",
            "\t Mixed_7b.branch3x3dbl_1.bn.bias\n",
            "\t Mixed_7b.branch3x3dbl_2.conv.weight\n",
            "\t Mixed_7b.branch3x3dbl_2.bn.weight\n",
            "\t Mixed_7b.branch3x3dbl_2.bn.bias\n",
            "\t Mixed_7b.branch3x3dbl_3a.conv.weight\n",
            "\t Mixed_7b.branch3x3dbl_3a.bn.weight\n",
            "\t Mixed_7b.branch3x3dbl_3a.bn.bias\n",
            "\t Mixed_7b.branch3x3dbl_3b.conv.weight\n",
            "\t Mixed_7b.branch3x3dbl_3b.bn.weight\n",
            "\t Mixed_7b.branch3x3dbl_3b.bn.bias\n",
            "\t Mixed_7b.branch_pool.conv.weight\n",
            "\t Mixed_7b.branch_pool.bn.weight\n",
            "\t Mixed_7b.branch_pool.bn.bias\n",
            "\t Mixed_7c.branch1x1.conv.weight\n",
            "\t Mixed_7c.branch1x1.bn.weight\n",
            "\t Mixed_7c.branch1x1.bn.bias\n",
            "\t Mixed_7c.branch3x3_1.conv.weight\n",
            "\t Mixed_7c.branch3x3_1.bn.weight\n",
            "\t Mixed_7c.branch3x3_1.bn.bias\n",
            "\t Mixed_7c.branch3x3_2a.conv.weight\n",
            "\t Mixed_7c.branch3x3_2a.bn.weight\n",
            "\t Mixed_7c.branch3x3_2a.bn.bias\n",
            "\t Mixed_7c.branch3x3_2b.conv.weight\n",
            "\t Mixed_7c.branch3x3_2b.bn.weight\n",
            "\t Mixed_7c.branch3x3_2b.bn.bias\n",
            "\t Mixed_7c.branch3x3dbl_1.conv.weight\n",
            "\t Mixed_7c.branch3x3dbl_1.bn.weight\n",
            "\t Mixed_7c.branch3x3dbl_1.bn.bias\n",
            "\t Mixed_7c.branch3x3dbl_2.conv.weight\n",
            "\t Mixed_7c.branch3x3dbl_2.bn.weight\n",
            "\t Mixed_7c.branch3x3dbl_2.bn.bias\n",
            "\t Mixed_7c.branch3x3dbl_3a.conv.weight\n",
            "\t Mixed_7c.branch3x3dbl_3a.bn.weight\n",
            "\t Mixed_7c.branch3x3dbl_3a.bn.bias\n",
            "\t Mixed_7c.branch3x3dbl_3b.conv.weight\n",
            "\t Mixed_7c.branch3x3dbl_3b.bn.weight\n",
            "\t Mixed_7c.branch3x3dbl_3b.bn.bias\n",
            "\t Mixed_7c.branch_pool.conv.weight\n",
            "\t Mixed_7c.branch_pool.bn.weight\n",
            "\t Mixed_7c.branch_pool.bn.bias\n",
            "\t fc.weight\n",
            "\t fc.bias\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXg5BAG1oo-f",
        "outputId": "5e5d2df0-5ed9-4bb4-8ea3-561e920c2d97"
      },
      "source": [
        "# Setup the loss fxn\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Train and evaluate\n",
        "model_ft, hist = train_model(model_ft, dataloaders, criterion, optimizer_ft, num_epochs=num_epochs, is_inception=(model_name==\"inception\"))"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/9\n",
            "----------\n",
            "train Loss: 0.0881 Acc: 0.9716\n",
            "val Loss: 0.7844 Acc: 0.8712\n",
            "\n",
            "Epoch 1/9\n",
            "----------\n",
            "train Loss: 0.0014 Acc: 0.9912\n",
            "val Loss: 0.8086 Acc: 0.8712\n",
            "\n",
            "Epoch 2/9\n",
            "----------\n",
            "train Loss: 0.0012 Acc: 0.9912\n",
            "val Loss: 0.8054 Acc: 0.8712\n",
            "\n",
            "Epoch 3/9\n",
            "----------\n",
            "train Loss: 0.0010 Acc: 0.9912\n",
            "val Loss: 0.8162 Acc: 0.8712\n",
            "\n",
            "Epoch 4/9\n",
            "----------\n",
            "train Loss: 0.0009 Acc: 0.9912\n",
            "val Loss: 0.8145 Acc: 0.8712\n",
            "\n",
            "Epoch 5/9\n",
            "----------\n",
            "train Loss: 0.0009 Acc: 0.9912\n",
            "val Loss: 0.8339 Acc: 0.8712\n",
            "\n",
            "Epoch 6/9\n",
            "----------\n",
            "train Loss: 0.0008 Acc: 0.9912\n",
            "val Loss: 0.8311 Acc: 0.8712\n",
            "\n",
            "Epoch 7/9\n",
            "----------\n",
            "train Loss: 0.0007 Acc: 0.9912\n",
            "val Loss: 0.8440 Acc: 0.8712\n",
            "\n",
            "Epoch 8/9\n",
            "----------\n",
            "train Loss: 0.0007 Acc: 0.9912\n",
            "val Loss: 0.8456 Acc: 0.8712\n",
            "\n",
            "Epoch 9/9\n",
            "----------\n",
            "train Loss: 0.0006 Acc: 0.9912\n",
            "val Loss: 0.8500 Acc: 0.8712\n",
            "\n",
            "Training complete in 8m 41s\n",
            "Best val Acc: 0.871212\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgYraiAjiys8"
      },
      "source": [
        "torch.save(model_ft,'/content/drive/MyDrive/saved_models/disk_dataset_ocular_0.h5')"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpGRminVjRIY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "outputId": "68edb51c-c12d-4051-8481-4ee1faf3f35c"
      },
      "source": [
        "import seaborn as sns\n",
        "nb_classes = num_classes\n",
        "confusion_matrix = np.zeros((nb_classes, nb_classes))\n",
        "with torch.no_grad():\n",
        "    for i, (inputs, classes) in enumerate(dataloaders['test']):\n",
        "        inputs = inputs.to(device)\n",
        "        classes = classes.to(device)\n",
        "        outputs = model_ft(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        for t, p in zip(classes.view(-1), preds.view(-1)):\n",
        "                confusion_matrix[t.long(), p.long()] += 1\n",
        "\n",
        "plt.figure(figsize=(15,10))\n",
        "\n",
        "class_names = ['Normal', 'Glaucoma']\n",
        "df_cm = pd.DataFrame(confusion_matrix, index=class_names, columns=class_names).astype(int)\n",
        "heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
        "\n",
        "heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right',fontsize=15)\n",
        "heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right',fontsize=15)\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 69.0, 'Predicted label')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x720 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EyL4HDhTKDa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "outputId": "3da53828-ec38-4c3c-ce19-67451f4e071e"
      },
      "source": [
        "confusion_matrix = np.zeros((nb_classes, nb_classes))\n",
        "with torch.no_grad():\n",
        "    for i, (inputs, classes) in enumerate(dataloaders['train']):\n",
        "        inputs = inputs.to(device)\n",
        "        classes = classes.to(device)\n",
        "        outputs = model_ft(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        for t, p in zip(classes.view(-1), preds.view(-1)):\n",
        "                confusion_matrix[t.long(), p.long()] += 1\n",
        "\n",
        "plt.figure(figsize=(15,10))\n",
        "\n",
        "class_names = ['Normal', 'Glaucoma']\n",
        "df_cm = pd.DataFrame(confusion_matrix, index=class_names, columns=class_names).astype(int)\n",
        "heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
        "\n",
        "heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right',fontsize=15)\n",
        "heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right',fontsize=15)\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 69.0, 'Predicted label')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3IAAAKDCAYAAABfbjjpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeZhlVXk37N/TjQJODBoQGhRUEj/NJFGcXiNKIqiJaJwwDoSYkFcxajQxmphgTJynaEQTVAKOOAsoDrwoGqMoGA0qqLQ40A2IiooRELprfX/s3XhSVHdXF111atH37XWuOnvtfc5e1V6cq57zW0O11gIAAEA/Vky7AwAAAGwZhRwAAEBnFHIAAACdUcgBAAB0RiEHAADQGYUcAABAZ7abdgfYtGt+cIH9IQC20I573mfaXQDozrqr19a0+zAfS/n38Y1udbtl+28ikQMAAOiMRA4AAOjHzPpp92BZkMgBAAB0RiEHAADQGUMrAQCAfrSZafdgWZDIAQAAdEYiBwAA9GNGIpdI5AAAALojkQMAALrRzJFLIpEDAADojkQOAADohzlySSRyAAAA3ZHIAQAA/TBHLolEDgAAoDsSOQAAoB8z66fdg2VBIgcAANAZiRwAANAPc+SSSOQAAAC6I5EDAAD6YR+5JBI5AACA7ijkAAAAOmNoJQAA0I1msZMkEjkAAIDuSOQAAIB+WOwkiUQOAACgOxI5AACgH+bIJZHIAQAAdEciBwAA9GNm/bR7sCxI5AAAADojkQMAAPphjlwSiRwAAEB3JHIAAEA/7COXRCIHAADQHYkcAADQD3PkkkjkAAAAuiORAwAA+mGOXBKJHAAAQHcUcgAAAJ0xtBIAAOhGa+un3YVlQSIHAADQGYkcAADQD9sPJJHIAQAAdEciBwAA9MP2A0kkcgAAAN2RyAEAAP0wRy6JRA4AAKA7EjkAAKAfM/aRSyRyAAAA3ZHIAQAA/TBHLolEDgAAoDsSOQAAoB/2kUsikQMAAOiORA4AAOiHOXJJJHIAAAALUlXHVdWlVfWVOc49s6paVd1qPK6qek1Vra6qc6pq/4lrD6+q88fH4fO5t0IOAABgYY5PcsjsxqraO8kDknx3ovmBSfYbH0cmef147a5Jjk5y9yQHJDm6qnbZ3I0VcgAAQD9mZpbusRmttU8luWyOU69K8qwkbaLt0CRvboMzk+xcVXskOTjJaa21y1prP0pyWuYoDmdTyAEAAGwlVXVokrWttf+edWpVkgsnjteMbRtr3ySLnQAAAP1Ywu0HqurIDMMgNzi2tXbsJq6/SZK/yTCsclEp5AAAAOYwFm0bLdzmcPsk+yb576pKkr2S/FdVHZBkbZK9J67da2xbm+TAWe1nbO5GCjkAAKAbra2fdhc2qrX25SS7bTiuqm8nuWtr7QdVdXKSp1TViRkWNvlJa+3iqvpokhdOLHDygCTP2dy9zJEDAABYgKp6R5LPJvmVqlpTVU/cxOWnJrkgyeokb0jy5CRprV2W5B+TnDU+nj+2bZJEDgAA6McSzpHbnNbaYzZzfp+J5y3JURu57rgkx23JvSVyAAAAnZHIAQAA/WjLJ5GbJokcAABAZyRyAABAP5bRHLlpksgBAAB0RiIHAAD0wxy5JBI5AACA7kjkAACAfpgjl0QiBwAA0B2FHAAAQGcMrQQAAPphsZMkEjkAAIDuSOQAAIB+WOwkiUQOAACgOxI5AACgHxK5JBI5AACA7kjkAACAfli1MolEDgAAoDsSOQAAoB/myCWRyAEAAHRHIgcAAPTDHLkkEjkAAIDuSOQAAIB+mCOXRCIHAADQHYkcAADQD3PkkkjkAAAAuqOQAwAA6IyhlQAAQD8sdpJEIgcAANAdiRwAANAPiVwSiRwAAEB3JHIAAEA/Wpt2D5YFiRwAAEBnJHIAAEA/zJFLIpEDAADojkQOAADoh0QuiUQOAACgOxI5AACgH00il0jkAAAAuiORAwAA+mGOXBKJHAAAQHckcgAAQD9am3YPlgWJHAAAQGcUcgAAAJ0xtBIAAOiHxU6SSOQAAAC6I5EDAAD6IZFLIpEDAADojkQOAADoR5PIJRI5AACA7kjkAACAbrQZG4InEjkAAIDuSOQAAIB+WLUyiUQOAACgOxI5AACgH1atTCKRAwAA6I5EDgAA6IdVK5NI5AAAALojkQMAAPph1cokEjkAAIDuKOQAAAA6o5ADAAD6MTOzdI/NqKrjqurSqvrKRNvLquprVXVOVb2/qnaeOPecqlpdVV+vqoMn2g8Z21ZX1bPn88+gkAMAAFiY45McMqvttCS/2lr79STfSPKcJKmqOyU5LMmdx9e8rqpWVtXKJMckeWCSOyV5zHjtJlnsBAAA6EdbPtsPtNY+VVX7zGr72MThmUkeMT4/NMmJrbWfJ/lWVa1OcsB4bnVr7YIkqaoTx2vP3dS9JXIAAABzqKojq+rsiceRW/gWf5zkw+PzVUkunDi3ZmzbWPsmSeQAAIB+LOH2A621Y5Mcu5DXVtXfJlmX5G1btVMjhRwAAMBWVFV/lOT3khzU2rVjQdcm2Xvisr3GtmyifaO6G1pZVc+rqlZVH53j3Huq6owpdGuLVNWB4+/wq9PuCwAAdGWmLd1jAarqkCTPSvKQ1toVE6dOTnJYVW1fVfsm2S/J55OclWS/qtq3qm6cYUGUkzd3n54TuQdU1d1aa2dNuyNwQ/HcF74yn/rPz2fXXXbOB976r0mSY9701rz35I9kl513SpI87c8Oz2/fa5iX+/XV38rzX/qa/M/PrsiKFSty4htfne23v3FOPe2MvOHN70wq2e1Wt8yL//6vrn09wLbq4AccmFe+8vlZuWJFjvv3d+SlLztm2l0CrqeqekeSA5PcqqrWJDk6wyqV2yc5raqS5MzW2v9trX21qt6VYRGTdUmOaq2tH9/nKUk+mmRlkuNaa1/d3L17LeQuyxA3/m2Sh27NN66qHVtrV27N94RePPRBv5s/fPhD8jf/+PL/1f74Rz80R/zhI/5X27p16/Ps5780L/q7v8od97tdfvyTy7Pddiuzbt36vPif/zUnve3fssvOO+UVx7wpb3/vKTnqiY9byl8FYFlZsWJFXvPqF+SQBz0ma9ZcnDM/e2pO+eDHct5550+7a9CftnRz5DantfaYOZrftInrX5DkBXO0n5rk1C25d3dDK0ctwz/AQ6rq1zZ2UVX9ZlWdXlVXVNWPquptVbX7xPl9xiGOj62qN1fVj5OcMtF+WFX9e1VdXlVrqupx4+ueVVUXVdX3q+olVbVi4j3vWFUnVtWF432/WlVPn7wGlqu7/uavZadb3Hxe137m81/IL99+39xxv9slSXbe6RZZuXJl2vi/K6+6Kq21/M/Prshut9p1MbsNsOwdcLe75Jvf/Ha+9a3v5pprrsm73nVSHvL7B2/+hQAb0WsilyTvTvL8DKncYbNPVtUvJTkjyXlJ/jDJzZK8OEPEedfW2tUTl788yfuSPDLJ+on2l2RYZebhGZYOPaGq7pLktuPxbyX5pyRfTHLi+JpVSb4+vu6nSX4zyT8k2THJi67n7wxT8Y73npKTP3J67nzH/fJXT/nT7HSLm+c7F65NVeXIv/jb/OjHP8kDf+e++ePHPjI32m67/N1fPiUPe/yTsuOOO+S2e63Kc5/55Gn/CgBTteeqW+fCNRdde7xm7cU54G53mWKPoGMLnLt2Q9NtStRam8lQGD2yqn55jkueOf48uLX2gdbaWzMUZL82/px0ZmvtqNbaaa21j0+0f7y19jettdOS/FmSmSQPSfLo1tpHxmj0rCQPm+jX6a21o1trpyT5ZJLXZigI//R6/9IwBY9+2IPz4Xcdl/cef0x+6Za75mWvfUOSZN369fniOV/NS45+Vt78+pfn9E9+Jmee/cVcs25d3vn+D+Xd//7afOKkt+WXb79v3viWd035twAAuGHptpAbvTXJdzNMKJztgCQfa61dvqGhtfa5JN9O8n9mXfuhjbz/6ROvvTzJ95N8csOkxNHqTGzYV1U7VNU/jDu1/zzJNRmGge5bVfNKQCc3Hnzjm98xn5fAornVrrtk5cqVWbFiRR7xkAfmK+d+I0my+263ym/9xq9ml513yo477JD73PNuOffr38zXzv9mkuQ2e+2ZqsrBB90nX/ryudP8FQCm7qK1l2Tvvfa89nivVXvkoosumWKPoF9tZmbJHstZ14Vca21dkpcmeVxV3XbW6T2SfG+Ol30vyewJO3NdlyQ/nnV89Ubadpg4fkmSv8ywceCDktwtw/DLzLpuo1prx7bW7tpau+ufPGGu+ZOwdL7/g8uufX76Jz+TO9xu+E/t3gf8Vs6/4Nu58qqrsm7d+pz9pS/n9vveJrvf6lb55re/m8t+NPyn8tnPfzG32+c2U+k7wHJx1tlfyh3usG/22Wfv3OhGN8qjHnVoTvngx6bdLaBjPc+R2+C4JM9N8tez2i9Ostsc1++e5Auz2rbmQNtHJvmX1tpLNzRU1YO34vvDovmro1+cs754Tn7848tz0EMflyc/8fE564vn5OvnX5BUsurWu+foZz01SbLTLW6eJxz2BznsiU9LVeU+97xb7jtuS/CkIx6bw496VrbbbmX2vPVuecHfPnNTtwW4wVu/fn2e9vTn5tQPvT0rV6zI8Se8M+eOIxyALWSOXJIbQCHXWvt5Vb08w3y5L2QYypgkn0vypKq6eWvtp0lSVXdLsk+STy9il3bMMKQy4z1XZo7FWGA5etk/PPs6bQ/fxKpqv3/w/fP7B9//Ou2PftiD8+iH+f4CYNKHP/LxfPgjH9/8hQDz0PXQygn/lmGFyHtNtL1y/PnRqjq0qh6bYWXKLyd57yL25bQkR1XV48ck7pQMGwICAADXV5tZuscydoMo5FprVyR51ay27ye5X5KrkrwjyTFJ/iPJ787aemBr+/PxPsdkGPb5ldh2AAAA2IqqNWNMl7NrfnCB/4MAttCOe95n2l0A6M66q9fWtPswHz/7p8ct2d/HN33uW5ftv0n3c+QAAIBtiMVOktxAhlYCAABsSyRyAABAP5b5Rt1LRSIHAADQGYkcAADQD3PkkkjkAAAAuiORAwAA+rHMN+peKhI5AACAzkjkAACAfpgjl0QiBwAA0B2JHAAA0I1mH7kkEjkAAIDuSOQAAIB+mCOXRCIHAADQHYkcAADQD4lcEokcAABAdxRyAAAAnTG0EgAA6Eez/UAikQMAAOiORA4AAOiHxU6SSOQAAAC6I5EDAAC60SRySSRyAAAA3ZHIAQAA/ZDIJZHIAQAAdEciBwAA9GPGPnKJRA4AAKA7EjkAAKAf5sglkcgBAAB0RyIHAAD0QyKXRCIHAADQHYkcAADQjdYkcolEDgAAoDsKOQAAgM4YWgkAAPTDYidJJHIAAADdkcgBAAD9kMglkcgBAAB0RyIHAAB0o0nkkkjkAAAAuiORAwAA+iGRSyKRAwAA6I5EDgAA6MfMtDuwPEjkAAAAOiORAwAAumHVyoFEDgAAoDMSOQAAoB8SuSQSOQAAgO5I5AAAgH5YtTKJRA4AAKA7CjkAAIAFqKrjqurSqvrKRNuuVXVaVZ0//txlbK+qek1Vra6qc6pq/4nXHD5ef35VHT6feyvkAACAbrSZtmSPeTg+ySGz2p6d5PTW2n5JTh+Pk+SBSfYbH0cmeX0yFH5Jjk5y9yQHJDl6Q/G3KQo5AACABWitfSrJZbOaD01ywvj8hCQPnWh/cxucmWTnqtojycFJTmutXdZa+1GS03Ld4vA6LHYCAAD0Y/kvdrJ7a+3i8fklSXYfn69KcuHEdWvGto21b5JEDgAAYA5VdWRVnT3xOHJLXt9aa0kWZeM7iRwAANCNec5d2zr3au3YJMdu4cu+V1V7tNYuHodOXjq2r02y98R1e41ta5McOKv9jM3dRCIHAACw9ZycZMPKk4cnOWmi/Qnj6pX3SPKTcQjmR5M8oKp2GRc5ecDYtkkSOQAAoB/LaI5cVb0jQ5p2q6pak2H1yRcneVdVPTHJd5I8arz81CQPSrI6yRVJjkiS1tplVfWPSc4ar3t+a232AirXoZADAABYgNbaYzZy6qA5rm1JjtrI+xyX5LgtubdCDgAA6EZbRoncNJkjBwAA0BmJHAAA0A+JXBKJHAAAQHckcgAAQDfMkRtI5AAAADojkQMAAPohkUsikQMAAOiOQg4AAKAzhlYCAADdsNjJQCIHAADQGYkcAADQDYncQCIHAADQGYkcAADQDYncQCIHAADQGYkcAADQj1bT7sGyIJEDAADojEQOAADohjlyA4kcAABAZyRyAABAN9qMOXKJRA4AAKA7EjkAAKAb5sgNJHIAAACdkcgBAADdaPaRSyKRAwAA6I5CDgAAoDOGVgIAAN2w2MlAIgcAANAZiRwAANANG4IPJHIAAACdkcgBAADdaG3aPVgeJHIAAACdkcgBAADdMEduIJEDAADojEQOAADohkRuIJEDAADojEQOAADohlUrBxI5AACAzkjkAACAbpgjN5DIAQAAdEYiBwAAdKM1iVwikQMAAOiOQg4AAKAzhlYCAADdaDPT7sHyIJEDAADojEQOAADoxozFTpJI5AAAALqz0USuqv4lSdvY+dbaUxelRwAAABth+4HBpoZWnr1kvQAAAGDeNlrItdZOmDyuqpu01q5Y/C4BAADMrc1I5JJ5zJGrqntW1blJvjYe/0ZVvW7RewYAAMCc5rPYyT8nOTjJD5OktfbfSX57MTsFAAAwl9aW7rGczWvVytbahbOa1i9CXwAAAJiH+ewjd2FV3StJq6obJXlakvMWt1sAAADXZY7cYD6J3P9NclSSVUkuSvKb4zEAAABTsNlErrX2gySPXYK+AAAAbNKMfeSSzG/VyttV1SlV9f2qurSqTqqq2y1F5wAAALiu+QytfHuSdyXZI8meSd6d5B2L2SkAAIC5tFZL9ljO5lPI3aS19pbW2rrx8dYkOyx2xwAAAJjbRufIVdWu49MPV9Wzk5yYpCV5dJJTl6BvAAAAzGFTi518IUPhtiFT/LOJcy3JcxarUwAAAHNZTht1V9VfJPmTDPXRl5MckWFK2olJbpmhpnp8a+3qqto+yZuT/FaSHyZ5dGvt2wu990aHVrbW9m2t3W78OfthsRMAAGCbVVWrkjw1yV1ba7+aZGWSw5K8JMmrWmt3SPKjJE8cX/LEJD8a2181Xrdg89kQPFX1q0nulIm5ca21N1+fGwMAAGypZbb9wHZJdqyqa5LcJMnFSe6f5A/H8yckeV6S1yc5dHyeJO9J8tqqqtYWljFutpCrqqOTHJihkDs1yQOTfDpDLAgAALDNaa2traqXJ/lukiuTfCzDUMoft9bWjZetSbJqfL4qyYXja9dV1U8yDL/8wULuP59VKx+R5KAkl7TWjkjyG0l2WsjNAAAAro+l3H6gqo6sqrMnHkdu6EdV7ZIhZds3wzZtN01yyFL9O8xnaOWVrbWZqlpXVbdIcmmSvRe5XwAAAFPVWjs2ybEbOf07Sb7VWvt+klTV+5LcO8nOVbXdmMrtlWTteP3aDHXUmqraLkM49sOF9m0+idzZVbVzkjdkiAr/K8lnF3pDAACAhWpt6R6b8d0k96iqm1RVZRjFeG6ST2QY1Zgkhyc5aXx+8nic8fzHFzo/LplHItdae/L49F+r6iNJbtFaO2ehNwQAAOhda+1zVfWeDEHXuiRfzJDefSjJiVX1T2Pbm8aXvCnJW6pqdZLLMqxwuWCb2hB8/02da6391/W5MQAAwJZaTqtWttaOTnL0rOYLkhwwx7VXJXnk1rr3phK5V2ziXMuwrCaLbMc97zPtLgAAAMvMRgu51tr9lrIjAAAAm9OWUSI3TfNZ7AQAAIBlZD7bDwAAACwLy2mO3DRJ5AAAADqz2UKuBo+rqr8fj29TVddZhQUAAGCxtSV8LGfzSeRel+SeSR4zHv80yTGL1iMAAAA2aT5z5O7eWtu/qr6YJK21H1XVjRe5XwAAAGzEfAq5a6pqZcZ0sap+KcnMovYKAABgDhY7GcxnaOVrkrw/yW5V9YIkn07ywkXtFQAAABu12USutfa2qvpCkoOSVJKHttbOW/SeAQAAzGJD8MFmC7mquk2SK5KcMtnWWvvuYnYMAACAuc1njtyHMsyPqyQ7JNk3ydeT3HkR+wUAAHAdFusYzGdo5a9NHlfV/kmevGg9AgAAYJPmk8j9L621/6qquy9GZwAAADalxRy5ZH5z5J4xcbgiyf5JLlq0HgEAALBJ80nkbj7xfF2GOXPvXZzuAAAAbNxMm3YPlodNFnLjRuA3b6395RL1BwAAgM3YaCFXVdu11tZV1b2XskMAAAAbM2OOXJJNJ3KfzzAf7ktVdXKSdyf52YaTrbX3LXLfAAAAmMN85sjtkOSHSe6fX+wn15Io5AAAgCVl1crBpgq53cYVK7+SXxRwG5hiCAAAMCWbKuRWJrlZMmfJq5ADAACW3My0O7BMbKqQu7i19vwl6wkAAADzsmIT5ww+BQAAWIY2lcgdtGS9AAAAmAeLnQw2msi11i5byo4AAAAwP/PZfgAAAGBZsNjJYFNz5AAAAFiGJHIAAEA3JHIDiRwAAEBnJHIAAEA3rFo5kMgBAAB0RiIHAAB0Y0Ygl0QiBwAA0B2JHAAA0I0Zc+SSSOQAAAC6I5EDAAC60abdgWVCIgcAANAZiRwAANCNmWl3YJmQyAEAAHRGIgcAAHRjpqxamUjkAAAAuqOQAwAA6IyhlQAAQDdsPzCQyAEAAHRGIgcAAHTD9gMDiRwAAEBnJHIAAEA3Zuw+kEQiBwAA0B2JHAAA0I2ZiOQSiRwAAEB3JHIAAEA37CM3kMgBAAB0RiIHAAB0w6qVA4kcAABAZyRyAABAN2am3YFlQiIHAADQGYkcAADQDatWDiRyAAAAnVHIAQAAdEYhBwAAdGOmlu4xH1W1c1W9p6q+VlXnVdU9q2rXqjqtqs4ff+4yXltV9ZqqWl1V51TV/gv9d1DIAQAALNyrk3yktXbHJL+R5Lwkz05yemttvySnj8dJ8sAk+42PI5O8fqE3VcgBAADdmFnCx+ZU1U5JfjvJm5KktXZ1a+3HSQ5NcsJ42QlJHjo+PzTJm9vgzCQ7V9UeC/l3UMgBAADMoaqOrKqzJx5Hzrpk3yTfT/LvVfXFqnpjVd00ye6ttYvHay5Jsvv4fFWSCydev2Zs22K2HwAAALqxlBuCt9aOTXLsJi7ZLsn+Sf68tfa5qnp1fjGMcsN7tKra6rsmSOQAAAAWZk2SNa21z43H78lQ2H1vw5DJ8eel4/m1SfaeeP1eY9sWU8gBAADdaLV0j832pbVLklxYVb8yNh2U5NwkJyc5fGw7PMlJ4/OTkzxhXL3yHkl+MjEEc4sYWgkAALBwf57kbVV14yQXJDkiQ2D2rqp6YpLvJHnUeO2pSR6UZHWSK8ZrF0QhBwAAdGMp58jNR2vtS0nuOsepg+a4tiU5amvc19BKAACAzkjkAACAbiy3RG5aJHIAAACdkcgBAADd2OobsnVKIgcAANAZiRwAANCNmXns77YtkMgBAAB0RiEHAADQGUMrAQCAbth+YCCRAwAA6IxEDgAA6IZEbiCRAwAA6IxEDgAA6IYNwQcSOQAAgM5I5AAAgG7YEHwgkQMAAOiMRA4AAOiGVSsHEjkAAIDOSOQAAIBuWLVyIJEDAADojEQOAADoxoxMLolEDgAAoDsSOQAAoBtWrRxI5AAAADqjkAMAAOiMoZUAAEA3LHUykMgBAAB0RiIHAAB0w2InA4kcAABAZyRyAABAN2Zq2j1YHiRyAAAAnZHIAQAA3ZixbmUSiRwAAEB3JHIAAEA35HEDiRwAAEBnJHIAAEA37CM3kMgBAAB0RiIHAAB0w6qVA4kcAABAZyRyAABAN+RxA4kcAABAZxRyAAAAnTG0EgAA6IbtBwYSOQAAgM5I5AAAgG7YfmAgkQMAAOiMRA4AAOiGPG4gkQMAAOiMRA4AAOiGVSsHEjkAAIDOSOQAAIBuNLPkkkjkAAAAuiORAwAAumGO3EAiBwAA0BmJHAAA0I0Zc+SSSOQAAAC6I5EDAAC6IY8bSOQAAAA6o5ADAADojKGVAABANyx2MpDIAQAALFBVrayqL1bVB8fjfavqc1W1uqreWVU3Htu3H49Xj+f3uT73XZJCrqoeWlUfq6ofVtXVVbW2qt5TVYdMXNOq6ilL0R8AAKBPM0v4mKenJTlv4vglSV7VWrtDkh8leeLY/sQkPxrbXzVet2CLXshV1auSvDfJ2iR/kuR3kjw7yY5JPlxVt1/sPgBb18EPODBf/cqn8rVzP51n/dVR0+4OQBd8dsINT1XtleTBSd44HleS+yd5z3jJCUkeOj4/dDzOeP6g8foFWdQ5clV1aJKnJzmitXb8rNNvqarfT3LlYvYB2LpWrFiR17z6BTnkQY/JmjUX58zPnppTPvixnHfe+dPuGsCy5bMTtp62vObI/XOSZyW5+Xh8yyQ/bq2tG4/XJFk1Pl+V5MIkaa2tq6qfjNf/YCE3XuxE7ulJzpqjiEuStNZOaa1dNNe5qnpwVZ1WVZdW1eVVdWZVPWDWNcdX1dmz2vYZh2n+3kTbyqp6TlV9o6p+XlVrqur4Wa97SlWdP55fXVV/Mev886rqB1V196o6u6qurKpPj2Ngd6uqD1TV/1TVeVV1/1mvfcJ47WVV9aOq+kRV3XUe/36w7Bxwt7vkm9/8dr71re/mmmuuybvedVIe8vsHT7tbAMuaz07oU1UdOf7tv+Fx5MS530tyaWvtC9Po26IlclW1XZJ7Jnn5At9i3ySnjK+fSfLADEMxf7u19p9b+F7/luQJSV6a5JNJdk3y8Im+/mmSf0nyyiQfTXK/JK+oqu1bay+eeJ+bJDl2fJ+fJXlNkrck+XmSDyd5XYaK/N1VtXdr7YrxdfskeXOSbya5cZLHJPmPqrpza+2CLfxdYKr2XHXrXLjmF9+/rFl7cQ64212m2COA5c9nJ2w9WzB37XprrR2b4e//udw7yUOq6kFJdkhyiySvTrJzVW03pnJ7ZZhilvHn3knWjLXSTkl+uNC+LebQylsm2T5jfLjBOA505UTT+tbadfLR1tprJ16zIsknktw5w5Ss3PoAABzaSURBVCTBeRdyVXXH8TVPa629ZuLUOyfe+3lJjm+tPXM897Gq2inJc6rqn1trV43tOyZ5amvtk+Nr90xyTJKjW2svH9vWJPlqkvtmKO7SWnv+rN/ltCQHJHlckmvPAQAAfWitPSfJc5Kkqg5M8pettcdW1buTPCLJiUkOT3LS+JKTx+PPjuc/PlcdNF9LsWrl7M49M8k1E485Z/tW1V5VdUJVrU2ybrz2AUl+eQvvf7/x5/EbOb9Xkj2TvHtW+zszVNW/NtF2dZL/mDhePf78+BxtG8bCpqr+v6p6f1V9L8n6DL/Lr2Qjv8tkhDsz87ONdBum46K1l2Tvvfa89nivVXvkoosumWKPAJY/n52w9bQl/N8C/XWSZ1TV6gzh1pvG9jclueXY/owMC0Au2GImcj/MMORwr1ntb0lyxvj8rLleOKZWJ2eYNPj3GYqjn2VIr3bbwn7cMsnPWmuXb+T8HuPP781q33C860TbT1trk2nu1ePPH29oaK1dPS4+s0OSVNXNk3xsfL9nJPlOkqsyrGyzw1wdmoxwt7vxqmU1mxPOOvtLucMd9s0+++ydtWsvyaMedWge/wSrrwFsis9OuGFrrZ2RscYZp04dMMc1VyV55Na656IVcuNKLJ/NkKL9/UT79zIWSZtYbfMOSe6S5IGttY9saKyqHWddd1WGOWeTdpl1/MMkN62qW2ykmLt4/Dm7QNx9/HnZxjo5T/fMUMz+bmvtaxsax6Gb0J3169fnaU9/bk790NuzcsWKHH/CO3Puud+YdrcAljWfnbD1LOUcueVsUbcfyLAc5weq6vGttbdswes2FGw/39BQVbfNMKHwnInr1iTZp6p2mJjH9r9Wtswvhj0+Iclrc11rklyUoTr+8ET7o5JcnuTLW9Dvucz1u9wrwwIoU1nhBq6vD3/k4/nwRz6++QsBuJbPTmBrWtRCrrV2UlX9c5Ljq+p+GVah/EGG4Y4bCq7/meOlX8tQYL2iqv4uwxDLf8gvVnzZ4AMZhlu+cdxO4C5J/nhWH75eVceO77Vbkk8l2TnJI1prh7XWZqrqeUn+rap+mGEhkvsmeVKSv5koEBfqzPF3fENVvTRDOve8OX4XAABgM2YWvj7IDcqiL3bSWvuLDKuy7J1hgt/HMyzTv3uSB821x1xr7edJ/iDDIifvSfKPSV6UYeuAyeu+kqFwu2eGOXX3TXLEHN14coZC8HFJTs2QFG7YGiCttTckeVqShyX5YIbtAZ45a+uBBRmHkj4yya0zrFjz9CT/N79YFAUAAGCL1PVY8ZIlYLETAACWwrqr1250AYvl5HG3/YMl+/v4rd9537L9N1mK7QcAAADYihRyAAAAnVnsVSsBAAC2mpmFb9R9gyKRAwAA6IxEDgAA6EaTyCWRyAEAAHRHIgcAAHRjZtodWCYkcgAAAJ2RyAEAAN2wauVAIgcAANAZiRwAANANq1YOJHIAAACdkcgBAADdsGrlQCIHAADQGYkcAADQjdbMkUskcgAAAN2RyAEAAN2wj9xAIgcAANAZhRwAAEBnDK0EAAC6YfuBgUQOAACgMxI5AACgG81iJ0kkcgAAAN2RyAEAAN2w/cBAIgcAANAZiRwAANCN1iRyiUQOAACgOxI5AACgG/aRG0jkAAAAOiORAwAAumEfuYFEDgAAoDMSOQAAoBv2kRtI5AAAADojkQMAALphH7mBRA4AAKAzCjkAAIDOGFoJAAB0w2InA4kcAABAZyRyAABAN2wIPpDIAQAAdEYiBwAAdGPG9gNJJHIAAADdkcgBAADdkMcNJHIAAACdkcgBAADdsI/cQCIHAADQGYkcAADQDYncQCIHAADQGYkcAADQjWYfuSQSOQAAgO5I5AAAgG6YIzeQyAEAAHRGIQcAANAZQysBAIBuNEMrk0jkAAAAuqOQAwAAutFaW7LH5lTV3lX1iao6t6q+WlVPG9t3rarTqur88ecuY3tV1WuqanVVnVNV+y/030EhBwAAsDDrkjyztXanJPdIclRV3SnJs5Oc3lrbL8np43GSPDDJfuPjyCSvX+iNzZEDAAC6sZy2H2itXZzk4vH5T6vqvCSrkhya5MDxshOSnJHkr8f2N7ch7juzqnauqj3G99kiEjkAAIDrqar2SXKXJJ9LsvtEcXZJkt3H56uSXDjxsjVj2xaTyAEAAN2Yz9y1raWqjswwBHKDY1trx85x3c2SvDfJ01trl1fVtedaa62qtnqnFXIAAABzGIu26xRuk6rqRhmKuLe11t43Nn9vw5DJqtojyaVj+9oke0+8fK+xbYsZWgkAAHRjJm3JHptTQ/T2piTntdZeOXHq5CSHj88PT3LSRPsTxtUr75HkJwuZH5dI5AAAABbq3kken+TLVfWlse1vkrw4ybuq6olJvpPkUeO5U5M8KMnqJFckOWKhN1bIAQAA3WjLa9XKTyepjZw+aI7rW5Kjtsa9Da0EAADojEQOAADoxswSrlq5nEnkAAAAOiORAwAAurGc5shNk0QOAACgMxI5AACgG+bIDSRyAAAAnVHIAQAAdMbQSgAAoBsWOxlI5AAAADojkQMAALphsZOBRA4AAKAzEjkAAKAb5sgNJHIAAACdkcgBAADdMEduIJEDAADojEQOAADohjlyA4kcAABAZyRyAABAN1qbmXYXlgWJHAAAQGckcgAAQDdmzJFLIpEDAADojkQOAADoRrOPXBKJHAAAQHcUcgAAAJ0xtBIAAOiGxU4GEjkAAIDOSOQAAIBuWOxkIJEDAADojEQOAADoxoxELolEDgAAoDsSOQAAoBvNqpVJJHIAAADdkcgBAADdsGrlQCIHAADQGYkcAADQjRlz5JJI5AAAALojkQMAALphjtxAIgcAANAZiRwAANCNGYlcEokcAABAdxRyAAAAnTG0EgAA6IbFTgYSOQAAgM5I5AAAgG7YEHwgkQMAAOiMRA4AAOiGOXIDiRwAAEBnJHIAAEA3bAg+kMgBAAB0RiIHAAB0o1m1MolEDgAAoDsSOQAAoBvmyA0kcgAAAJ2RyAEAAN2wj9xAIgcAANAZiRwAANANq1YOJHIAAACdUcgBAAB0xtBKAACgGxY7GUjkAAAAOqOQAwAAutFaW7LH5lTVIVX19apaXVXPXoJf/1oKOQAAgC1UVSuTHJPkgUnulOQxVXWnpbq/Qg4AAOhGW8LHZhyQZHVr7YLW2tVJTkxy6Fb5JefBYifL3Lqr19a0+wAbU1VHttaOnXY/AHrhcxOuv6X8+7iqjkxy5ETTsRP/Da9KcuHEuTVJ7r5UfZPIAdfHkZu/BIAJPjehI621Y1trd514LJsvYhRyAAAAW25tkr0njvca25aEQg4AAGDLnZVkv6rat6punOSwJCcv1c3NkQOuj2UzvACgEz434Qaitbauqp6S5KNJViY5rrX21aW6f9kZHQAAoC+GVgIAAHRGIQcAANAZhRwAAEBnFHIAAACdUcgBqaodquqW0+4HAADzo5CDbVxVrUhyUpIzqmr3afcHAIDNU8jBNq61NpPk5UlunuRExRzA5lXVymn3Adi22UcOSFVVkvskeXuS1Uke3Vr73nR7BbA8VdXK1tr68flzk9whyW2THJfk/7XWLp5m/4Btg0QOSBu+0fmPJH+Y4Q+Sd0rmAK6rqmqiiDsxyZ8muTzJRUlemOQFVbXP1DoIbDMUcrCNGlO4a43F3H8meWwUcwBzGj8rU1UvTLJ/kke21p6a5NNJViU5KMk/VdVtptdLYFugkINt0DgsaMMfI7cYH9uP3zJ/Noo5gI2qqr2S7Jnk+a21z1fVXyf5lySPTPKWJI/KUMzddordBG7gzJGDbcysuR0vTnJAklsmuSDJk1prl1TVjZLcK8nbYs4cwHVU1WOSfDzJnZK8I8nftdbeMJ47I8OXYf+V5M9ba9+ZVj+BGy6JHGxD5pjbcViSUzJ8k3yvJP9ZVXdorV2TXwyzvG2Sj1TVblPqNsDUbGx1ytbaO8YvuPZP8r0kH5s4fVWS/0lyqyTXLHongW2SQg62IRPDKZ+d5NczJG2vSrJLhu0Htk/yqbGYW5ehmPvTJDdOsuN0eg0wHbNGMDy8qo6oqv1mzTHeO8mtN6RuVbVrkp9k+Ox8cGvtoiXvOLBNMLQStjFVdZMkz0iyrrX24qp6RpIXJ3lChm+V35nkp0l+p7X2raraLsmNWmtXTq3TAFM0jmD4vSTrk+yQ5HlJjm+tXVxVv5zkU0nOzZDK3TXJfZPs31q7cDo9BrYF2027A8DSGb9FvjLJh5Ksqao7J3lqkmcmeWdrrVXVB5P8UZKvVtWvt9ZWJ1k3rT4DLLVxGPqGEQy/nWG+20OSfDfJ45K8IMkuVfXq1to3quqIJC9L8qQkP0xykCIOWGwKObgBmxwWlPyvoZVfGou2A5PcJMmn2i/i+UuTnDQ+N/wa2KbM/tzM8LfSmUk+MX5OPq+qrkzyoiQrquqlrbUPV9VpSW6d5PLW2uVL33NgW6OQgxuoqloxMbfj6Uluk2EFtc+01i4YL9shyUySPavqnCS3SHL7DFsQvLq19vOl7znAdMxaEOpFGQqz22cYdr59VV3dWptprb2kqmaSvCTJ+qr619bat5KsmVrngW2OOXJwA1dVb0vyu0l+nGSnJF9O8rettc9V1U4ZNrG9UYb5HTdOcu8kdxuHVAJsE8Yvv2bG52/LsLH3BUlulmS/JA9vrZ0667pnZhhS+U8Z9pQzDB1YMoZNwQ3M5GpqVXW7JKuS/EGSO2aYC3eTJMdU1X1aaz9Jcr8k52TYS267JPdRxAHbmonibKckP0vy8Axfgh2WYb+4t1TVga21mapaMb7mFUmenuRERRyw1CRycAMya6nsHZLskWFS/p+11n46tj88w6qVOyT5i9bap6rqxhkWNNne6pTAtqqqXprkiAxzhR/SWvvm2H6bJK9Pco8MydwZk8kcwDRI5OAGYtbcjtcn+X9JzkhypyQ33XBda+29SV6RYcPal43fMG+Y96GIA7ZJ48bfFyb5dpLdMnxGbhhy+d0MK1J+NsmJVfW7ijhg2hRycAMwJnEbVqR8eZKHZhgu+Y0MG38/q6puveH61tr7MszruFmSo8f0DmCbsWF45AbjF2FvTPK6DCMUPlBV249DKWuimDs/yb+Oe3ICTI1VK+EGYCKJ2zfJLkme3Fp7/9h2TIY5HldW1Wtaa98bX/OBqlqf5Muttaum1HWAJTdrGPqeSVqGHVouqaq3Z1jN93lJPlpVh7TWrhqLuQur6rAkK1prV0ztFwCIRA66NvmNclU9J8k3k/yfJGs3tLfWjkry3iR/nOSpVbX7xLlTWmvfXrIOA0zZrK1ZXpfkg0m+kuSMqvrjcduVtyX5hwzbtnx0TObaWMyttdk3sBxI5KBTs5bAfnyStye5b5IHJPmtcdPvq5Oktfbn42KWj09y06p6YWvt0il1HWBqJj4335rhM/NVGf4eukuSN1TVnZI8J8k7Mnzh/awkn6+qA+ytCSwnCjno0Pit8IY/Ro5Pcs8MS2X/UZL3J/nrJF+uqs9suG4s5m6W5OAMK1kCbJOq6m5J7pXkGa21d49tOyT5TIbCbm1r7VXjMMvtkxyZYXPw70ypywDXYfsB6MxYxG1Y2OROGSbmvyjJJ1prV4+Lmnwo+f/bu/dozeb7juPvz7iMyTQIcUtDNDRxW8KUGqMR1CJYodOwtJNW4tKQYkJWlrRLl6gmQViklluaMbG0LqFEJG2NkqoRSdwWyrRJqMsiHWXGbRiX4ds/9u8ZzzodjDHOc86c9+uvc35772f/nvPHXuezf5cvq9Nto704zLVr1uutk5OksSjJJ4B/Az5RVbP72gN8i+7ZuV1V/bKVZ5nQ6m5K0ojhGjlplOkLcTOBv6UbWb+9hbhxVTUX2Bt4BrgQmNK/ls4QJ2ksaWUFhlpAVytus97zse8l2Y/onqvrA7TyLIY4SSOOQU4avf4D+H3gY8Cm0K39aP+MPA7sAzwJXAPsMLBeStKADNmdcnrbcZKqugO4A/gL4KOtrTdF6SXgKeDV4e+xJC09g5w0CgzZnXIcQFWdSTf9ZyJwWJJ1W3v1hbmpwF3AE8Pfa0kanPYc7IW4y4EjgT/oq6l5MPA8cFWSTyVZN8mmwKGt/f5B9FuSlpZr5KQRbsgb5fcAq7fpk73jfw6cDZwBnFJVT7b2tFC3+HpJGmuSnE5XS/MAurqZC/qejxsD3wUm0dWOm0tXi3PPqrp7QF2WpKXirpXSCDYkxH2Lrkbcpklupfvn4wdVdW4bpTurOy0nV9WTvWlChjhJY1WSteiemzOr6qe99r7n40PArkn2BzYAXgBusL6mpNHAICeNUEOmBV0C7ERXpPYSunpwJwNbJ/laVZ2d5DW6UbmJSY6vqnmD6rskjRCr0a0hvhxefznWNyKX6vzjYLspSW+fa+SkESTJakk2H9I2BdgN+CJwfFWdAUym2zr7QOCg9s/JuXRFbA8AlrRLmyStsIasJU778Xngabqpk7QQt3LfxibHJPncsHZUkpYTg5w0QrQtsmcClyfZtu8fjfWAtYBb2xvk8VX1EnA48AjwZ0Bg8QYom1TV/w7/N5CkwenVy0xyBrBPklVb2YDTgGlJprfzFrXz3kf3UmzPJBMG1G1JWmYGOWmEaNMo/51ujcYZSSa1Q7+kG2HbtZ33UgtzLwPHA9sAk3tvoKvq6WHvvCSNAC2Q7QmcD+zcmq8BZtA9V89IsmOSfYFz6Eq4nFRVCwfSYUl6B9y1UhoB2lSf3lviP6WbRrkA+DJwJ3At3YuXE6rqlr7rPg2cB0ypKrfKljSm9BXxJsm4VktzTeAquvpwn62q65NsRLe2+Ct0MxgWAI+34+5OKWlUMshJA/RGpQGSfBY4mu6fjUOAtYEr6IqAz6iqHyTZhG5N3A7AblVlrThJY0Z/iOtrW7mqFrUwdzXwEeCgqrq+Hd+wtc0DHu2Va5Gk0cggJw1IkonA9+neCn8XeKCqHu47/jngGLqF+p8BNgZOpVu0P59uCuaawB5Vdddw9l2SRook3wTGV9UX2+/9Ye4aumfnocDsqnpxcD2VpOXLICcNSJK/oVvjBnAP3aYmFwF3VtX32jn7AScBT9GNzD0D7Ei3i+X9wKyqemCYuy5JI0KrE3cusD1wcVWd0Np7YW5L4F+Bx4ATgWutrSlpRWGQkwYkyQeBrwKfAq4DbgaOoytK+wBwPXA2sC+wH926julVdc+SphRJ0oruDaZTbkQ3zXxP4JKq+qu+YxPonq87Ab8AfqeqXhjGLkvSu8ZdK6UBqapH6YLcdXRh7f6q2hTYhW6Ebg+6NXH7AhsBmwAXJdnSECdprGlriqvv93Ftg5NHgG/SjbxNS/L1vsveDzwIbAHsboiTtCJZedAdkMayqvp1kq8A44GrkxxeVZcCf9LeJE8FtgM2p5t6uSbdBiiSNGb0bwyV5AS6HSk3AH6Y5JKqejDJycAi4KAkHwb+Gdib7hk63/qaklY0Tq2URoAk6wNnAnsBR1bVxUOOrw3sDvy8qh4a/h5K0mAMKTFwGTAFuAxYi+65eCdwdFU91nal/CPgKLoXZPOAaZYYkLQiMshJI8SQMHdEVV3W2lepqlcG2jlJGrAkXwMOoCsn8PMkxwKnA48Cc4BD2yyHVYAJwAeBuVU1f2CdlqR3kWvkpBGiquYCxwL/Apyf5MDWboiTNGYkmZjk4CTr9LV9gG4E7tQW4o4DTqMrzXIesDNwXpL1q+qVqnq2quYY4iStyAxy0gjSF+Z+BFya5NMD7pIkDbejgAuAg9u0coC5wI/p1sR9nK7G5pFVdVlVnQLcDuwKXNVmN0jSCs/NTqQRpqrmtrfNLwL3Dro/kjScqurUJBsAJwPjklxQVU8kubKqKsk04Gm6Ei0984H/AhYCqw5/ryVp+BnkpBGorfM4oqoWDbovkvRuSzKebhOTycA5VXVMkgBfb8dnVNWT7fQN6Xbwnd+OrQm8CnwDuLGqnh7u/kvSILjZiSRJGpgk7wUuBz4AfBg4pKquaMfOAo4Ejgd6I3MfAm6jq7N5C7AZ3bTKSa2mnCSNCY7ISZKkgWgh7g66nSdPoJsuubBXcqCqpifpjbaRZGZVPZxkKvBt4I/pplnuZoiTNNYY5CRJ0rBLsipdPbhHgYOBR9oauMUlV5JsXFXHJnmF18Pcd6rqJ0m2BdYAXqqq5wb0NSRpYAxykiRpELYEfhM4iddD3Li+EHcccFSSL1XVcd2SOb4BvJbk76vqf4An3+jDJWlFZ5CTJEmDMIluTdwt1RbsV9VrsLj493F0ZQfOSbKohblXgVOAl5Oc1TtfksYig5wkSRqEVenKrDwP0FsXl2Rr4JPA/lV1TZIbgQvaaN1fJlkJmGWIkzTWuWulJEkadkm2B2YBJ1bVWX3tE4B1gcd6JViSPAtcXFVfGEhnJWkEGjfoDkiSpDHpv4H7gYNaqAOgqhZW1cNVtSjJSkk2B34G3ATdyN1guitJI4tBTpIkDbuqmgccAWwBnJhk0hJOWx34Et0I3ex2nVOJJAmnVkqSpAFKshdwJXA3MAO4kO5F82TgMGAq8HtVdc+g+ihJI5FBTpIkDVSbWjkT2AB4AXgNeA54GTjYECdJ/59BTpIkDVyS9YCtgCl0I3K3APdU1eMD7ZgkjVAGOUmSJEkaZdzsRJIkjQj9O1K6O6UkvTlH5CRJkiRplHFETpIkSZJGGYOcJEmSJI0yBjlJkiRJGmUMcpIkSZI0yhjkJEmSJGmUMchJkt6xJK8muSvJvUmuSPKed/BZFybZv/08I8kWb3LuLkmmLMM9Hkry/qVtH3LOgrd5rxOTfPnt9lGSpDdjkJMkLQ8Lq2qbqtoKeBk4ov9gkpWX5UOr6rCqmvMmp+wCvO0gJ0nSaGeQkyQtb7OBTdto2ewk1wBzkqyU5LQktyW5J8nh0BV+TnJ2kl8kuR5Yt/dBSW5Msl37+ZNJ7kxyd5IbkmxMFxiPbaOBH0+yTpIr2z1uS7JTu3btJNcluS/JDOAti00nuTrJHe2azw85dmZrvyHJOq1tkyTXtmtmJ9lsefwxJUlakmV6QypJ0pK0kbe9gGtb0yRgq6p6sIWhZ6pq+yTjgZ8kuQ7YFvgosAWwHjAHmDnkc9cBvgPs3D5rraqan+R8YEFVnd7OuwQ4s6puTrIRMAvYHPgqcHNVnZRkH+DQpfg6h7R7TABuS3JlVc0DJgK3V9WxSU5on30U8HfAEVX1qyQ7AOcCuy3Dn1GSpLdkkJMkLQ8TktzVfp4NXEA35fHWqnqwte8BbN1b/wasAfw2sDNwaVW9Cvw6yY+X8PmTgZt6n1VV89+gH7sDWySLB9xWT/Ib7R5/2K79pyRPLcV3mp5kavt5w9bXecBrwPda+z8AV7V7TAGu6Lv3+KW4hyRJy8QgJ0laHhZW1Tb9DS3QPN/fBBxdVbOGnLf3cuzHOGByVb24hL4stSS70IXCHavqhSQ3Aqu9wenV7vv00L+BJEnvFtfISZKGyyzgC0lWAUjykSQTgZuAA9saug2AXZdw7c+AnZP8Vrt2rdb+HPDevvOuA47u/ZKkF6xuAqa1tr2A971FX9cAnmohbjO6EcGecUBvVHEa3ZTNZ4EHkxzQ7pEkH3uLe0iStMwMcpKk4TKDbv3bnUnuBb5NNzPk+8Cv2rGLgJ8OvbCqngA+TzeN8W5en9r4Q2Bqb7MTYDqwXdtMZQ6v757513RB8D66KZaPvEVfrwVWTvKfwCl0QbLneeB323fYDTiptX8GOLT17z5gv6X4m0iStExSVYPugyRJkiTpbXBETpIkSZJGGYOcJEmSJI0yBjlJkiRJGmUMcpIkSZI0yhjkJEmSJGmUMchJkiRJ0ihjkJMkSZKkUcYgJ0mSJEmjzP8BlcrCq3zpeoIAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1080x720 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pryRZOM_O64w"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}