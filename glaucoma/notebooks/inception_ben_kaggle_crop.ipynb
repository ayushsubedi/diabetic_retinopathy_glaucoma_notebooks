{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "inceptionv3_ben.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "71d8e2246aad477fbbab995c404ede92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a511bf1a592e49ee86676aecd68c70d6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5f69daad0ce847649883b8729dc8923a",
              "IPY_MODEL_ff957dbe91b14ecc95985a44ac3cfce8"
            ]
          }
        },
        "a511bf1a592e49ee86676aecd68c70d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5f69daad0ce847649883b8729dc8923a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_afba5e52e8c3462696827e88eadafab3",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 108857766,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 108857766,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1560115405d0476086b0f661c04d4558"
          }
        },
        "ff957dbe91b14ecc95985a44ac3cfce8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_efadeb74de884cab9b417074e27a1e03",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 104M/104M [00:13&lt;00:00, 7.80MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_33588ccf14a648308d46db6c7f2cd529"
          }
        },
        "afba5e52e8c3462696827e88eadafab3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1560115405d0476086b0f661c04d4558": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "efadeb74de884cab9b417074e27a1e03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "33588ccf14a648308d46db6c7f2cd529": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqHnaptr-kuA",
        "outputId": "10395cd1-6c0d-4b42-d43c-9999cf82e3c6"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon May 10 09:34:25 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   46C    P8    10W /  70W |      3MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7-9XFsaZnKQ"
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oGJ2hstm39V"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from imutils import contours\n",
        "from skimage import measure\n",
        "import imutils\n",
        "import os\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import copy\n",
        "import time\n",
        "\n",
        "import torch\n",
        "from torchvision import datasets, models, transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader, Dataset, TensorDataset, Subset, WeightedRandomSampler\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import pickle"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u899MaWr-ZF0"
      },
      "source": [
        "# Top level data directory. Here we assume the format of the directory conforms\n",
        "#   to the ImageFolder structure\n",
        "data_dir = '/content/drive/MyDrive/disk_dataset_kaggle'\n",
        "\n",
        "# Models to choose from [resnet, alexnet, vgg, squeezenet, densenet, inception]\n",
        "model_name = \"inception\"\n",
        "# inception\n",
        "input_size = 299\n",
        "\n",
        "# Number of classes in the dataset\n",
        "num_classes = 2\n",
        "\n",
        "# Batch size for training (change depending on how much memory you have)\n",
        "batch_size = 32\n",
        "\n",
        "# Number of epochs to train for\n",
        "num_epochs = 10\n",
        "\n",
        "# Flag for feature extracting. When False, we finetune the whole model,\n",
        "#   when True we only update the reshaped layer params\n",
        "feature_extract = False\n",
        "\n",
        "num_workers = 2\n",
        "\n",
        "train_size = 0.60\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYnO7mxJZywE"
      },
      "source": [
        "\n",
        "class ben_color(object):\n",
        "    def __call__(self, img, sigmaX=10):\n",
        "        \"\"\"\n",
        "        :param img: PIL): Image \n",
        "\n",
        "        :return: Normalized image\n",
        "        \"\"\"\n",
        "\n",
        "        img = np.asarray(img)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        img = self.crop_image_from_gray(img)\n",
        "        img = cv2.resize(img, (input_size, input_size))\n",
        "        img = cv2.addWeighted (img, 4, cv2.GaussianBlur(img, (0,0), sigmaX), -4, 128)\n",
        "        return Image.fromarray(img)\n",
        "\n",
        "    def crop_image_from_gray(self, img, tol=7):\n",
        "        if img.ndim ==2:\n",
        "            mask = img>tol\n",
        "            return img[np.ix_(mask.any(1),mask.any(0))]\n",
        "        elif img.ndim==3:\n",
        "            gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "            mask = gray_img>tol\n",
        "            \n",
        "            check_shape = img[:,:,0][np.ix_(mask.any(1),mask.any(0))].shape[0]\n",
        "            if (check_shape == 0):\n",
        "                return img \n",
        "            else:\n",
        "                img1=img[:,:,0][np.ix_(mask.any(1),mask.any(0))]\n",
        "                img2=img[:,:,1][np.ix_(mask.any(1),mask.any(0))]\n",
        "                img3=img[:,:,2][np.ix_(mask.any(1),mask.any(0))]\n",
        "                img = np.stack([img1,img2,img3],axis=-1)\n",
        "            return img\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__+'()'"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jj74frLDrZd"
      },
      "source": [
        "# Todos: shuffle in validation set\n",
        "# add more augmentations  \n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "        ben_color(),\n",
        "        transforms.RandomRotation(degrees=(0, 360)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomVerticalFlip(),\n",
        "        transforms.Resize((input_size, input_size)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "\n",
        "\n",
        "valid_transform = transforms.Compose([\n",
        "        ben_color(),\n",
        "        transforms.Resize((input_size, input_size)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "\n",
        "\n",
        "class DR(Dataset):\n",
        "    def __init__(self, dataset, transform=None):\n",
        "        self.dataset = dataset\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        if self.transform:\n",
        "            x = self.transform(dataset[index][0])\n",
        "        else:\n",
        "            x = dataset[index][0]\n",
        "        y = dataset[index][1]\n",
        "        return x, y\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(dataset)\n",
        "    \n",
        "\n",
        "dataset = ImageFolder(data_dir)\n",
        "\n",
        "traindataset = DR(dataset, train_transform)\n",
        "valdataset = DR(dataset, valid_transform)\n",
        "testdataset = DR(dataset, valid_transform)\n",
        "\n",
        "# Create the index splits for training, validation and test\n",
        "\n",
        "num_train = len(dataset)\n",
        "indices = list(range(num_train))\n",
        "split = int(np.floor(train_size * num_train))\n",
        "split2 = int(np.floor((train_size+(1-train_size)/2) * num_train))\n",
        "np.random.shuffle(indices)\n",
        "train_idx, valid_idx, test_idx = indices[:split], indices[split:split2], indices[split2:]\n",
        "\n",
        "traindata = Subset(traindataset, indices=train_idx)\n",
        "valdata = Subset(valdataset, indices=valid_idx)\n",
        "testdata = Subset(testdataset, indices=test_idx)\n",
        "\n",
        "class_weights = []\n",
        "for root, subdir, files in os.walk(data_dir):\n",
        "  if len(files)>0:\n",
        "    class_weights.append(1/len(files))\n",
        "\n",
        "sample_weights = [0] * len(traindata)\n",
        "\n",
        "for idx, (data, label) in enumerate(traindata):\n",
        "  class_weight = class_weights[label]\n",
        "  sample_weights[idx] = class_weight\n",
        "\n",
        "\n",
        "with open('/content/drive/MyDrive/clean_weights.pkl', 'wb') as f:\n",
        "  pickle.dump(sample_weights, f)\n",
        "\n",
        "with open('/content/drive/MyDrive/clean_weights.pkl', 'rb') as f:\n",
        "  sample_weights = pickle.load(f)\n",
        "\n",
        "sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)\n",
        "\n",
        "trainLoader = torch.utils.data.DataLoader(traindata, sampler=sampler, batch_size=batch_size, \n",
        "                                          num_workers=num_workers, drop_last=True)\n",
        "valLoader = torch.utils.data.DataLoader(valdata, batch_size=batch_size, \n",
        "                                          num_workers=num_workers, drop_last=True)\n",
        "testLoader = torch.utils.data.DataLoader(testdata, batch_size=batch_size,\n",
        "                                          num_workers=num_workers, drop_last=True)\n",
        "dataloaders = {'train': trainLoader, 'val': valLoader, 'test': testLoader}"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyThMaR4nbLF"
      },
      "source": [
        "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False):\n",
        "    since = time.time()\n",
        "\n",
        "    val_acc_history = []\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    # Get model outputs and calculate loss\n",
        "                    # Special case for inception because in training it has an auxiliary output. In train\n",
        "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
        "                    #   but in testing we only consider the final output.\n",
        "                    if is_inception and phase == 'train':\n",
        "                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
        "                        outputs, aux_outputs = model(inputs)\n",
        "                        loss1 = criterion(outputs, labels)\n",
        "                        loss2 = criterion(aux_outputs, labels)\n",
        "                        loss = loss1 + 0.4*loss2\n",
        "                    else:\n",
        "                        outputs = model(inputs)\n",
        "                        loss = criterion(outputs, labels)\n",
        "\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
        "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            if phase == 'val':\n",
        "                val_acc_history.append(epoch_acc)\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, val_acc_history"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75VdlQ8ln1a9"
      },
      "source": [
        "def set_parameter_requires_grad(model, feature_extracting):\n",
        "    if feature_extracting:\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "71d8e2246aad477fbbab995c404ede92",
            "a511bf1a592e49ee86676aecd68c70d6",
            "5f69daad0ce847649883b8729dc8923a",
            "ff957dbe91b14ecc95985a44ac3cfce8",
            "afba5e52e8c3462696827e88eadafab3",
            "1560115405d0476086b0f661c04d4558",
            "efadeb74de884cab9b417074e27a1e03",
            "33588ccf14a648308d46db6c7f2cd529"
          ]
        },
        "id": "Y4O8Uqptn8Sb",
        "outputId": "7cb0053e-70b2-489b-bcce-057e0cfd77f2"
      },
      "source": [
        "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
        "    # Initialize these variables which will be set in this if statement. Each of these\n",
        "    #   variables is model specific.\n",
        "    model_ft = None\n",
        "    input_size = 0\n",
        "\n",
        "    if model_name == \"resnet\":\n",
        "        \"\"\" Resnet18\n",
        "        \"\"\"\n",
        "        model_ft = models.resnet18(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.fc.in_features\n",
        "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"alexnet\":\n",
        "        \"\"\" Alexnet\n",
        "        \"\"\"\n",
        "        model_ft = models.alexnet(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.classifier[6].in_features\n",
        "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"vgg\":\n",
        "        \"\"\" VGG11_bn\n",
        "        \"\"\"\n",
        "        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.classifier[6].in_features\n",
        "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"squeezenet\":\n",
        "        \"\"\" Squeezenet\n",
        "        \"\"\"\n",
        "        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
        "        model_ft.num_classes = num_classes\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"densenet\":\n",
        "        \"\"\" Densenet\n",
        "        \"\"\"\n",
        "        model_ft = models.densenet121(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.classifier.in_features\n",
        "        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"inception\":\n",
        "        \"\"\" Inception v3\n",
        "        Be careful, expects (299,299) sized images and has auxiliary output\n",
        "        \"\"\"\n",
        "        model_ft = models.inception_v3(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        # Handle the auxilary net\n",
        "        num_ftrs = model_ft.AuxLogits.fc.in_features\n",
        "        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n",
        "        # Handle the primary net\n",
        "        num_ftrs = model_ft.fc.in_features\n",
        "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
        "        input_size = 299\n",
        "\n",
        "    else:\n",
        "        print(\"Invalid model name, exiting...\")\n",
        "        exit()\n",
        "\n",
        "    return model_ft, input_size\n",
        "\n",
        "# Initialize the model for this run\n",
        "model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n",
        "\n",
        "# Print the model we just instantiated\n",
        "print(model_ft)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/inception_v3_google-1a9a5a14.pth\" to /root/.cache/torch/hub/checkpoints/inception_v3_google-1a9a5a14.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "71d8e2246aad477fbbab995c404ede92",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=108857766.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Inception3(\n",
            "  (Conv2d_1a_3x3): BasicConv2d(\n",
            "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
            "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (Conv2d_2a_3x3): BasicConv2d(\n",
            "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (Conv2d_2b_3x3): BasicConv2d(\n",
            "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (Conv2d_3b_1x1): BasicConv2d(\n",
            "    (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (Conv2d_4a_3x3): BasicConv2d(\n",
            "    (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (Mixed_5b): InceptionA(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_1): BasicConv2d(\n",
            "      (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_2): BasicConv2d(\n",
            "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_5c): InceptionA(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_1): BasicConv2d(\n",
            "      (conv): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_2): BasicConv2d(\n",
            "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_5d): InceptionA(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_1): BasicConv2d(\n",
            "      (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_2): BasicConv2d(\n",
            "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_6a): InceptionB(\n",
            "    (branch3x3): BasicConv2d(\n",
            "      (conv): Conv2d(288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_6b): InceptionC(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_2): BasicConv2d(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_3): BasicConv2d(\n",
            "      (conv): Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_4): BasicConv2d(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_5): BasicConv2d(\n",
            "      (conv): Conv2d(128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_6c): InceptionC(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_2): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_3): BasicConv2d(\n",
            "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_4): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_5): BasicConv2d(\n",
            "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_6d): InceptionC(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_2): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_3): BasicConv2d(\n",
            "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_4): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_5): BasicConv2d(\n",
            "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_6e): InceptionC(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_2): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_3): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_4): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_5): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (AuxLogits): InceptionAux(\n",
            "    (conv0): BasicConv2d(\n",
            "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (conv1): BasicConv2d(\n",
            "      (conv): Conv2d(128, 768, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fc): Linear(in_features=768, out_features=2, bias=True)\n",
            "  )\n",
            "  (Mixed_7a): InceptionD(\n",
            "    (branch3x3_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_2): BasicConv2d(\n",
            "      (conv): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7x3_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7x3_2): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7x3_3): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7x3_4): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_7b): InceptionE(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_1): BasicConv2d(\n",
            "      (conv): Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_2a): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_2b): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3a): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3b): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_7c): InceptionE(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_1): BasicConv2d(\n",
            "      (conv): Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_2a): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_2b): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3a): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3b): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (fc): Linear(in_features=2048, out_features=2, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6151ULNdzuq",
        "outputId": "520d185d-a651-4ba3-baf7-936aa29121e6"
      },
      "source": [
        "# Send the model to GPU\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "# Gather the parameters to be optimized/updated in this run. If we are\n",
        "#  finetuning we will be updating all parameters. However, if we are\n",
        "#  doing feature extract method, we will only update the parameters\n",
        "#  that we have just initialized, i.e. the parameters with requires_grad\n",
        "#  is True.\n",
        "params_to_update = model_ft.parameters()\n",
        "print(\"Params to learn:\")\n",
        "if feature_extract:\n",
        "    params_to_update = []\n",
        "    for name,param in model_ft.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            params_to_update.append(param)\n",
        "            print(\"\\t\",name)\n",
        "else:\n",
        "    for name,param in model_ft.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            print(\"\\t\",name)\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Params to learn:\n",
            "\t Conv2d_1a_3x3.conv.weight\n",
            "\t Conv2d_1a_3x3.bn.weight\n",
            "\t Conv2d_1a_3x3.bn.bias\n",
            "\t Conv2d_2a_3x3.conv.weight\n",
            "\t Conv2d_2a_3x3.bn.weight\n",
            "\t Conv2d_2a_3x3.bn.bias\n",
            "\t Conv2d_2b_3x3.conv.weight\n",
            "\t Conv2d_2b_3x3.bn.weight\n",
            "\t Conv2d_2b_3x3.bn.bias\n",
            "\t Conv2d_3b_1x1.conv.weight\n",
            "\t Conv2d_3b_1x1.bn.weight\n",
            "\t Conv2d_3b_1x1.bn.bias\n",
            "\t Conv2d_4a_3x3.conv.weight\n",
            "\t Conv2d_4a_3x3.bn.weight\n",
            "\t Conv2d_4a_3x3.bn.bias\n",
            "\t Mixed_5b.branch1x1.conv.weight\n",
            "\t Mixed_5b.branch1x1.bn.weight\n",
            "\t Mixed_5b.branch1x1.bn.bias\n",
            "\t Mixed_5b.branch5x5_1.conv.weight\n",
            "\t Mixed_5b.branch5x5_1.bn.weight\n",
            "\t Mixed_5b.branch5x5_1.bn.bias\n",
            "\t Mixed_5b.branch5x5_2.conv.weight\n",
            "\t Mixed_5b.branch5x5_2.bn.weight\n",
            "\t Mixed_5b.branch5x5_2.bn.bias\n",
            "\t Mixed_5b.branch3x3dbl_1.conv.weight\n",
            "\t Mixed_5b.branch3x3dbl_1.bn.weight\n",
            "\t Mixed_5b.branch3x3dbl_1.bn.bias\n",
            "\t Mixed_5b.branch3x3dbl_2.conv.weight\n",
            "\t Mixed_5b.branch3x3dbl_2.bn.weight\n",
            "\t Mixed_5b.branch3x3dbl_2.bn.bias\n",
            "\t Mixed_5b.branch3x3dbl_3.conv.weight\n",
            "\t Mixed_5b.branch3x3dbl_3.bn.weight\n",
            "\t Mixed_5b.branch3x3dbl_3.bn.bias\n",
            "\t Mixed_5b.branch_pool.conv.weight\n",
            "\t Mixed_5b.branch_pool.bn.weight\n",
            "\t Mixed_5b.branch_pool.bn.bias\n",
            "\t Mixed_5c.branch1x1.conv.weight\n",
            "\t Mixed_5c.branch1x1.bn.weight\n",
            "\t Mixed_5c.branch1x1.bn.bias\n",
            "\t Mixed_5c.branch5x5_1.conv.weight\n",
            "\t Mixed_5c.branch5x5_1.bn.weight\n",
            "\t Mixed_5c.branch5x5_1.bn.bias\n",
            "\t Mixed_5c.branch5x5_2.conv.weight\n",
            "\t Mixed_5c.branch5x5_2.bn.weight\n",
            "\t Mixed_5c.branch5x5_2.bn.bias\n",
            "\t Mixed_5c.branch3x3dbl_1.conv.weight\n",
            "\t Mixed_5c.branch3x3dbl_1.bn.weight\n",
            "\t Mixed_5c.branch3x3dbl_1.bn.bias\n",
            "\t Mixed_5c.branch3x3dbl_2.conv.weight\n",
            "\t Mixed_5c.branch3x3dbl_2.bn.weight\n",
            "\t Mixed_5c.branch3x3dbl_2.bn.bias\n",
            "\t Mixed_5c.branch3x3dbl_3.conv.weight\n",
            "\t Mixed_5c.branch3x3dbl_3.bn.weight\n",
            "\t Mixed_5c.branch3x3dbl_3.bn.bias\n",
            "\t Mixed_5c.branch_pool.conv.weight\n",
            "\t Mixed_5c.branch_pool.bn.weight\n",
            "\t Mixed_5c.branch_pool.bn.bias\n",
            "\t Mixed_5d.branch1x1.conv.weight\n",
            "\t Mixed_5d.branch1x1.bn.weight\n",
            "\t Mixed_5d.branch1x1.bn.bias\n",
            "\t Mixed_5d.branch5x5_1.conv.weight\n",
            "\t Mixed_5d.branch5x5_1.bn.weight\n",
            "\t Mixed_5d.branch5x5_1.bn.bias\n",
            "\t Mixed_5d.branch5x5_2.conv.weight\n",
            "\t Mixed_5d.branch5x5_2.bn.weight\n",
            "\t Mixed_5d.branch5x5_2.bn.bias\n",
            "\t Mixed_5d.branch3x3dbl_1.conv.weight\n",
            "\t Mixed_5d.branch3x3dbl_1.bn.weight\n",
            "\t Mixed_5d.branch3x3dbl_1.bn.bias\n",
            "\t Mixed_5d.branch3x3dbl_2.conv.weight\n",
            "\t Mixed_5d.branch3x3dbl_2.bn.weight\n",
            "\t Mixed_5d.branch3x3dbl_2.bn.bias\n",
            "\t Mixed_5d.branch3x3dbl_3.conv.weight\n",
            "\t Mixed_5d.branch3x3dbl_3.bn.weight\n",
            "\t Mixed_5d.branch3x3dbl_3.bn.bias\n",
            "\t Mixed_5d.branch_pool.conv.weight\n",
            "\t Mixed_5d.branch_pool.bn.weight\n",
            "\t Mixed_5d.branch_pool.bn.bias\n",
            "\t Mixed_6a.branch3x3.conv.weight\n",
            "\t Mixed_6a.branch3x3.bn.weight\n",
            "\t Mixed_6a.branch3x3.bn.bias\n",
            "\t Mixed_6a.branch3x3dbl_1.conv.weight\n",
            "\t Mixed_6a.branch3x3dbl_1.bn.weight\n",
            "\t Mixed_6a.branch3x3dbl_1.bn.bias\n",
            "\t Mixed_6a.branch3x3dbl_2.conv.weight\n",
            "\t Mixed_6a.branch3x3dbl_2.bn.weight\n",
            "\t Mixed_6a.branch3x3dbl_2.bn.bias\n",
            "\t Mixed_6a.branch3x3dbl_3.conv.weight\n",
            "\t Mixed_6a.branch3x3dbl_3.bn.weight\n",
            "\t Mixed_6a.branch3x3dbl_3.bn.bias\n",
            "\t Mixed_6b.branch1x1.conv.weight\n",
            "\t Mixed_6b.branch1x1.bn.weight\n",
            "\t Mixed_6b.branch1x1.bn.bias\n",
            "\t Mixed_6b.branch7x7_1.conv.weight\n",
            "\t Mixed_6b.branch7x7_1.bn.weight\n",
            "\t Mixed_6b.branch7x7_1.bn.bias\n",
            "\t Mixed_6b.branch7x7_2.conv.weight\n",
            "\t Mixed_6b.branch7x7_2.bn.weight\n",
            "\t Mixed_6b.branch7x7_2.bn.bias\n",
            "\t Mixed_6b.branch7x7_3.conv.weight\n",
            "\t Mixed_6b.branch7x7_3.bn.weight\n",
            "\t Mixed_6b.branch7x7_3.bn.bias\n",
            "\t Mixed_6b.branch7x7dbl_1.conv.weight\n",
            "\t Mixed_6b.branch7x7dbl_1.bn.weight\n",
            "\t Mixed_6b.branch7x7dbl_1.bn.bias\n",
            "\t Mixed_6b.branch7x7dbl_2.conv.weight\n",
            "\t Mixed_6b.branch7x7dbl_2.bn.weight\n",
            "\t Mixed_6b.branch7x7dbl_2.bn.bias\n",
            "\t Mixed_6b.branch7x7dbl_3.conv.weight\n",
            "\t Mixed_6b.branch7x7dbl_3.bn.weight\n",
            "\t Mixed_6b.branch7x7dbl_3.bn.bias\n",
            "\t Mixed_6b.branch7x7dbl_4.conv.weight\n",
            "\t Mixed_6b.branch7x7dbl_4.bn.weight\n",
            "\t Mixed_6b.branch7x7dbl_4.bn.bias\n",
            "\t Mixed_6b.branch7x7dbl_5.conv.weight\n",
            "\t Mixed_6b.branch7x7dbl_5.bn.weight\n",
            "\t Mixed_6b.branch7x7dbl_5.bn.bias\n",
            "\t Mixed_6b.branch_pool.conv.weight\n",
            "\t Mixed_6b.branch_pool.bn.weight\n",
            "\t Mixed_6b.branch_pool.bn.bias\n",
            "\t Mixed_6c.branch1x1.conv.weight\n",
            "\t Mixed_6c.branch1x1.bn.weight\n",
            "\t Mixed_6c.branch1x1.bn.bias\n",
            "\t Mixed_6c.branch7x7_1.conv.weight\n",
            "\t Mixed_6c.branch7x7_1.bn.weight\n",
            "\t Mixed_6c.branch7x7_1.bn.bias\n",
            "\t Mixed_6c.branch7x7_2.conv.weight\n",
            "\t Mixed_6c.branch7x7_2.bn.weight\n",
            "\t Mixed_6c.branch7x7_2.bn.bias\n",
            "\t Mixed_6c.branch7x7_3.conv.weight\n",
            "\t Mixed_6c.branch7x7_3.bn.weight\n",
            "\t Mixed_6c.branch7x7_3.bn.bias\n",
            "\t Mixed_6c.branch7x7dbl_1.conv.weight\n",
            "\t Mixed_6c.branch7x7dbl_1.bn.weight\n",
            "\t Mixed_6c.branch7x7dbl_1.bn.bias\n",
            "\t Mixed_6c.branch7x7dbl_2.conv.weight\n",
            "\t Mixed_6c.branch7x7dbl_2.bn.weight\n",
            "\t Mixed_6c.branch7x7dbl_2.bn.bias\n",
            "\t Mixed_6c.branch7x7dbl_3.conv.weight\n",
            "\t Mixed_6c.branch7x7dbl_3.bn.weight\n",
            "\t Mixed_6c.branch7x7dbl_3.bn.bias\n",
            "\t Mixed_6c.branch7x7dbl_4.conv.weight\n",
            "\t Mixed_6c.branch7x7dbl_4.bn.weight\n",
            "\t Mixed_6c.branch7x7dbl_4.bn.bias\n",
            "\t Mixed_6c.branch7x7dbl_5.conv.weight\n",
            "\t Mixed_6c.branch7x7dbl_5.bn.weight\n",
            "\t Mixed_6c.branch7x7dbl_5.bn.bias\n",
            "\t Mixed_6c.branch_pool.conv.weight\n",
            "\t Mixed_6c.branch_pool.bn.weight\n",
            "\t Mixed_6c.branch_pool.bn.bias\n",
            "\t Mixed_6d.branch1x1.conv.weight\n",
            "\t Mixed_6d.branch1x1.bn.weight\n",
            "\t Mixed_6d.branch1x1.bn.bias\n",
            "\t Mixed_6d.branch7x7_1.conv.weight\n",
            "\t Mixed_6d.branch7x7_1.bn.weight\n",
            "\t Mixed_6d.branch7x7_1.bn.bias\n",
            "\t Mixed_6d.branch7x7_2.conv.weight\n",
            "\t Mixed_6d.branch7x7_2.bn.weight\n",
            "\t Mixed_6d.branch7x7_2.bn.bias\n",
            "\t Mixed_6d.branch7x7_3.conv.weight\n",
            "\t Mixed_6d.branch7x7_3.bn.weight\n",
            "\t Mixed_6d.branch7x7_3.bn.bias\n",
            "\t Mixed_6d.branch7x7dbl_1.conv.weight\n",
            "\t Mixed_6d.branch7x7dbl_1.bn.weight\n",
            "\t Mixed_6d.branch7x7dbl_1.bn.bias\n",
            "\t Mixed_6d.branch7x7dbl_2.conv.weight\n",
            "\t Mixed_6d.branch7x7dbl_2.bn.weight\n",
            "\t Mixed_6d.branch7x7dbl_2.bn.bias\n",
            "\t Mixed_6d.branch7x7dbl_3.conv.weight\n",
            "\t Mixed_6d.branch7x7dbl_3.bn.weight\n",
            "\t Mixed_6d.branch7x7dbl_3.bn.bias\n",
            "\t Mixed_6d.branch7x7dbl_4.conv.weight\n",
            "\t Mixed_6d.branch7x7dbl_4.bn.weight\n",
            "\t Mixed_6d.branch7x7dbl_4.bn.bias\n",
            "\t Mixed_6d.branch7x7dbl_5.conv.weight\n",
            "\t Mixed_6d.branch7x7dbl_5.bn.weight\n",
            "\t Mixed_6d.branch7x7dbl_5.bn.bias\n",
            "\t Mixed_6d.branch_pool.conv.weight\n",
            "\t Mixed_6d.branch_pool.bn.weight\n",
            "\t Mixed_6d.branch_pool.bn.bias\n",
            "\t Mixed_6e.branch1x1.conv.weight\n",
            "\t Mixed_6e.branch1x1.bn.weight\n",
            "\t Mixed_6e.branch1x1.bn.bias\n",
            "\t Mixed_6e.branch7x7_1.conv.weight\n",
            "\t Mixed_6e.branch7x7_1.bn.weight\n",
            "\t Mixed_6e.branch7x7_1.bn.bias\n",
            "\t Mixed_6e.branch7x7_2.conv.weight\n",
            "\t Mixed_6e.branch7x7_2.bn.weight\n",
            "\t Mixed_6e.branch7x7_2.bn.bias\n",
            "\t Mixed_6e.branch7x7_3.conv.weight\n",
            "\t Mixed_6e.branch7x7_3.bn.weight\n",
            "\t Mixed_6e.branch7x7_3.bn.bias\n",
            "\t Mixed_6e.branch7x7dbl_1.conv.weight\n",
            "\t Mixed_6e.branch7x7dbl_1.bn.weight\n",
            "\t Mixed_6e.branch7x7dbl_1.bn.bias\n",
            "\t Mixed_6e.branch7x7dbl_2.conv.weight\n",
            "\t Mixed_6e.branch7x7dbl_2.bn.weight\n",
            "\t Mixed_6e.branch7x7dbl_2.bn.bias\n",
            "\t Mixed_6e.branch7x7dbl_3.conv.weight\n",
            "\t Mixed_6e.branch7x7dbl_3.bn.weight\n",
            "\t Mixed_6e.branch7x7dbl_3.bn.bias\n",
            "\t Mixed_6e.branch7x7dbl_4.conv.weight\n",
            "\t Mixed_6e.branch7x7dbl_4.bn.weight\n",
            "\t Mixed_6e.branch7x7dbl_4.bn.bias\n",
            "\t Mixed_6e.branch7x7dbl_5.conv.weight\n",
            "\t Mixed_6e.branch7x7dbl_5.bn.weight\n",
            "\t Mixed_6e.branch7x7dbl_5.bn.bias\n",
            "\t Mixed_6e.branch_pool.conv.weight\n",
            "\t Mixed_6e.branch_pool.bn.weight\n",
            "\t Mixed_6e.branch_pool.bn.bias\n",
            "\t AuxLogits.conv0.conv.weight\n",
            "\t AuxLogits.conv0.bn.weight\n",
            "\t AuxLogits.conv0.bn.bias\n",
            "\t AuxLogits.conv1.conv.weight\n",
            "\t AuxLogits.conv1.bn.weight\n",
            "\t AuxLogits.conv1.bn.bias\n",
            "\t AuxLogits.fc.weight\n",
            "\t AuxLogits.fc.bias\n",
            "\t Mixed_7a.branch3x3_1.conv.weight\n",
            "\t Mixed_7a.branch3x3_1.bn.weight\n",
            "\t Mixed_7a.branch3x3_1.bn.bias\n",
            "\t Mixed_7a.branch3x3_2.conv.weight\n",
            "\t Mixed_7a.branch3x3_2.bn.weight\n",
            "\t Mixed_7a.branch3x3_2.bn.bias\n",
            "\t Mixed_7a.branch7x7x3_1.conv.weight\n",
            "\t Mixed_7a.branch7x7x3_1.bn.weight\n",
            "\t Mixed_7a.branch7x7x3_1.bn.bias\n",
            "\t Mixed_7a.branch7x7x3_2.conv.weight\n",
            "\t Mixed_7a.branch7x7x3_2.bn.weight\n",
            "\t Mixed_7a.branch7x7x3_2.bn.bias\n",
            "\t Mixed_7a.branch7x7x3_3.conv.weight\n",
            "\t Mixed_7a.branch7x7x3_3.bn.weight\n",
            "\t Mixed_7a.branch7x7x3_3.bn.bias\n",
            "\t Mixed_7a.branch7x7x3_4.conv.weight\n",
            "\t Mixed_7a.branch7x7x3_4.bn.weight\n",
            "\t Mixed_7a.branch7x7x3_4.bn.bias\n",
            "\t Mixed_7b.branch1x1.conv.weight\n",
            "\t Mixed_7b.branch1x1.bn.weight\n",
            "\t Mixed_7b.branch1x1.bn.bias\n",
            "\t Mixed_7b.branch3x3_1.conv.weight\n",
            "\t Mixed_7b.branch3x3_1.bn.weight\n",
            "\t Mixed_7b.branch3x3_1.bn.bias\n",
            "\t Mixed_7b.branch3x3_2a.conv.weight\n",
            "\t Mixed_7b.branch3x3_2a.bn.weight\n",
            "\t Mixed_7b.branch3x3_2a.bn.bias\n",
            "\t Mixed_7b.branch3x3_2b.conv.weight\n",
            "\t Mixed_7b.branch3x3_2b.bn.weight\n",
            "\t Mixed_7b.branch3x3_2b.bn.bias\n",
            "\t Mixed_7b.branch3x3dbl_1.conv.weight\n",
            "\t Mixed_7b.branch3x3dbl_1.bn.weight\n",
            "\t Mixed_7b.branch3x3dbl_1.bn.bias\n",
            "\t Mixed_7b.branch3x3dbl_2.conv.weight\n",
            "\t Mixed_7b.branch3x3dbl_2.bn.weight\n",
            "\t Mixed_7b.branch3x3dbl_2.bn.bias\n",
            "\t Mixed_7b.branch3x3dbl_3a.conv.weight\n",
            "\t Mixed_7b.branch3x3dbl_3a.bn.weight\n",
            "\t Mixed_7b.branch3x3dbl_3a.bn.bias\n",
            "\t Mixed_7b.branch3x3dbl_3b.conv.weight\n",
            "\t Mixed_7b.branch3x3dbl_3b.bn.weight\n",
            "\t Mixed_7b.branch3x3dbl_3b.bn.bias\n",
            "\t Mixed_7b.branch_pool.conv.weight\n",
            "\t Mixed_7b.branch_pool.bn.weight\n",
            "\t Mixed_7b.branch_pool.bn.bias\n",
            "\t Mixed_7c.branch1x1.conv.weight\n",
            "\t Mixed_7c.branch1x1.bn.weight\n",
            "\t Mixed_7c.branch1x1.bn.bias\n",
            "\t Mixed_7c.branch3x3_1.conv.weight\n",
            "\t Mixed_7c.branch3x3_1.bn.weight\n",
            "\t Mixed_7c.branch3x3_1.bn.bias\n",
            "\t Mixed_7c.branch3x3_2a.conv.weight\n",
            "\t Mixed_7c.branch3x3_2a.bn.weight\n",
            "\t Mixed_7c.branch3x3_2a.bn.bias\n",
            "\t Mixed_7c.branch3x3_2b.conv.weight\n",
            "\t Mixed_7c.branch3x3_2b.bn.weight\n",
            "\t Mixed_7c.branch3x3_2b.bn.bias\n",
            "\t Mixed_7c.branch3x3dbl_1.conv.weight\n",
            "\t Mixed_7c.branch3x3dbl_1.bn.weight\n",
            "\t Mixed_7c.branch3x3dbl_1.bn.bias\n",
            "\t Mixed_7c.branch3x3dbl_2.conv.weight\n",
            "\t Mixed_7c.branch3x3dbl_2.bn.weight\n",
            "\t Mixed_7c.branch3x3dbl_2.bn.bias\n",
            "\t Mixed_7c.branch3x3dbl_3a.conv.weight\n",
            "\t Mixed_7c.branch3x3dbl_3a.bn.weight\n",
            "\t Mixed_7c.branch3x3dbl_3a.bn.bias\n",
            "\t Mixed_7c.branch3x3dbl_3b.conv.weight\n",
            "\t Mixed_7c.branch3x3dbl_3b.bn.weight\n",
            "\t Mixed_7c.branch3x3dbl_3b.bn.bias\n",
            "\t Mixed_7c.branch_pool.conv.weight\n",
            "\t Mixed_7c.branch_pool.bn.weight\n",
            "\t Mixed_7c.branch_pool.bn.bias\n",
            "\t fc.weight\n",
            "\t fc.bias\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXg5BAG1oo-f",
        "outputId": "7715b0bc-ff94-4e70-c810-6094a991cb33"
      },
      "source": [
        "# Setup the loss fxn\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Train and evaluate\n",
        "model_ft, hist = train_model(model_ft, dataloaders, criterion, optimizer_ft, num_epochs=num_epochs, is_inception=(model_name==\"inception\"))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/9\n",
            "----------\n",
            "train Loss: 0.3375 Acc: 0.9306\n",
            "val Loss: 1.1786 Acc: 0.7462\n",
            "\n",
            "Epoch 1/9\n",
            "----------\n",
            "train Loss: 0.0096 Acc: 0.9871\n",
            "val Loss: 1.6080 Acc: 0.7462\n",
            "\n",
            "Epoch 2/9\n",
            "----------\n",
            "train Loss: 0.0025 Acc: 0.9871\n",
            "val Loss: 1.6974 Acc: 0.7462\n",
            "\n",
            "Epoch 3/9\n",
            "----------\n",
            "train Loss: 0.0018 Acc: 0.9871\n",
            "val Loss: 1.7324 Acc: 0.7462\n",
            "\n",
            "Epoch 4/9\n",
            "----------\n",
            "train Loss: 0.0014 Acc: 0.9871\n",
            "val Loss: 1.7565 Acc: 0.7462\n",
            "\n",
            "Epoch 5/9\n",
            "----------\n",
            "train Loss: 0.0013 Acc: 0.9871\n",
            "val Loss: 1.7438 Acc: 0.7462\n",
            "\n",
            "Epoch 6/9\n",
            "----------\n",
            "train Loss: 0.0013 Acc: 0.9871\n",
            "val Loss: 1.7535 Acc: 0.7462\n",
            "\n",
            "Epoch 7/9\n",
            "----------\n",
            "train Loss: 0.0012 Acc: 0.9871\n",
            "val Loss: 1.7683 Acc: 0.7462\n",
            "\n",
            "Epoch 8/9\n",
            "----------\n",
            "train Loss: 0.0012 Acc: 0.9871\n",
            "val Loss: 1.7684 Acc: 0.7462\n",
            "\n",
            "Epoch 9/9\n",
            "----------\n",
            "train Loss: 0.0011 Acc: 0.9871\n",
            "val Loss: 1.7750 Acc: 0.7462\n",
            "\n",
            "Training complete in 2m 21s\n",
            "Best val Acc: 0.746154\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgYraiAjiys8"
      },
      "source": [
        "torch.save(model_ft,'/content/drive/MyDrive/saved_models/kaggle_recropped_disk.h5')"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpGRminVjRIY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 682
        },
        "outputId": "ec6682f7-c70d-4d22-fbfc-0e08337e240c"
      },
      "source": [
        "import seaborn as sns\n",
        "nb_classes = num_classes\n",
        "confusion_matrix = np.zeros((nb_classes, nb_classes))\n",
        "with torch.no_grad():\n",
        "    for i, (inputs, classes) in enumerate(dataloaders['test']):\n",
        "        inputs = inputs.to(device)\n",
        "        classes = classes.to(device)\n",
        "        outputs = model_ft(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        for t, p in zip(classes.view(-1), preds.view(-1)):\n",
        "                confusion_matrix[t.long(), p.long()] += 1\n",
        "\n",
        "plt.figure(figsize=(15,10))\n",
        "\n",
        "class_names = ['Normal', 'Glaucoma']\n",
        "df_cm = pd.DataFrame(confusion_matrix, index=class_names, columns=class_names).astype(int)\n",
        "heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
        "\n",
        "heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right',fontsize=15)\n",
        "heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right',fontsize=15)\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 69.0, 'Predicted label')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x720 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EyL4HDhTKDa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}