{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "inceptionv3_ben.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1d38d583ff24457a9db0dcacd069234d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4a29a8450e6f4e78950d9f8b79059d02",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_790e2fe4adea4fc08b11929b1bf8ddc4",
              "IPY_MODEL_70bc0777411644518418933665d5a8dc"
            ]
          }
        },
        "4a29a8450e6f4e78950d9f8b79059d02": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "790e2fe4adea4fc08b11929b1bf8ddc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c3e5bbde7bdc4018b2b7f091cf4f426f",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 108857766,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 108857766,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a18b036696444fee84d4fc3da2d0199b"
          }
        },
        "70bc0777411644518418933665d5a8dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_87c10cdd172f413d8f5067a90edfcb8f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 104M/104M [00:15&lt;00:00, 7.23MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2c723301fc8443eaaba0682d1b890dba"
          }
        },
        "c3e5bbde7bdc4018b2b7f091cf4f426f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a18b036696444fee84d4fc3da2d0199b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "87c10cdd172f413d8f5067a90edfcb8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2c723301fc8443eaaba0682d1b890dba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqHnaptr-kuA",
        "outputId": "f2a4fe66-6944-4bc1-dbc8-d268d0663fba"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed May  5 02:44:40 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   49C    P8    10W /  70W |      3MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mI9F5EeeXOzF"
      },
      "source": [
        ""
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7-9XFsaZnKQ"
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oGJ2hstm39V"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import copy\n",
        "import time\n",
        "\n",
        "import torch\n",
        "from torchvision import datasets, models, transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader, Dataset, TensorDataset, Subset, WeightedRandomSampler\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import pickle"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMzw_DRLY1VG"
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u899MaWr-ZF0"
      },
      "source": [
        "# Top level data directory. Here we assume the format of the directory conforms\n",
        "#   to the ImageFolder structure\n",
        "data_dir = '/content/drive/MyDrive/ocular'\n",
        "\n",
        "# Models to choose from [resnet, alexnet, vgg, squeezenet, densenet, inception]\n",
        "model_name = \"inception\"\n",
        "# inception\n",
        "input_size = 299\n",
        "\n",
        "# Number of classes in the dataset\n",
        "num_classes = 2\n",
        "\n",
        "# Batch size for training (change depending on how much memory you have)\n",
        "batch_size = 16\n",
        "\n",
        "# Number of epochs to train for\n",
        "num_epochs = 10\n",
        "\n",
        "# Flag for feature extracting. When False, we finetune the whole model,\n",
        "#   when True we only update the reshaped layer params\n",
        "feature_extract = False\n",
        "\n",
        "num_workers = 2\n",
        "\n",
        "train_size = 0.70\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYnO7mxJZywE"
      },
      "source": [
        "\n",
        "class ben_color(object):\n",
        "   \n",
        "   #     Parameters\n",
        "   #    ----------\n",
        "   #   img: 2D numpy array\n",
        "   #         The original image with format of (h, w, c)\n",
        "    \n",
        "    def __call__(self, img, sigmaX=10):\n",
        "        \"\"\"\n",
        "        :param img: PIL): Image \n",
        "\n",
        "        :return: Normalized image\n",
        "        \"\"\"\n",
        "\n",
        "        img = np.asarray(img)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        img = self.crop_image_from_gray(img)\n",
        "        img = cv2.resize(img, (input_size, input_size))\n",
        "        img = cv2.addWeighted (img, 4, cv2.GaussianBlur(img, (0,0), sigmaX), -4, 128)\n",
        "        return Image.fromarray(img)\n",
        "\n",
        "    def crop_image_from_gray(self, img, tol=7):\n",
        "        if img.ndim ==2:\n",
        "            mask = img>tol\n",
        "            return img[np.ix_(mask.any(1),mask.any(0))]\n",
        "        elif img.ndim==3:\n",
        "            gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "            mask = gray_img>tol\n",
        "            \n",
        "            check_shape = img[:,:,0][np.ix_(mask.any(1),mask.any(0))].shape[0]\n",
        "            if (check_shape == 0):\n",
        "                return img \n",
        "            else:\n",
        "                img1=img[:,:,0][np.ix_(mask.any(1),mask.any(0))]\n",
        "                img2=img[:,:,1][np.ix_(mask.any(1),mask.any(0))]\n",
        "                img3=img[:,:,2][np.ix_(mask.any(1),mask.any(0))]\n",
        "                img = np.stack([img1,img2,img3],axis=-1)\n",
        "            return img\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__+'()'"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jj74frLDrZd"
      },
      "source": [
        "# Todos: shuffle in validation set\n",
        "# add more augmentations  \n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "        ben_color(),\n",
        "        transforms.RandomRotation(degrees=(0, 360)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        # transforms.Resize((input_size, input_size)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "\n",
        "\n",
        "valid_transform = transforms.Compose([\n",
        "        ben_color(),\n",
        "        # transforms.Resize((input_size, input_size)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "\n",
        "\n",
        "class DR(Dataset):\n",
        "    def __init__(self, dataset, transform=None):\n",
        "        self.dataset = dataset\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        if self.transform:\n",
        "            x = self.transform(dataset[index][0])\n",
        "        else:\n",
        "            x = dataset[index][0]\n",
        "        y = dataset[index][1]\n",
        "        return x, y\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(dataset)\n",
        "    \n",
        "\n",
        "dataset = ImageFolder(data_dir)\n",
        "\n",
        "traindataset = DR(dataset, train_transform)\n",
        "valdataset = DR(dataset, valid_transform)\n",
        "testdataset = DR(dataset, valid_transform)\n",
        "\n",
        "# Create the index splits for training, validation and test\n",
        "\n",
        "num_train = len(dataset)\n",
        "indices = list(range(num_train))\n",
        "split = int(np.floor(train_size * num_train))\n",
        "split2 = int(np.floor((train_size+(1-train_size)/2) * num_train))\n",
        "np.random.shuffle(indices)\n",
        "train_idx, valid_idx, test_idx = indices[:split], indices[split:split2], indices[split2:]\n",
        "\n",
        "traindata = Subset(traindataset, indices=train_idx)\n",
        "valdata = Subset(valdataset, indices=valid_idx)\n",
        "testdata = Subset(testdataset, indices=test_idx)\n",
        "\n",
        "# class_weights = []\n",
        "# for root, subdir, files in os.walk(data_dir):\n",
        "#   if len(files)>0:\n",
        "#     class_weights.append(1/len(files))\n",
        "\n",
        "# sample_weights = [0] * len(traindata)\n",
        "\n",
        "# for idx, (data, label) in enumerate(traindata):\n",
        "#   class_weight = class_weights[label]\n",
        "#   sample_weights[idx] = class_weight\n",
        "\n",
        "\n",
        "# with open('/content/drive/MyDrive/new_weights.pkl', 'wb') as f:\n",
        "#   pickle.dump(sample_weights, f)\n",
        "\n",
        "with open('/content/drive/MyDrive/new_weights.pkl', 'rb') as f:\n",
        "  sample_weights = pickle.load(f)\n",
        "\n",
        "sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)\n",
        "\n",
        "trainLoader = torch.utils.data.DataLoader(traindata, batch_size=batch_size, \n",
        "                                          num_workers=num_workers, drop_last=True)\n",
        "valLoader = torch.utils.data.DataLoader(valdata, batch_size=batch_size, \n",
        "                                          num_workers=num_workers, drop_last=True)\n",
        "testLoader = torch.utils.data.DataLoader(testdata, batch_size=batch_size,\n",
        "                                          num_workers=num_workers, drop_last=True)\n",
        "dataloaders = {'train': trainLoader, 'val': valLoader, 'test': testLoader}"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyThMaR4nbLF"
      },
      "source": [
        "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False):\n",
        "    since = time.time()\n",
        "\n",
        "    val_acc_history = []\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    # Get model outputs and calculate loss\n",
        "                    # Special case for inception because in training it has an auxiliary output. In train\n",
        "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
        "                    #   but in testing we only consider the final output.\n",
        "                    if is_inception and phase == 'train':\n",
        "                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
        "                        outputs, aux_outputs = model(inputs)\n",
        "                        loss1 = criterion(outputs, labels)\n",
        "                        loss2 = criterion(aux_outputs, labels)\n",
        "                        loss = loss1 + 0.4*loss2\n",
        "                    else:\n",
        "                        outputs = model(inputs)\n",
        "                        loss = criterion(outputs, labels)\n",
        "\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
        "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            if phase == 'val':\n",
        "                val_acc_history.append(epoch_acc)\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, val_acc_history"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75VdlQ8ln1a9"
      },
      "source": [
        "def set_parameter_requires_grad(model, feature_extracting):\n",
        "    if feature_extracting:\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "1d38d583ff24457a9db0dcacd069234d",
            "4a29a8450e6f4e78950d9f8b79059d02",
            "790e2fe4adea4fc08b11929b1bf8ddc4",
            "70bc0777411644518418933665d5a8dc",
            "c3e5bbde7bdc4018b2b7f091cf4f426f",
            "a18b036696444fee84d4fc3da2d0199b",
            "87c10cdd172f413d8f5067a90edfcb8f",
            "2c723301fc8443eaaba0682d1b890dba"
          ]
        },
        "id": "Y4O8Uqptn8Sb",
        "outputId": "42b37603-94bb-46da-fd0e-71a9c3d3db82"
      },
      "source": [
        "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
        "    # Initialize these variables which will be set in this if statement. Each of these\n",
        "    #   variables is model specific.\n",
        "    model_ft = None\n",
        "    input_size = 0\n",
        "\n",
        "    if model_name == \"resnet\":\n",
        "        \"\"\" Resnet18\n",
        "        \"\"\"\n",
        "        model_ft = models.resnet18(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.fc.in_features\n",
        "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"alexnet\":\n",
        "        \"\"\" Alexnet\n",
        "        \"\"\"\n",
        "        model_ft = models.alexnet(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.classifier[6].in_features\n",
        "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"vgg\":\n",
        "        \"\"\" VGG11_bn\n",
        "        \"\"\"\n",
        "        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.classifier[6].in_features\n",
        "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"squeezenet\":\n",
        "        \"\"\" Squeezenet\n",
        "        \"\"\"\n",
        "        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
        "        model_ft.num_classes = num_classes\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"densenet\":\n",
        "        \"\"\" Densenet\n",
        "        \"\"\"\n",
        "        model_ft = models.densenet121(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.classifier.in_features\n",
        "        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"inception\":\n",
        "        \"\"\" Inception v3\n",
        "        Be careful, expects (299,299) sized images and has auxiliary output\n",
        "        \"\"\"\n",
        "        model_ft = models.inception_v3(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        # Handle the auxilary net\n",
        "        num_ftrs = model_ft.AuxLogits.fc.in_features\n",
        "        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n",
        "        # Handle the primary net\n",
        "        num_ftrs = model_ft.fc.in_features\n",
        "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
        "        input_size = 299\n",
        "\n",
        "    else:\n",
        "        print(\"Invalid model name, exiting...\")\n",
        "        exit()\n",
        "\n",
        "    return model_ft, input_size\n",
        "\n",
        "# Initialize the model for this run\n",
        "model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n",
        "\n",
        "# Print the model we just instantiated\n",
        "print(model_ft)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/inception_v3_google-1a9a5a14.pth\" to /root/.cache/torch/hub/checkpoints/inception_v3_google-1a9a5a14.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1d38d583ff24457a9db0dcacd069234d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=108857766.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Inception3(\n",
            "  (Conv2d_1a_3x3): BasicConv2d(\n",
            "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
            "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (Conv2d_2a_3x3): BasicConv2d(\n",
            "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (Conv2d_2b_3x3): BasicConv2d(\n",
            "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (Conv2d_3b_1x1): BasicConv2d(\n",
            "    (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (Conv2d_4a_3x3): BasicConv2d(\n",
            "    (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (Mixed_5b): InceptionA(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_1): BasicConv2d(\n",
            "      (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_2): BasicConv2d(\n",
            "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_5c): InceptionA(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_1): BasicConv2d(\n",
            "      (conv): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_2): BasicConv2d(\n",
            "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_5d): InceptionA(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_1): BasicConv2d(\n",
            "      (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_2): BasicConv2d(\n",
            "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_6a): InceptionB(\n",
            "    (branch3x3): BasicConv2d(\n",
            "      (conv): Conv2d(288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_6b): InceptionC(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_2): BasicConv2d(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_3): BasicConv2d(\n",
            "      (conv): Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_4): BasicConv2d(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_5): BasicConv2d(\n",
            "      (conv): Conv2d(128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_6c): InceptionC(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_2): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_3): BasicConv2d(\n",
            "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_4): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_5): BasicConv2d(\n",
            "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_6d): InceptionC(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_2): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_3): BasicConv2d(\n",
            "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_4): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_5): BasicConv2d(\n",
            "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_6e): InceptionC(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_2): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_3): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_4): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_5): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (AuxLogits): InceptionAux(\n",
            "    (conv0): BasicConv2d(\n",
            "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (conv1): BasicConv2d(\n",
            "      (conv): Conv2d(128, 768, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fc): Linear(in_features=768, out_features=2, bias=True)\n",
            "  )\n",
            "  (Mixed_7a): InceptionD(\n",
            "    (branch3x3_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_2): BasicConv2d(\n",
            "      (conv): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7x3_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7x3_2): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7x3_3): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7x3_4): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_7b): InceptionE(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_1): BasicConv2d(\n",
            "      (conv): Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_2a): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_2b): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3a): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3b): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_7c): InceptionE(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_1): BasicConv2d(\n",
            "      (conv): Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_2a): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_2b): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3a): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3b): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (fc): Linear(in_features=2048, out_features=2, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6151ULNdzuq",
        "outputId": "24e5a7d4-06a4-4bb1-853a-f65bf66965e0"
      },
      "source": [
        "# Send the model to GPU\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "# Gather the parameters to be optimized/updated in this run. If we are\n",
        "#  finetuning we will be updating all parameters. However, if we are\n",
        "#  doing feature extract method, we will only update the parameters\n",
        "#  that we have just initialized, i.e. the parameters with requires_grad\n",
        "#  is True.\n",
        "params_to_update = model_ft.parameters()\n",
        "print(\"Params to learn:\")\n",
        "if feature_extract:\n",
        "    params_to_update = []\n",
        "    for name,param in model_ft.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            params_to_update.append(param)\n",
        "            print(\"\\t\",name)\n",
        "else:\n",
        "    for name,param in model_ft.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            print(\"\\t\",name)\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Params to learn:\n",
            "\t Conv2d_1a_3x3.conv.weight\n",
            "\t Conv2d_1a_3x3.bn.weight\n",
            "\t Conv2d_1a_3x3.bn.bias\n",
            "\t Conv2d_2a_3x3.conv.weight\n",
            "\t Conv2d_2a_3x3.bn.weight\n",
            "\t Conv2d_2a_3x3.bn.bias\n",
            "\t Conv2d_2b_3x3.conv.weight\n",
            "\t Conv2d_2b_3x3.bn.weight\n",
            "\t Conv2d_2b_3x3.bn.bias\n",
            "\t Conv2d_3b_1x1.conv.weight\n",
            "\t Conv2d_3b_1x1.bn.weight\n",
            "\t Conv2d_3b_1x1.bn.bias\n",
            "\t Conv2d_4a_3x3.conv.weight\n",
            "\t Conv2d_4a_3x3.bn.weight\n",
            "\t Conv2d_4a_3x3.bn.bias\n",
            "\t Mixed_5b.branch1x1.conv.weight\n",
            "\t Mixed_5b.branch1x1.bn.weight\n",
            "\t Mixed_5b.branch1x1.bn.bias\n",
            "\t Mixed_5b.branch5x5_1.conv.weight\n",
            "\t Mixed_5b.branch5x5_1.bn.weight\n",
            "\t Mixed_5b.branch5x5_1.bn.bias\n",
            "\t Mixed_5b.branch5x5_2.conv.weight\n",
            "\t Mixed_5b.branch5x5_2.bn.weight\n",
            "\t Mixed_5b.branch5x5_2.bn.bias\n",
            "\t Mixed_5b.branch3x3dbl_1.conv.weight\n",
            "\t Mixed_5b.branch3x3dbl_1.bn.weight\n",
            "\t Mixed_5b.branch3x3dbl_1.bn.bias\n",
            "\t Mixed_5b.branch3x3dbl_2.conv.weight\n",
            "\t Mixed_5b.branch3x3dbl_2.bn.weight\n",
            "\t Mixed_5b.branch3x3dbl_2.bn.bias\n",
            "\t Mixed_5b.branch3x3dbl_3.conv.weight\n",
            "\t Mixed_5b.branch3x3dbl_3.bn.weight\n",
            "\t Mixed_5b.branch3x3dbl_3.bn.bias\n",
            "\t Mixed_5b.branch_pool.conv.weight\n",
            "\t Mixed_5b.branch_pool.bn.weight\n",
            "\t Mixed_5b.branch_pool.bn.bias\n",
            "\t Mixed_5c.branch1x1.conv.weight\n",
            "\t Mixed_5c.branch1x1.bn.weight\n",
            "\t Mixed_5c.branch1x1.bn.bias\n",
            "\t Mixed_5c.branch5x5_1.conv.weight\n",
            "\t Mixed_5c.branch5x5_1.bn.weight\n",
            "\t Mixed_5c.branch5x5_1.bn.bias\n",
            "\t Mixed_5c.branch5x5_2.conv.weight\n",
            "\t Mixed_5c.branch5x5_2.bn.weight\n",
            "\t Mixed_5c.branch5x5_2.bn.bias\n",
            "\t Mixed_5c.branch3x3dbl_1.conv.weight\n",
            "\t Mixed_5c.branch3x3dbl_1.bn.weight\n",
            "\t Mixed_5c.branch3x3dbl_1.bn.bias\n",
            "\t Mixed_5c.branch3x3dbl_2.conv.weight\n",
            "\t Mixed_5c.branch3x3dbl_2.bn.weight\n",
            "\t Mixed_5c.branch3x3dbl_2.bn.bias\n",
            "\t Mixed_5c.branch3x3dbl_3.conv.weight\n",
            "\t Mixed_5c.branch3x3dbl_3.bn.weight\n",
            "\t Mixed_5c.branch3x3dbl_3.bn.bias\n",
            "\t Mixed_5c.branch_pool.conv.weight\n",
            "\t Mixed_5c.branch_pool.bn.weight\n",
            "\t Mixed_5c.branch_pool.bn.bias\n",
            "\t Mixed_5d.branch1x1.conv.weight\n",
            "\t Mixed_5d.branch1x1.bn.weight\n",
            "\t Mixed_5d.branch1x1.bn.bias\n",
            "\t Mixed_5d.branch5x5_1.conv.weight\n",
            "\t Mixed_5d.branch5x5_1.bn.weight\n",
            "\t Mixed_5d.branch5x5_1.bn.bias\n",
            "\t Mixed_5d.branch5x5_2.conv.weight\n",
            "\t Mixed_5d.branch5x5_2.bn.weight\n",
            "\t Mixed_5d.branch5x5_2.bn.bias\n",
            "\t Mixed_5d.branch3x3dbl_1.conv.weight\n",
            "\t Mixed_5d.branch3x3dbl_1.bn.weight\n",
            "\t Mixed_5d.branch3x3dbl_1.bn.bias\n",
            "\t Mixed_5d.branch3x3dbl_2.conv.weight\n",
            "\t Mixed_5d.branch3x3dbl_2.bn.weight\n",
            "\t Mixed_5d.branch3x3dbl_2.bn.bias\n",
            "\t Mixed_5d.branch3x3dbl_3.conv.weight\n",
            "\t Mixed_5d.branch3x3dbl_3.bn.weight\n",
            "\t Mixed_5d.branch3x3dbl_3.bn.bias\n",
            "\t Mixed_5d.branch_pool.conv.weight\n",
            "\t Mixed_5d.branch_pool.bn.weight\n",
            "\t Mixed_5d.branch_pool.bn.bias\n",
            "\t Mixed_6a.branch3x3.conv.weight\n",
            "\t Mixed_6a.branch3x3.bn.weight\n",
            "\t Mixed_6a.branch3x3.bn.bias\n",
            "\t Mixed_6a.branch3x3dbl_1.conv.weight\n",
            "\t Mixed_6a.branch3x3dbl_1.bn.weight\n",
            "\t Mixed_6a.branch3x3dbl_1.bn.bias\n",
            "\t Mixed_6a.branch3x3dbl_2.conv.weight\n",
            "\t Mixed_6a.branch3x3dbl_2.bn.weight\n",
            "\t Mixed_6a.branch3x3dbl_2.bn.bias\n",
            "\t Mixed_6a.branch3x3dbl_3.conv.weight\n",
            "\t Mixed_6a.branch3x3dbl_3.bn.weight\n",
            "\t Mixed_6a.branch3x3dbl_3.bn.bias\n",
            "\t Mixed_6b.branch1x1.conv.weight\n",
            "\t Mixed_6b.branch1x1.bn.weight\n",
            "\t Mixed_6b.branch1x1.bn.bias\n",
            "\t Mixed_6b.branch7x7_1.conv.weight\n",
            "\t Mixed_6b.branch7x7_1.bn.weight\n",
            "\t Mixed_6b.branch7x7_1.bn.bias\n",
            "\t Mixed_6b.branch7x7_2.conv.weight\n",
            "\t Mixed_6b.branch7x7_2.bn.weight\n",
            "\t Mixed_6b.branch7x7_2.bn.bias\n",
            "\t Mixed_6b.branch7x7_3.conv.weight\n",
            "\t Mixed_6b.branch7x7_3.bn.weight\n",
            "\t Mixed_6b.branch7x7_3.bn.bias\n",
            "\t Mixed_6b.branch7x7dbl_1.conv.weight\n",
            "\t Mixed_6b.branch7x7dbl_1.bn.weight\n",
            "\t Mixed_6b.branch7x7dbl_1.bn.bias\n",
            "\t Mixed_6b.branch7x7dbl_2.conv.weight\n",
            "\t Mixed_6b.branch7x7dbl_2.bn.weight\n",
            "\t Mixed_6b.branch7x7dbl_2.bn.bias\n",
            "\t Mixed_6b.branch7x7dbl_3.conv.weight\n",
            "\t Mixed_6b.branch7x7dbl_3.bn.weight\n",
            "\t Mixed_6b.branch7x7dbl_3.bn.bias\n",
            "\t Mixed_6b.branch7x7dbl_4.conv.weight\n",
            "\t Mixed_6b.branch7x7dbl_4.bn.weight\n",
            "\t Mixed_6b.branch7x7dbl_4.bn.bias\n",
            "\t Mixed_6b.branch7x7dbl_5.conv.weight\n",
            "\t Mixed_6b.branch7x7dbl_5.bn.weight\n",
            "\t Mixed_6b.branch7x7dbl_5.bn.bias\n",
            "\t Mixed_6b.branch_pool.conv.weight\n",
            "\t Mixed_6b.branch_pool.bn.weight\n",
            "\t Mixed_6b.branch_pool.bn.bias\n",
            "\t Mixed_6c.branch1x1.conv.weight\n",
            "\t Mixed_6c.branch1x1.bn.weight\n",
            "\t Mixed_6c.branch1x1.bn.bias\n",
            "\t Mixed_6c.branch7x7_1.conv.weight\n",
            "\t Mixed_6c.branch7x7_1.bn.weight\n",
            "\t Mixed_6c.branch7x7_1.bn.bias\n",
            "\t Mixed_6c.branch7x7_2.conv.weight\n",
            "\t Mixed_6c.branch7x7_2.bn.weight\n",
            "\t Mixed_6c.branch7x7_2.bn.bias\n",
            "\t Mixed_6c.branch7x7_3.conv.weight\n",
            "\t Mixed_6c.branch7x7_3.bn.weight\n",
            "\t Mixed_6c.branch7x7_3.bn.bias\n",
            "\t Mixed_6c.branch7x7dbl_1.conv.weight\n",
            "\t Mixed_6c.branch7x7dbl_1.bn.weight\n",
            "\t Mixed_6c.branch7x7dbl_1.bn.bias\n",
            "\t Mixed_6c.branch7x7dbl_2.conv.weight\n",
            "\t Mixed_6c.branch7x7dbl_2.bn.weight\n",
            "\t Mixed_6c.branch7x7dbl_2.bn.bias\n",
            "\t Mixed_6c.branch7x7dbl_3.conv.weight\n",
            "\t Mixed_6c.branch7x7dbl_3.bn.weight\n",
            "\t Mixed_6c.branch7x7dbl_3.bn.bias\n",
            "\t Mixed_6c.branch7x7dbl_4.conv.weight\n",
            "\t Mixed_6c.branch7x7dbl_4.bn.weight\n",
            "\t Mixed_6c.branch7x7dbl_4.bn.bias\n",
            "\t Mixed_6c.branch7x7dbl_5.conv.weight\n",
            "\t Mixed_6c.branch7x7dbl_5.bn.weight\n",
            "\t Mixed_6c.branch7x7dbl_5.bn.bias\n",
            "\t Mixed_6c.branch_pool.conv.weight\n",
            "\t Mixed_6c.branch_pool.bn.weight\n",
            "\t Mixed_6c.branch_pool.bn.bias\n",
            "\t Mixed_6d.branch1x1.conv.weight\n",
            "\t Mixed_6d.branch1x1.bn.weight\n",
            "\t Mixed_6d.branch1x1.bn.bias\n",
            "\t Mixed_6d.branch7x7_1.conv.weight\n",
            "\t Mixed_6d.branch7x7_1.bn.weight\n",
            "\t Mixed_6d.branch7x7_1.bn.bias\n",
            "\t Mixed_6d.branch7x7_2.conv.weight\n",
            "\t Mixed_6d.branch7x7_2.bn.weight\n",
            "\t Mixed_6d.branch7x7_2.bn.bias\n",
            "\t Mixed_6d.branch7x7_3.conv.weight\n",
            "\t Mixed_6d.branch7x7_3.bn.weight\n",
            "\t Mixed_6d.branch7x7_3.bn.bias\n",
            "\t Mixed_6d.branch7x7dbl_1.conv.weight\n",
            "\t Mixed_6d.branch7x7dbl_1.bn.weight\n",
            "\t Mixed_6d.branch7x7dbl_1.bn.bias\n",
            "\t Mixed_6d.branch7x7dbl_2.conv.weight\n",
            "\t Mixed_6d.branch7x7dbl_2.bn.weight\n",
            "\t Mixed_6d.branch7x7dbl_2.bn.bias\n",
            "\t Mixed_6d.branch7x7dbl_3.conv.weight\n",
            "\t Mixed_6d.branch7x7dbl_3.bn.weight\n",
            "\t Mixed_6d.branch7x7dbl_3.bn.bias\n",
            "\t Mixed_6d.branch7x7dbl_4.conv.weight\n",
            "\t Mixed_6d.branch7x7dbl_4.bn.weight\n",
            "\t Mixed_6d.branch7x7dbl_4.bn.bias\n",
            "\t Mixed_6d.branch7x7dbl_5.conv.weight\n",
            "\t Mixed_6d.branch7x7dbl_5.bn.weight\n",
            "\t Mixed_6d.branch7x7dbl_5.bn.bias\n",
            "\t Mixed_6d.branch_pool.conv.weight\n",
            "\t Mixed_6d.branch_pool.bn.weight\n",
            "\t Mixed_6d.branch_pool.bn.bias\n",
            "\t Mixed_6e.branch1x1.conv.weight\n",
            "\t Mixed_6e.branch1x1.bn.weight\n",
            "\t Mixed_6e.branch1x1.bn.bias\n",
            "\t Mixed_6e.branch7x7_1.conv.weight\n",
            "\t Mixed_6e.branch7x7_1.bn.weight\n",
            "\t Mixed_6e.branch7x7_1.bn.bias\n",
            "\t Mixed_6e.branch7x7_2.conv.weight\n",
            "\t Mixed_6e.branch7x7_2.bn.weight\n",
            "\t Mixed_6e.branch7x7_2.bn.bias\n",
            "\t Mixed_6e.branch7x7_3.conv.weight\n",
            "\t Mixed_6e.branch7x7_3.bn.weight\n",
            "\t Mixed_6e.branch7x7_3.bn.bias\n",
            "\t Mixed_6e.branch7x7dbl_1.conv.weight\n",
            "\t Mixed_6e.branch7x7dbl_1.bn.weight\n",
            "\t Mixed_6e.branch7x7dbl_1.bn.bias\n",
            "\t Mixed_6e.branch7x7dbl_2.conv.weight\n",
            "\t Mixed_6e.branch7x7dbl_2.bn.weight\n",
            "\t Mixed_6e.branch7x7dbl_2.bn.bias\n",
            "\t Mixed_6e.branch7x7dbl_3.conv.weight\n",
            "\t Mixed_6e.branch7x7dbl_3.bn.weight\n",
            "\t Mixed_6e.branch7x7dbl_3.bn.bias\n",
            "\t Mixed_6e.branch7x7dbl_4.conv.weight\n",
            "\t Mixed_6e.branch7x7dbl_4.bn.weight\n",
            "\t Mixed_6e.branch7x7dbl_4.bn.bias\n",
            "\t Mixed_6e.branch7x7dbl_5.conv.weight\n",
            "\t Mixed_6e.branch7x7dbl_5.bn.weight\n",
            "\t Mixed_6e.branch7x7dbl_5.bn.bias\n",
            "\t Mixed_6e.branch_pool.conv.weight\n",
            "\t Mixed_6e.branch_pool.bn.weight\n",
            "\t Mixed_6e.branch_pool.bn.bias\n",
            "\t AuxLogits.conv0.conv.weight\n",
            "\t AuxLogits.conv0.bn.weight\n",
            "\t AuxLogits.conv0.bn.bias\n",
            "\t AuxLogits.conv1.conv.weight\n",
            "\t AuxLogits.conv1.bn.weight\n",
            "\t AuxLogits.conv1.bn.bias\n",
            "\t AuxLogits.fc.weight\n",
            "\t AuxLogits.fc.bias\n",
            "\t Mixed_7a.branch3x3_1.conv.weight\n",
            "\t Mixed_7a.branch3x3_1.bn.weight\n",
            "\t Mixed_7a.branch3x3_1.bn.bias\n",
            "\t Mixed_7a.branch3x3_2.conv.weight\n",
            "\t Mixed_7a.branch3x3_2.bn.weight\n",
            "\t Mixed_7a.branch3x3_2.bn.bias\n",
            "\t Mixed_7a.branch7x7x3_1.conv.weight\n",
            "\t Mixed_7a.branch7x7x3_1.bn.weight\n",
            "\t Mixed_7a.branch7x7x3_1.bn.bias\n",
            "\t Mixed_7a.branch7x7x3_2.conv.weight\n",
            "\t Mixed_7a.branch7x7x3_2.bn.weight\n",
            "\t Mixed_7a.branch7x7x3_2.bn.bias\n",
            "\t Mixed_7a.branch7x7x3_3.conv.weight\n",
            "\t Mixed_7a.branch7x7x3_3.bn.weight\n",
            "\t Mixed_7a.branch7x7x3_3.bn.bias\n",
            "\t Mixed_7a.branch7x7x3_4.conv.weight\n",
            "\t Mixed_7a.branch7x7x3_4.bn.weight\n",
            "\t Mixed_7a.branch7x7x3_4.bn.bias\n",
            "\t Mixed_7b.branch1x1.conv.weight\n",
            "\t Mixed_7b.branch1x1.bn.weight\n",
            "\t Mixed_7b.branch1x1.bn.bias\n",
            "\t Mixed_7b.branch3x3_1.conv.weight\n",
            "\t Mixed_7b.branch3x3_1.bn.weight\n",
            "\t Mixed_7b.branch3x3_1.bn.bias\n",
            "\t Mixed_7b.branch3x3_2a.conv.weight\n",
            "\t Mixed_7b.branch3x3_2a.bn.weight\n",
            "\t Mixed_7b.branch3x3_2a.bn.bias\n",
            "\t Mixed_7b.branch3x3_2b.conv.weight\n",
            "\t Mixed_7b.branch3x3_2b.bn.weight\n",
            "\t Mixed_7b.branch3x3_2b.bn.bias\n",
            "\t Mixed_7b.branch3x3dbl_1.conv.weight\n",
            "\t Mixed_7b.branch3x3dbl_1.bn.weight\n",
            "\t Mixed_7b.branch3x3dbl_1.bn.bias\n",
            "\t Mixed_7b.branch3x3dbl_2.conv.weight\n",
            "\t Mixed_7b.branch3x3dbl_2.bn.weight\n",
            "\t Mixed_7b.branch3x3dbl_2.bn.bias\n",
            "\t Mixed_7b.branch3x3dbl_3a.conv.weight\n",
            "\t Mixed_7b.branch3x3dbl_3a.bn.weight\n",
            "\t Mixed_7b.branch3x3dbl_3a.bn.bias\n",
            "\t Mixed_7b.branch3x3dbl_3b.conv.weight\n",
            "\t Mixed_7b.branch3x3dbl_3b.bn.weight\n",
            "\t Mixed_7b.branch3x3dbl_3b.bn.bias\n",
            "\t Mixed_7b.branch_pool.conv.weight\n",
            "\t Mixed_7b.branch_pool.bn.weight\n",
            "\t Mixed_7b.branch_pool.bn.bias\n",
            "\t Mixed_7c.branch1x1.conv.weight\n",
            "\t Mixed_7c.branch1x1.bn.weight\n",
            "\t Mixed_7c.branch1x1.bn.bias\n",
            "\t Mixed_7c.branch3x3_1.conv.weight\n",
            "\t Mixed_7c.branch3x3_1.bn.weight\n",
            "\t Mixed_7c.branch3x3_1.bn.bias\n",
            "\t Mixed_7c.branch3x3_2a.conv.weight\n",
            "\t Mixed_7c.branch3x3_2a.bn.weight\n",
            "\t Mixed_7c.branch3x3_2a.bn.bias\n",
            "\t Mixed_7c.branch3x3_2b.conv.weight\n",
            "\t Mixed_7c.branch3x3_2b.bn.weight\n",
            "\t Mixed_7c.branch3x3_2b.bn.bias\n",
            "\t Mixed_7c.branch3x3dbl_1.conv.weight\n",
            "\t Mixed_7c.branch3x3dbl_1.bn.weight\n",
            "\t Mixed_7c.branch3x3dbl_1.bn.bias\n",
            "\t Mixed_7c.branch3x3dbl_2.conv.weight\n",
            "\t Mixed_7c.branch3x3dbl_2.bn.weight\n",
            "\t Mixed_7c.branch3x3dbl_2.bn.bias\n",
            "\t Mixed_7c.branch3x3dbl_3a.conv.weight\n",
            "\t Mixed_7c.branch3x3dbl_3a.bn.weight\n",
            "\t Mixed_7c.branch3x3dbl_3a.bn.bias\n",
            "\t Mixed_7c.branch3x3dbl_3b.conv.weight\n",
            "\t Mixed_7c.branch3x3dbl_3b.bn.weight\n",
            "\t Mixed_7c.branch3x3dbl_3b.bn.bias\n",
            "\t Mixed_7c.branch_pool.conv.weight\n",
            "\t Mixed_7c.branch_pool.bn.weight\n",
            "\t Mixed_7c.branch_pool.bn.bias\n",
            "\t fc.weight\n",
            "\t fc.bias\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXg5BAG1oo-f",
        "outputId": "07c8aa11-8856-42ed-b9d6-d6e632a164b3"
      },
      "source": [
        "# Setup the loss fxn\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Train and evaluate\n",
        "model_ft, hist = train_model(model_ft, dataloaders, criterion, optimizer_ft, num_epochs=num_epochs, is_inception=(model_name==\"inception\"))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/9\n",
            "----------\n",
            "train Loss: 0.4037 Acc: 0.8957\n",
            "val Loss: 0.2053 Acc: 0.9222\n",
            "\n",
            "Epoch 1/9\n",
            "----------\n",
            "train Loss: 0.3015 Acc: 0.9048\n",
            "val Loss: 0.1895 Acc: 0.9261\n",
            "\n",
            "Epoch 2/9\n",
            "----------\n",
            "train Loss: 0.2588 Acc: 0.9115\n",
            "val Loss: 0.1790 Acc: 0.9241\n",
            "\n",
            "Epoch 3/9\n",
            "----------\n",
            "train Loss: 0.2267 Acc: 0.9257\n",
            "val Loss: 0.1774 Acc: 0.9261\n",
            "\n",
            "Epoch 4/9\n",
            "----------\n",
            "train Loss: 0.2123 Acc: 0.9265\n",
            "val Loss: 0.1738 Acc: 0.9319\n",
            "\n",
            "Epoch 5/9\n",
            "----------\n",
            "train Loss: 0.1779 Acc: 0.9432\n",
            "val Loss: 0.1727 Acc: 0.9300\n",
            "\n",
            "Epoch 6/9\n",
            "----------\n",
            "train Loss: 0.1605 Acc: 0.9533\n",
            "val Loss: 0.1851 Acc: 0.9202\n",
            "\n",
            "Epoch 7/9\n",
            "----------\n",
            "train Loss: 0.1511 Acc: 0.9516\n",
            "val Loss: 0.2005 Acc: 0.9183\n",
            "\n",
            "Epoch 8/9\n",
            "----------\n",
            "train Loss: 0.1340 Acc: 0.9566\n",
            "val Loss: 0.1907 Acc: 0.9319\n",
            "\n",
            "Epoch 9/9\n",
            "----------\n",
            "train Loss: 0.1151 Acc: 0.9629\n",
            "val Loss: 0.2139 Acc: 0.9241\n",
            "\n",
            "Training complete in 86m 32s\n",
            "Best val Acc: 0.931907\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgYraiAjiys8"
      },
      "source": [
        "torch.save(model_ft,'/content/drive/MyDrive/saved_models/'+model_name+'ben.h5')"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpGRminVjRIY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "outputId": "67b8c5cb-7056-4786-a759-806cd0d17fe5"
      },
      "source": [
        "import seaborn as sns\n",
        "nb_classes = num_classes\n",
        "confusion_matrix = np.zeros((nb_classes, nb_classes))\n",
        "with torch.no_grad():\n",
        "    for i, (inputs, classes) in enumerate(dataloaders['test']):\n",
        "        inputs = inputs.to(device)\n",
        "        classes = classes.to(device)\n",
        "        outputs = model_ft(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        for t, p in zip(classes.view(-1), preds.view(-1)):\n",
        "                confusion_matrix[t.long(), p.long()] += 1\n",
        "\n",
        "plt.figure(figsize=(15,10))\n",
        "\n",
        "class_names = ['Normal', 'Glaucoma']\n",
        "df_cm = pd.DataFrame(confusion_matrix, index=class_names, columns=class_names).astype(int)\n",
        "heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
        "\n",
        "heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right',fontsize=15)\n",
        "heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right',fontsize=15)\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 69.0, 'Predicted label')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2wAAAKDCAYAAABmCYmyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeZRlVXk34N/LIMgkOIAIKBpJjCOiEocYByLOgnEIDqioaaMYNZpPQZOIRkSNBIeASSuGQRRxZAgqyBAkIoqKCCLaTgEEWlEERNDu2t8f9zRcmuqpoG6d0/U8rrPq3n3OqbMvrlWr3/vbQ7XWAgAAQP+sM9cdAAAAYHoKNgAAgJ5SsAEAAPSUgg0AAKCnFGwAAAA9pWADAADoqfXmugOs3B9++WP7LgCsodvf7dFz3QWAwVny+0trrvuwOib57+P173yvOf9vImEDAADoKQkbAAAwHFNL57oHEyVhAwAA6CkFGwAAQE8ZEgkAAAxHm5rrHkyUhA0AAKCnJGwAAMBwTEnYAAAA6AEJGwAAMBjNHDYAAAD6QMIGAAAMhzlsAAAA9IGEDQAAGA5z2AAAAOgDCRsAADAcU0vnugcTJWEDAADoKQkbAAAwHOawAQAA0AcSNgAAYDjswwYAAEAfKNgAAAB6ypBIAABgMJpFRwAAAOgDCRsAADAcFh0BAACgDyRsAADAcJjDBgAAQB9I2AAAgOGYWjrXPZgoCRsAAEBPSdgAAIDhMIcNAACAPpCwAQAAw2EfNgAAAPpAwgYAAAyHOWwAAAD0gYQNAAAYDnPYAAAA6AMFGwAAQE8ZEgkAAAxGa0vnugsTJWEDAADoKQkbAAAwHJb1BwAAoA8kbAAAwHBY1h8AAIA+kLABAADDYQ4bAAAAfSBhAwAAhmPKPmwAAAD0gIQNAAAYDnPYAAAA6AMJGwAAMBz2YQMAAKAPJGwAAMBwmMMGAABAHyjYAAAAesqQSAAAYDgsOgIAAMDqqKp1q+rbVXVC9/6eVXV2VS2qqk9W1e269g2694u689uvzu9XsAEAAMMxNTW5Y/W8NsmFY+/fneSg1tq9k/w6ycu69pcl+XXXflB33Sop2AAAAGagqrZN8tQkH+neV5LHJ/l0d8nhSXbvXu/WvU93fpfu+pUyhw0AABiM1pbOdRfGvS/JG5Ns2r2/U5KrWmtLuveXJNmme71NkouTpLW2pKp+013/y5U9QMIGAAAwjapaUFXnjB0Lxs49Lcni1to3Z7MPEjYAAGA4JrhKZGttYZKFKzj9qCTPqKqnJNkwyWZJ3p9k86par0vZtk1yaXf9pUm2S3JJVa2X5A5JrlxVHyRsAAAAa6i1tm9rbdvW2vZJ9khyamvtBUlOS/Ls7rIXJzm2e31c9z7d+VNba21Vz5GwAQAAw9F6vw/bm5IcXVXvSPLtJId27YcmObKqFiX5VUZF3iop2AAAAG6F1trpSU7vXv84yc7TXHN9kues6e9WsAEAAMMxwTlsfWAOGwAAQE9J2AAAgOHo/xy225SEDQAAoKckbAAAwHCYwwYAAEAfKNgAAAB6ypBIAABgOCw6AgAAQB9I2AAAgOGw6AgAAAB9IGEDAACGQ8IGAABAH0jYAACA4bBKJAAAAH0gYQMAAIbDHDYAAAD6QMIGAAAMhzlsAAAA9IGEDQAAGA5z2AAAAOgDCRsAADAc5rABAADQBwo2AACAnjIkEgAAGA6LjgAAANAHEjYAAGA4JGwAAAD0gYQNAAAYjtbmugcTJWEDAADoKQkbAAAwHOawAQAA0AcSNgAAYDgkbAAAAPSBhA0AABiOJmEDAACgByRsAADAcJjDBgAAQB9I2AAAgOFoba57MFESNgAAgJ5SsAEAAPSUIZEAAMBwWHQEAACAPpCwAQAAwyFhAwAAoA8kbAAAwHA0CRsAAAA9IGEDAAAGo03ZOBsAAIAekLABAADDYZVIAAAA+kDCBgAADIdVIgEAAOgDBRsAADAcU21yxypU1YZV9fWq+k5VXVBVb+vaD6uqn1TVud2xY9deVfWBqlpUVedV1U6reoYhkQAAADNzQ5LHt9aurar1k5xZVV/ozv2/1tqnl7v+yUl26I4/S/Kh7ucKKdgAAIDh6NEqka21luTa7u363bGyaG63JEd0932tqjavqq1ba5et6AZDIgEAAKZRVQuq6pyxY8E016xbVecmWZzk5Nba2d2p/bthjwdV1QZd2zZJLh67/ZKubYUkbAAAANNorS1MsnAV1yxNsmNVbZ7kc1V1/yT7Jrk8ye26+9+U5O0z6YOEDQAAGI6pqckda6C1dlWS05I8qbV2WRu5Icl/Jdm5u+zSJNuN3bZt17ZCCjYAAIAZqKq7dMlaqur2SZ6Q5PtVtXXXVkl2T3J+d8txSV7UrRb58CS/Wdn8tcSQSAAAYEjaqpfbn6CtkxxeVetmFIYd01o7oapOraq7JKkk5yb52+76E5M8JcmiJNcl2WtVD1CwAQAAzEBr7bwkD56m/fEruL4l2XtNnqFgAwAAhqNHy/pPgjlsAAAAPTW4gq2q9quqVlVfmubcp6vq9Dno1hqpqsd2n+H+c90XAAAYlKk2uaMHBlewjdm1qh42152Atd3SpUvz7JfsnVf9v7ferP2dB30oD/vLZ974/ueXX5GXvWafPPNFr8xLXv3GXL74F5PuKkCvfHjhgfn5Jd/Jud8+5ca2LbbYPF888RO58IIz88UTP5HNN7/DHPYQGIKhFmy/SvLdJG+5rX9xtxwn0PnYp47Nvba/+83azr/wB7n6mmtv1vbef/9InvGkXfK5Iz6UV+71/LzvPw6bYC8B+ueII47JU5/2gpu1vemNe+fU087Mn97vz3PqaWfmTW9co7UHgCRpU5M7emCoBVtLsn+SZ1TVA1Z0UVXtWFWnVNV1VfXrqjqqqrYaO799NzTxBVV1RFVdleT4sfY9quq/qurqqrqkql7Y3ffGqvp5Vf2iqt5dVeuM/c77VNXRVXVx99wLqup149fAUFy++Bc546tfz7Oe/sQb25YuXZoDDz40b3jVy2527Y9+8n/Z+SE7Jkl23ulBOe0rZ020rwB985Uzz86vfn3Vzdqe/vQn5ogjP5UkOeLIT+UZz3jSXHQNGJAhFxGfSvLDrCBl6/Y9OD3JRkmen+TvkjwmyclVdbvlLn9vkmuSPCfJO8fa353ksiTPSvKVjPZYODCjncpfmuR9Sd6Y5Llj92yT5KIkr8poj4UPJ3lbkjfN7GPC3Hn3+/8zr3/VyzL+fcPHP3N8HvfnD89d7nzHm137JzvcK1/+n/9Nknz5f76a3173u1z1m6sn2l+Avttqyzvn8ssXJ0kuv3xxttryznPcIxigeTaHbbDL+rfWpqrqgCSHVtU/t9Z+sNwlb+h+PrG1dnWSVNUPk3wtowLsE2PXfq21duOYhKravnt5amvtzV3b2UmeneQZSe7TWlua5ItVtVuSZyY5uuvXKUlO6e6pJGdmVDT+TZIDboOPDhNx+v+enTtusXnud58d8vVvnZckWfyLK3PSaV/Jf33wPbe4/h/2fnn2/7dDcuyJJ+chOz4gW93lTllnnSF/JwQw+1q/NgAGemiwBVvnY0nemmTf3HKX8J2TnLSsWEuS1trZVfXTJH+emxds/72C33/jLOHW2tVV9Ysk/9MVa8ssSnLjBJ+q2rDrzwu69vXHzq3XWluyqg9VVQuSLEiSQw58R17+ouet6ha4zX37vO/l9DO/lq+c9Y3c8Ps/5Le/vS677/m3WX/99fOUv35pkuT662/Ik5/70nzhmI9my7vcKe8/4J+SJNdd97t8+fQzs9mmm8zlRwDonSsW/zJ3veuWufzyxbnrXbfM4l9cOdddgsFp82wftkEXbK21JVX1niQfqKr9lju9dZILprntiiR3nKZtOlct9/73K2jbcOz9u5O8PKNhkN/qrt8tyT92112bVWitLUyyMEn+8Msf++qNOfH3r9wrf//K0fcgX//WeTnsE5/JIf/6tptd87C/fGa+cMxHkyS/vuo3ucNmm2adddbJh4/8ZJ751F0n3meAvjvh+JPyoj2fk/f868F50Z7PyfHH32KXIoCbWRvGK300yeLcco7YZUm2nOb6rTJaZXLcbVkUPSfJB1tr72mtfbm1dk6SVaZqMHTf+PZ5edrz/iZP3ePlufJXV2XBi/eY6y4BzKmPHXlwzjzjuPzJH/9Rfvrjc7LXS/bIu//14PzlLn+RCy84M7s8/tF593sOnutuwvCYwzYsrbUbquq9Gc0P+2aSP3Snzk7yyqratLV2TZJ0+7Ztn9G8stly+yQ3LHtTVesm8S9XBm3nnR6YnXd64C3av/Hlz934etfHPTq7Pu7Rk+wWQK+9cM/pl+zf9Ul/PeGeAEO2NiRsSfKfGa3y+Mixtn/rfn6pqnarqhck+WxG+7d9Zhb7cnKSvatqz6p6apLjk2wwi88DAID5wz5sw9Nauy7JQcu1/SLJ45Jcn9ECIwdntDT/E1prv5/F7vxd95yDMxqueX6sDgkAAMxAWU623yw6ArDmbn83w3MB1tSS319ac92H1fHbd7xwYv8+3vgfPzbn/00GP4cNAACYR3qyGMikrBVDIgEAANZGEjYAAGA45tnG2RI2AACAnpKwAQAAw2EOGwAAAH0gYQMAAIajJxtaT4qEDQAAoKckbAAAwHCYwwYAAEAfSNgAAIDBaPZhAwAAoA8kbAAAwHCYwwYAAEAfSNgAAIDhkLABAADQBwo2AACAnjIkEgAAGI5mWX8AAAB6QMIGAAAMh0VHAAAA6AMJGwAAMBhNwgYAAEAfSNgAAIDhkLABAADQBxI2AABgOKbswwYAAEAPSNgAAIDhMIcNAACAPpCwAQAAwyFhAwAAoA8kbAAAwGC0JmEDAACgBxRsAAAAPWVIJAAAMBwWHQEAAKAPJGwAAMBwSNgAAADoAwUbAAAwGG2qTexYlarasKq+XlXfqaoLquptXfs9q+rsqlpUVZ+sqtt17Rt07xd157df1TMUbAAAADNzQ5LHt9YelGTHJE+qqocneXeSg1pr907y6yQv665/WZJfd+0HddetlIINAAAYjqk2uWMV2si13dv1u6MleXyST3fthyfZvXu9W/c+3fldqqpW9gwFGwAAwDSqakFVnTN2LJjmmnWr6twki5OcnORHSa5qrS3pLrkkyTbd622SXJwk3fnfJLnTyvpglUgAAGA4pib3qNbawiQLV3HN0iQ7VtXmST6X5D63ZR8kbAAAALdSa+2qJKcleUSSzatqWTi2bZJLu9eXJtkuSbrzd0hy5cp+r4INAAAYjJ6tEnmXLllLVd0+yROSXJhR4fbs7rIXJzm2e31c9z7d+VNbayt9kCGRAAAAM7N1ksOrat2MwrBjWmsnVNX3khxdVe9I8u0kh3bXH5rkyKpalORXSfZY1QMUbAAAwHCsRvI1Ka2185I8eJr2HyfZeZr265M8Z02eYUgkAABAT0nYAACA4ZjgKpF9IGEDAADoKQUbAABATxkSCQAADMbqLLe/NpGwAQAA9JSEDQAAGA6LjgAAANAHEjYAAGAwzGEDAACgFyRsAADAcJjDBgAAQB9I2AAAgMFoEjYAAAD6QMIGAAAMh4QNAACAPpCwAQAAg2EOGwAAAL0gYQMAAIZDwgYAAEAfKNgAAAB6ypBIAABgMCw6AgAAQC9I2AAAgMGQsAEAANALEjYAAGAwJGwAAAD0goQNAAAYjlZz3YOJkrABAAD0lIQNAAAYDHPYAAAA6AUJGwAAMBhtyhw2AAAAekDCBgAADIY5bAAAAPSChA0AABiMZh82AAAA+kDBBgAA0FOGRAIAAINh0REAAAB6QcIGAAAMho2zAQAA6AUJGwAAMBitzXUPJkvCBgAA0FMSNgAAYDDMYQMAAKAXJGwAAMBgSNgAAADoBQkbAAAwGFaJBAAAoBckbAAAwGCYwwYAAEAvSNgAAIDBaE3CBgAAwCpU1XZVdVpVfa+qLqiq13bt+1XVpVV1bnc8ZeyefatqUVVdVFVPXNUzJGwAAAAzsyTJG1pr36qqTZN8s6pO7s4d1Fp77/jFVXXfJHskuV+SuyX5clX9cWtt6YoeoGADAAAGo03NdQ9u0lq7LMll3etrqurCJNus5JbdkhzdWrshyU+qalGSnZOctaIbDIkEAACYRlUtqKpzxo4FK7l2+yQPTnJ21/Tqqjqvqj5aVVt0bdskuXjstkuy8gJPwgYAAAzH1AQXHWmtLUyycFXXVdUmST6T5HWttaur6kNJ/iVJ634emOSlM+mDhA0AAGCGqmr9jIq1o1prn02S1toVrbWlrbWpJB/OaNhjklyaZLux27ft2lZohQlbVX0wo4pwWq2116zWJwAAALiN9GlZ/6qqJIcmubC19m9j7Vt389uS5JlJzu9eH5fk41X1bxktOrJDkq+v7BkrGxJ5zkw7DgAAMA88KsmeSb5bVed2bW9O8ryq2jGjAOynSV6RJK21C6rqmCTfy2iFyb1XtkJkspKCrbV2+Pj7qtqotXbdDD8IAADArdam+pOwtdbOTDJdh05cyT37J9l/dZ+xyjlsVfWIqvpeku937x9UVYes7gMAAACYmdVZdOR9SZ6Y5Mokaa19J8lfzGanAAAAptPa5I4+WK1VIltrFy/XtNJxlgAAANx6q7MP28VV9cgkrVuy8rVJLpzdbgEAANxSn+awTcLqJGx/m2TvjHbg/nmSHbv3AAAAzKJVJmyttV8mecEE+gIAALBSUz3ah20SVmeVyHtV1fFV9YuqWlxVx1bVvSbROQAAgPlsdYZEfjzJMUm2zmg37k8l+cRsdgoAAGA6rdXEjj5YnYJto9baka21Jd3xsSQbznbHAAAA5rsVzmGrqjt2L79QVfskOTpJS/LXWcnO3QAAANw2VrboyDczKtCWZYGvGDvXkuw7W50CAACYTl82tJ6UFRZsrbV7TrIjAAAA3NzqbJydqrp/kvtmbO5aa+2I2eoUAADAdObbsv6rLNiq6q1JHptRwXZikicnOTOJgg0AAGAWrU7C9uwkD0ry7dbaXlW1VZKPzW63AAAAbqkvy+1Pyuos6/+71tpUkiVVtVmSxUm2m91uAQAAsDoJ2zlVtXmSD2e0cuS1Sc6a1V4BAABMwyqRy2mtvap7+R9V9cUkm7XWzpvdbgEAALCyjbN3Wtm51tq3ZqdLAAAA07NK5E0OXMm5luTxt3FfmMaW2+86110AGJyN1t9grrsAALeJlW2c/bhJdgQAAGBVrBIJAABAL6zOKpEAAAC9MN/msEnYAAAAemqVBVuNvLCq/rl7f/eq2nn2uwYAAHBzbYJHH6xOwnZIkkckeV73/pokB89ajwAAAEiyenPY/qy1tlNVfTtJWmu/rqrbzXK/AAAA5r3VKdj+UFXrpksFq+ouSaZmtVcAAADTsOjILX0gyeeSbFlV+yc5M8k7Z7VXAAAArDpha60dVVXfTLJLkkqye2vtwlnvGQAAwHLm28bZqyzYquruSa5Lcvx4W2vt/2azYwAAAPPd6sxh+++M5q9Vkg2T3DPJRUnuN4v9AgAAuIX5tpjG6gyJfMD4+6raKcmrZq1HAAAAJFm9hO1mWmvfqqo/m43OAAAArEyLOWw3U1WvH3u7TpKdkvx81noEAABAktVL2DYde70kozltn5md7gAAAKzYVJvrHkzWSgu2bsPsTVtr/zCh/gAAANBZYcFWVeu11pZU1aMm2SEAAIAVmTKH7UZfz2i+2rlVdVySTyX57bKTrbXPznLfAAAA5rXVmcO2YZIrkzw+N+3H1pIo2AAAgImySuRNtuxWiDw/NxVqy8yzqX4AAACTt7KCbd0kmyTTlrAKNgAAYOKm5roDE7aygu2y1trbJ9YTAAAAbmadlZybX4NDAQAAemZlCdsuE+sFAADAaphvi46sMGFrrf1qkh0BAADg5lZnWX8AAIBemG+LjqxsDhsAAABzSMIGAAAMhoQNAACAXpCwAQAAg2GVSAAAAHpBwgYAAAzG1PwK2CRsAAAAM1FV21XVaVX1vaq6oKpe27XfsapOrqofdj+36Nqrqj5QVYuq6ryq2mlVz1CwAQAAgzGVmtixGpYkeUNr7b5JHp5k76q6b5J9kpzSWtshySnd+yR5cpIdumNBkg+t6gEKNgAAgBlorV3WWvtW9/qaJBcm2SbJbkkO7y47PMnu3evdkhzRRr6WZPOq2nplz1CwAQAAg9EmeFTVgqo6Z+xYsKJ+VdX2SR6c5OwkW7XWLutOXZ5kq+71NkkuHrvtkq5thSw6AgAAMI3W2sIkC1d1XVVtkuQzSV7XWru66qbhlK21VlVtpn1QsAEAAIMxNdcdWE5VrZ9RsXZUa+2zXfMVVbV1a+2ybsjj4q790iTbjd2+bde2QoZEAgAAzECNorRDk1zYWvu3sVPHJXlx9/rFSY4da39Rt1rkw5P8Zmzo5LQkbAAAwGBMVa82YntUkj2TfLeqzu3a3pzkXUmOqaqXJflZkud2505M8pQki5Jcl2SvVT1AwQYAADADrbUzkxWu/7/LNNe3JHuvyTMMiQQAAOgpCRsAADAYM15ucaAkbAAAAD0lYQMAAAajb8v6zzYJGwAAQE9J2AAAgMGY6tWq/rNPwgYAANBTEjYAAGAwpla47dnaScIGAADQUxI2AABgMOzDBgAAQC9I2AAAgMGwSiQAAAC9IGEDAAAGY2quOzBhEjYAAICekrABAACDYZVIAAAAekHBBgAA0FOGRAIAAINhWX8AAAB6QcIGAAAMhmX9AQAA6AUJGwAAMBgSNgAAAHpBwgYAAAxGs0okAAAAfSBhAwAABsMcNgAAAHpBwgYAAAyGhA0AAIBekLABAACD0ea6AxMmYQMAAOgpCRsAADAYU/ZhAwAAoA8UbAAAAD1lSCQAADAYlvUHAACgFyRsAADAYEjYAAAA6AUJGwAAMBg2zgYAAKAXJGwAAMBg2DgbAACAXpCwAQAAg2GVSAAAAHpBwgYAAAyGVSIBAADoBQkbAAAwGFPzLGOTsAEAAPSUhA0AABgMq0QCAADQCwo2AACAnlKwAQAAg9EmeKxKVX20qhZX1fljbftV1aVVdW53PGXs3L5VtaiqLqqqJ67O51WwAQAAzMxhSZ40TftBrbUdu+PEJKmq+ybZI8n9unsOqap1V/UABRsAADAYUxM8VqW1dkaSX61m13dLcnRr7YbW2k+SLEqy86puUrABAADctl5dVed1Qya36Nq2SXLx2DWXdG0rpWADAAAGY6omd1TVgqo6Z+xYsBpd/FCSP0qyY5LLkhx4az6vfdgAAACm0VpbmGThGt5zxbLXVfXhJCd0by9Nst3Ypdt2bSslYQMAAAZjKm1ix0xU1dZjb5+ZZNkKkscl2aOqNqiqeybZIcnXV/X7JGwAAAAzUFWfSPLYJHeuqkuSvDXJY6tqx4x2BvhpklckSWvtgqo6Jsn3kixJsndrbemqnqFgAwAABmNmudfsaK09b5rmQ1dy/f5J9l+TZxgSCQAA0FMSNgAAYDBWZ3+0tYmEDQAAoKckbAAAwGDMdPXGoZKwAQAA9JSEDQAAGIz5la9J2AAAAHpLwQYAANBThkQCAACDYVl/AAAAekHCBgAADIZl/QEAAOgFCRsAADAY8ytfk7ABAAD0loQNAAAYDKtEAgAA0AsSNgAAYDDaPJvFJmEDAADoKQkbAAAwGOawAQAA0AsSNgAAYDCmzGEDAACgDyRsAADAYMyvfE3CBgAA0FsKNgAAgJ4yJBIAABgMi44AAADQCxMp2Kpq96o6qaqurKrfV9WlVfXpqnrS2DWtql49if4AAADDNDXBow9mvWCrqoOSfCbJpUlenuQvk+yT5PZJvlBVfzTbfQBunW222TrHnfixnHXOF/PVb3whr3jVi5Mk93/An+akUz+dM756XE4943PZ6SEPnOOeAvTHNttsnRNOPCpfP+dLOfsbX8wrX/WSJMm+b35tvv/Dr+bMs07ImWedkF2f+Ng57SfQb7M6h62qdkvyuiR7tdYOW+70kVX19CS/m80+ALfekiVL8o/7HpDzvnNBNtlk45z2lc/n9FP/N297x5vyngM+kC+ffEaesOtj8rZ3vClPf/IL5rq7AL2wZOmSvOXN78x3zh397TzjzONy6qlnJkkO/veP5oPv/8gc9xCGqZnDdpt6XZJvTFOsJUlaa8e31n4+3bmqempVnVxVi6vq6qr6WlXtutw1h1XVOcu1bd8Nr3zaWNu6VbVvVf2gqm6oqkuq6rDl7nt1Vf2wO7+oqv5+ufP7VdUvq+rPquqcqvpdVZ1ZVfesqi2r6vNVdW1VXVhVj1/u3hd11/6qqn5dVadV1UNX478f9MIVV/wi533ngiTJtdf+Nj+46EfZeuut0lrLppttkiTZ7A6b5vLLrpjLbgL0yhWX/yLfOfemv50XXbQod7vbXee4V8DQzFrBVlXrJXlEkpNm+CvumeT4JHsmeVaSr2Y0hPJRM/hd/5nkbUmOSfK0JG9IstFYX/8myQeTHJfk6Uk+leTAqtpnud+zUZKFSQ5K8rwkd09yZJJPJDkzyV9lNPTzU1W10dh92yc5Islzkjw/ycVJvlJV95rBZ4E5td3dt8kDH3TffPOc7+TNb3pH3v6OfXL+97+St++/T97+1vfOdfcAeunud98mD3zQ/XLON85Nkix4xYvy1bNPzMEfenc233yzOe4dDIs5bLedOyXZIKPi5EY1st7YUdPd3Fr799baB1prX0pySpI3JvlykpetSSeq6j7dPf/QWvvH1trJrbVPttae251fJ8l+SQ5rrb2htXZSa23fJP+RZN+q2nDs190+yWtaa0e11j6f5F1JHpXkf1pr722tnZTkNUnumOQxY5/l7a21ha21U5J8KclLk/wsyQvX5LPAXNt4441yxFEHZ983vSPXXHNtXvry5+fN++yf+9/n0XnLPu/MBw45YK67CNA7G2+8UY78+CHZ543/kmuuuTYf+chRedD9H5tHPfypufzyxdn/gLfMdReBHpvEKpHLDzJ9Q5I/jB17T3dTVW1bVYdX1aVJlnTX7prkj9fw+Y/rfh62gvPbJrlbRqnauE8m2SzJA8bafp/kK2PvF3U/T52mbZtlDVX1p1X1uaq6IsnSjD7Ln2QFnw8M/swAABxHSURBVKWqFnTDLs+54Q9Xr6DbMFnrrbdeDj/q4Hzqk8flhONGwfnznv9XOf7YLyVJPv/ZE7PTQx40l10E6J311lsvH/v4ITnmk8fl+ONGfy9/sfiXmZqaSmsth//X0XnIQy3YBGuiTfB/fTCbBduVSW7IqCAad2SSh3XHtLrU67gkj0zyzxkVXQ9L8oUkG67ovhW4U5LfttZWVPls3f1cfvLNsvd3HGu7prU2no7+vvt51bKG1tqytg2TpKo2zWhY6HZJXp/k0Rl9lu9kBZ+lS+Me2lp76AbrGyZBP3zwkAPyg4sW5ZB//+iNbZddfkUe9eg/S5L8xWMfkR//6Kdz1DuAfjr4Q+/KRRf9KAd/8NAb27a6611ufP30ZzwxF17wg7noGjAQs7ZKZGttSVWdlVEq9s9j7VekK4ZWMBoySe6d5MFJntxa++Kyxqq6/XLXXZ/kdsu1bbHc+yuTbFxVm62gaLus+7nlcu1bdT9/taJOrqZHZFS0PqG19v1ljVV1h1v5e2FiHv6Ih2SP5z8zF5z//Zzx1eOSJP+y34F53avfkgPe809Zb711c/31N+R1f2dYD8AyD3/EQ/O85/9Vzj//+znzrBOSJG/f77159nOengc88L5preX/fnZJXvsafzthTfRlbtmkzOqy/knel+TzVbVna+3INbhvWWF2w7KGqrpHRvPFzhu77pIk21fVhq2167u2m60kmZuGK74oyb9P86xLkvw8owVBvjDW/twkVyf57hr0ezrTfZZHZrQQyTdv5e+GifjaWd/MFpvce9pzj3v07hPuDcAwfO2sc7LZxrdcX+ykL50++c4AgzWrBVtr7diqel+Sw6rqcRmt+vjLjIYpLiusrp3m1u9nVEgdWFX/lGTTjFZ5vHS56z6f5O1JPtIt0//gjBb0GO/DRVW1sPtdWyY5I8nmSZ7dWtujtTZVVfsl+c+qujLJyRktGPLKJG8eKwRn6mvdZ/xwVb0no7Rtv2k+CwAAsApTrR9zyyZl1hcdaa39fZJnZzSH69CMEq9DMhpy+JTp9mhrrd2Q0RL5S5J8Osm/JDkgyf8sd935GRVoj8hozttjkuw1TTdelVHB98IkJ2aU/F039ns+nOS1SZ6Z5ISMlux/Q2vtXTP71Dfr4xUZpXd3TXJsRnvT/W1uWpwEAABgWtXmWYU6NFtscm//BwGsoaVtvs1wALj1rv7tj1e4wESfvPAefzWxfx9/7GefnfP/JpNY1h8AAIAZULABAAD01GyvEgkAAHCbmerJhtaTImEDAADoKQkbAAAwGE3CBgAAQB9I2AAAgMGYbxu3SNgAAAB6SsIGAAAMhlUiAQAA6AUJGwAAMBhWiQQAAKAXJGwAAMBgWCUSAACAVaqqj1bV4qo6f6ztjlV1clX9sPu5RddeVfWBqlpUVedV1U6r8wwFGwAAMBittYkdq+GwJE9arm2fJKe01nZIckr3PkmenGSH7liQ5EOr8wAFGwAAwAy01s5I8qvlmndLcnj3+vAku4+1H9FGvpZk86raelXPMIcNAAAYjAHsw7ZVa+2y7vXlSbbqXm+T5OKx6y7p2i7LSkjYAAAAplFVC6rqnLFjwZrc30bjKm9VhSlhAwAAmEZrbWGShWt42xVVtXVr7bJuyOPirv3SJNuNXbdt17ZSEjYAAGAwpiZ4zNBxSV7cvX5xkmPH2l/UrRb58CS/GRs6uUISNgAAgBmoqk8keWySO1fVJUnemuRdSY6pqpcl+VmS53aXn5jkKUkWJbkuyV6r8wwFGwAAMBitR4uOtNaet4JTu0xzbUuy95o+w5BIAACAnpKwAQAAgzGAZf1vUxI2AACAnpKwAQAAgzGaCjZ/SNgAAAB6SsIGAAAMxq3YH22QJGwAAAA9JWEDAAAGo0/7sE2ChA0AAKCnJGwAAMBg2IcNAACAXpCwAQAAg2EfNgAAAHpBwQYAANBThkQCAACDYdERAAAAekHCBgAADIaNswEAAOgFCRsAADAYU5b1BwAAoA8kbAAAwGDMr3xNwgYAANBbEjYAAGAw7MMGAABAL0jYAACAwZCwAQAA0AsSNgAAYDCafdgAAADoAwkbAAAwGOawAQAA0AsKNgAAgJ4yJBIAABiMZkgkAAAAfSBhAwAABsOy/gAAAPSChA0AABgMy/oDAADQCxI2AABgMMxhAwAAoBckbAAAwGCYwwYAAEAvSNgAAIDBaBI2AAAA+kDCBgAADMaUVSIBAADoAwkbAAAwGOawAQAA0AsSNgAAYDDMYQMAAKAXFGwAAAA9ZUgkAAAwGBYdAQAAoBckbAAAwGDMt0VHFGwAAAAzVFU/TXJNkqVJlrTWHlpVd0zyySTbJ/lpkue21n49k99vSCQAADAYbYL/WwOPa63t2Fp7aPd+nySntNZ2SHJK935GFGwAAAC3rd2SHN69PjzJ7jP9RYZEAgAAg9HDOWwtyUlV1ZL8Z2ttYZKtWmuXdecvT7LVTH+5gg0AAGAaVbUgyYKxpoVdQTbuz1trl1bVlklOrqrvj59srbWumJsRBRsAADAYk9yHrSvOli/Qlr/m0u7n4qr6XJKdk1xRVVu31i6rqq2TLJ5pH8xhAwAAmIGq2riqNl32OsmuSc5PclySF3eXvTjJsTN9hoQNAAAYjNam5roL47ZK8rmqSka11cdba1+sqm8kOaaqXpbkZ0meO9MHKNgAAABmoLX24yQPmqb9yiS73BbPULABAACDMTXBOWx9YA4bAABAT0nYAACAwWj924dtVknYAAAAekrBBgAA0FOGRAIAAINh0REAAAB6QcIGAAAMhkVHAAAA6AUJGwAAMBhTEjYAAAD6QMIGAAAMRrNKJAAAAH0gYQMAAAbDKpEAAAD0goQNAAAYjClz2AAAAOgDCRsAADAY5rABAADQCxI2AABgMKYkbAAAAPSBgg0AAKCnDIkEAAAGw6IjAAAA9IKEDQAAGAwbZwMAANALEjYAAGAwzGEDAACgFyRsAADAYNg4GwAAgF6QsAEAAIPRrBIJAABAH0jYAACAwTCHDQAAgF6QsAEAAINhHzYAAAB6QcIGAAAMhlUiAQAA6AUFGwAAQE8ZEgkAAAyGRUcAAADoBQkbAAAwGBI2AAAAekHCBgAADMb8yteSmm+RInDbqaoFrbWFc90PgKHwdxNYU4ZEArfGgrnuAMDA+LsJrBEFGwAAQE8p2AAAAHpKwQbcGuZhAKwZfzeBNWLREQAAgJ6SsAEAAPSUgg0AAKCnFGwAAAA9pWADAADoKQUbkKrasKruNNf9AADg5hRsMM9V1TpJjk1yelVtNdf9AQDgJgo2mOdaa1NJ3ptk0yRHK9oAVq2q1p3rPgDzg33YgFRVJXl0ko8nWZTkr1trV8xtrwD6qarWba0t7V7/Y5J7J7lHko8m+XJr7bK57B+wdpGwAWmjb26+kuT5Gf3D45OSNoBbqqoaK9aOTvI3Sa5O8vMk70yyf1VtP2cdBNY6CjaYp7pU7UZd0fa/SV4QRRvAtLq/lamqdybZKclzWmuvSXJmkm2S7JLkHVV197nrJbA2UbDBPNQN51n2j47NumOD7lvjs6JoA1ihqto2yd2SvL219vWqelOSDyZ5TpIjkzw3o6LtHnPYTWAtYQ4bzDPLzb14V5Kdk9wpyY+TvLK1dnlVrZ/kkUmOijltALdQVc9LcmqS+yb5RJJ/aq19uDt3ekZfen0ryd+11n42V/0Ehk/CBvPINHMv9khyfEbfDD8yyf9W1b1ba3/ITcMj75Hki1W15Rx1G2DOrGg1yNbaJ7ovsnZKckWSk8ZOX5/k2iR3TvKHWe8ksFZTsME8MjYMcp8kD8woOTsoyRYZLeu/QZIzuqJtSUZF298kuV2S289NrwHmxnIjEp5VVXtV1Q7LzQHeLsldl6VoVXXHJL/J6G/nU1trP594x4G1iiGRMM9U1UZJXp9kSWvtXVX1+iTvSvKijL4l/mSSa5L8ZWvtJ1W1XpL1W2u/m7NOA8yhbkTC05IsTbJhkv2SHNZau6yq/jjJGUm+l1HK9tAkj0myU2vt4rnpMbA2WW+uOwBMTvet8O+S/HeSS6rqfklek+QNST7ZWmtVdUKSlyS5oKoe2FpblGTJXPUZYNK64ePLRiT8RUbz0Z6R5P+SvDDJ/km2qKr3t9Z+UFV7JfnXJK9McmWSXRRrwG1FwQZrsfHhPMnNhkSe2xVnj02yUZIz2k1x++Ikx3avDZsG5pXl/25m9G+lryU5rfs7uV9V/S7JAUnWqar3tNa+UFUnJ7lrkqtba1dPvufA2krBBmupqlpnbO7F65LcPaMVy77aWvtxd9mGSaaS3K2qzkuyWZI/ymhp//e31m6YfM8B5sZyCzMdkFEB9kcZDRffoKp+31qbaq29u6qmkrw7ydKq+o/W2k+SXDJnnQfWWuawwVquqo5K8oQkVyW5Q5LvJnlLa+3sqrpDRpu9rp/R/IvbJXlUkod1QyEB5oXuS66p7vVRGW2A/eMkmyTZIcmzWmsnLnfdGzIaCvmOjPZkM3wcuM0Z7gRrmfHVy6rqXkm2SfJXSe6T0Vy1jZIcXFWPbq39JsnjkpyX0V5s6yV5tGINmG/GirA7JPltkmdl9GXXHhntt3ZkVT22tTZVVet09xyY5HVJjlasAbNFwgZrkeWWoN4wydYZTY5/RWvtmq79WRmtErlhkr9vrZ1RVbfLaGGRDawGCcxXVfWeJHtlNJf3Ga21H3Xtd0/yoSQPzyhpO308aQOYTRI2WEssN/fiQ0m+nOT0JPdNsvGy61prn0lyYEYbu/5r943xsnkZijVgXuo2yL44yU+TbJnR38hlQyX/L6MVIM9KcnRVPUGxBkyKgg3WAl2ytmwFyPcm2T2jYY4/yGiD7DdW1V2XXd9a+2xG8y42SfLWLo0DmDeWDWtcpvvC6yNJDsloxMHnq2qDbghkjRVtP0zyH92elgCzziqRsBYYS9bumWSLJK9qrX2uazs4ozkYv6uqD7TWruju+XxVLU3y3dba9XPUdYCJW274+N2StIx2Prm8qj6e0eq5+yX5UlU9qbV2fVe0XVxVeyRZp7V23Zx9AGBekbDBgI1/Q1xV+yb5UZI/T3LpsvbW2t5JPpPkpUleU1VbjZ07vrX204l1GGCOLbflySFJTkhyfpLTq+ql3XYmRyV5W0bboXypS9paV7RdalNsYJIkbDBQyy0tvWeSjyd5TJJdkzyk2xz790nSWvu7bvHIPZNsXFXvbK0tnqOuA8yZsb+bH8vob+ZBGf176MFJPlxV902yb5JPZPTF9huTfL2qdrY3JTAXFGwwQN23vMv+0XFYkkdktAT1S5J8Lsmbkny3qr667LquaNskyRMzWjkSYF6qqocleWSS17fWPtW1bZjkqxkVcJe21g7qhkdukGRBRpto/2yOugzMY5b1h4HpirVlC4zcN6MJ8gckOa219vtucZH/TrJZRstT31i0dfdstWweG8B8VFWPSXJakse01r4y1l5J3pfR386HttZ+0G17cvtu30qAiTOHDQZmrFj7aJL3Z5SUn9MVa+u01i5P8pQkv0lyWJJHjs91U6z9//buPejT8b7j+PuzDmuzDUKc0lCNbeI0wpZaqzGoIWJCt2G0m1bi0JBiQyYj7eiIahKEoWOckqxNRuoQSkTS1ioZtSIJYVC2TUMdhpSyS1jWYfn2j/v6rV+f7trFen6/3ef9+ut5rvu+f/f1e/645/nc13V9L0ljSSvXP9ICur3Wtuw9H/tehv2Q7rm6MUDb9sSwJmlgDGzSyuvfgD8APgxMgm5tRvun4wlgP+Ap4Fpg54H1UpIGZEQ1yBmtwiNVdQdwB/CXwIdaW2/K0UvA08Cro99jSfr/DGzSSmBENchxAFV1Nt20nYnAEUk2bO3VF9qmAXcBT45+ryVpcNpzsBfWrgCOBv6wb0/KQ4HngauTfDzJhkkmAYe39vsH0W9JGsk1bNKQG/GG+F3A2m3aY+/4XwDnAmcBp1XVU609Lbwtvl6SxpokZ9LtRXkQ3b6TC/qej5sD3wIm0+299jjdXpb7VNXdA+qyJP0fVomUhtiIsPZ3dHusTUpyG90/Gd+vqvPbqNs53Wk5taqe6k3vMaxJGquSrEf33JxVVT/ptfc9Hx8C9khyILAJ8AJwo/tTShomBjZpSI2YznMpsCvdZq6X0u2ndiqwXZIvV9W5SV6jG2WbmOTEqpo3qL5L0pBYi26N7xXw+kuwvhG2VOcfBttNSVo617BJQyTJWkm2GtE2FdgT+BxwYlWdBUyhK0l9MHBI+yfkfLrNXg8CllQVTZJWWSPW+qb9+DzwDN2UR1pYW72vwMhxST49qh2VpDfJwCYNiVZ6ehZwRZId+v6h2AhYD7itvREeX1UvAUcCjwB/DgQWFyLZoqr+Z/S/gSQNTm+/ySRnAfslWbOV4z8DmJ5kRjtvUTvvPXQvv/ZJMmFA3ZakZTKwSUOiTX/8V7o1FGclmdwO/SfdiNke7byXWmh7GTgR2B6Y0nujXFXPjHrnJWkItOC1D3AhsFtrvhaYSfdcPSvJLkn2B86j2xrllKpaOJAOS9JysEqkNATaFJ3eW98/o5v+uAD4AnAncB3dC5aTqurWvus+AVwATK0qS1BLGlP6Nrsmybi2F+W6wNV0+6t9qqpuSLIZ3drfL9LNSFgAPNGOWw1S0lAzsEkDtLSS+0k+BRxL90/FYcD6wJV0m2XPrKrvJ9mCbs3azsCeVeVea5LGjP6w1te2elUtaqHtGuCDwCFVdUM7vmlrmwc82tsGRZKGmYFNGpAkE4Hv0b3l/RbwQFU93Hf808BxdAvmPwlsDpxOt3h+Pt3UyXWBvavqrtHsuyQNiyRfA8ZX1efa7/2h7Vq6Z+fhwJyqenFwPZWkt8bAJg1Ikr+lW4MGcA9dcZGLgTur6rvtnAOAU4Cn6Ubafg3sQlc18n5gdlU9MMpdl6Sh0PZZOx/YCbikqk5q7b3Qtg3wL8BjwMnAde5NKWllY2CTBiTJ+4EvAR8HrgduAU6g27z1AeAG4Fxgf+AAunUXM6rqniVNBZKkVd1SpkFuRjc9fB/g0qr6675jE+ier7sCvwB+t6peGMUuS9LbZpVIaUCq6lG6wHY9XSi7v6omAbvTjbjtTbdmbX9gM2AL4OIk2xjWJI01bc1v9f0+rhUaeQT4Gt1I2vQkX+m77L3Ag8DWwF6GNUkro9UH3QFpLKuqXyX5IjAeuCbJkVV1GfCn7c3wNGBHYCu6KZPr0hUikaQxo79AU5KT6CpAbgL8IMmlVfVgklOBRcAhST4A/BPwMbpn6Hz3p5S0snJKpDQEkmwMnA3sCxxdVZeMOL4+sBfws6p6aPR7KEmDMaJ0/+XAVOByYD265+KdwLFV9VirAvnHwDF0L8LmAdMt3S9pZWZgk4bEiNB2VFVd3trXqKpXBto5SRqwJF8GDqIr0/+zJMcDZwKPAnOBw9ushTWACcD7gcerav7AOi1JK4Br2KQhUVWPA8cD/wxcmOTg1m5YkzRmJJmY5NAkG/S1vY9uRO30FtZOAM6g2/LkAmA34IIkG1fVK1X1bFXNNaxJWhUY2KQh0hfafghcluQTA+6SJI22Y4CLgEPbdHCAx4Ef0a1Z+wjdHpVHV9XlVXUa8HNgD+DqNltBklYZFh2RhkxVPd7eHr8I3Dvo/kjSaKqq05NsApwKjEtyUVU9meSqqqok04Fn6LY+6ZkP/AewEFhz9HstSe8cA5s0hNo6jKOqatGg+yJJ77Qk4+mKiUwBzquq45IE+Eo7PrOqnmqnb0pXMXd+O7Yu8CrwVeCmqnpmtPsvSe8ki45IkqSBSfJu4ArgfcAHgMOq6sp27BzgaOBEoDfS9lvA7XT7VN4KbEk3HXJy25NNklYpjrBJkqSBaGHtDrpKjyfRTXNc2CvlX1UzkvRGz0gyq6oeTjIN+DrwJ3TTI/c0rElaVRnYJEnSqEuyJt1+ao8ChwKPtDVqi7cySbJ5VR2f5BVeD23frKofJ9kBWAd4qaqeG9DXkKR3nIFNkiQNwjbAbwKn8HpYG9cX1k4Ajkny+ao6oVvSxleB15J8p6r+G3hqaR8uSasKA5skSRqEyXRr1m6ttqC+ql6DxZtkn0BXzv+8JItaaHsVOA14Ock5vfMlaVVmYJMkSYOwJt32Jc8D9NatJdkO+ChwYFVdm+Qm4KI2+vZXSVYDZhvWJI0VVomUJEmjLslOwGzg5Ko6p699ArAh8Fhva5MkzwKXVNVnB9JZSRqgcYPugCRJGpP+C7gfOKSFNwCqamFVPVxVi5KslmQr4KfAzdCNxA2mu5I0GAY2SZI06qpqHnAUsDVwcpLJSzhtbeDzdCNuc9p1Tg2SNKY4JVKSJA1Mkn2Bq4C7gZnAt+leKE8BjgCmAb9fVfcMqo+SNEgGNkmSNFBtSuQsYBPgBeA14DngZeBQw5qksczAJkmSBi7JRsC2wFS6EbZbgXuq6omBdkySBszAJkmSJElDyqIjkiRpKPRXgLQapCR1HGGTJEmSpCHlCJskSZIkDSkDmyRJkiQNKQObJEmSJA0pA5skSZIkDSkDmyRJkiQNKQObJOltS/JqkruS3JvkyiTvehuf9e0kB7afZybZ+g3O3T3J1Ldwj4eSvHd520ecs+BN3uvkJF94s32UJAkMbJKkFWNhVW1fVdsCLwNH9R9Msvpb+dCqOqKq5r7BKbsDbzqwSZK0sjCwSZJWtDnApDb6NSfJtcDcJKslOSPJ7UnuSXIkdBskJzk3yS+S3ABs2PugJDcl2bH9/NEkdya5O8mNSTanC4bHt9G9jyTZIMlV7R63J9m1Xbt+kuuT3JdkJrDMTZmTXJPkjnbNZ0YcO7u135hkg9a2RZLr2jVzkmy5Iv6YkqSx7S298ZQkaUnaSNq+wHWtaTKwbVU92ELPr6tqpyTjgR8nuR7YAfgQsDWwETAXmDXiczcAvgns1j5rvaqan+RCYEFVndnOuxQ4u6puSbIZMBvYCvgScEtVnZJkP+Dw5fg6h7V7TABuT3JVVc0DJgI/r6rjk5zUPvsY4BvAUVX1yyQ7A+cDe76FP6MkSYsZ2CRJK8KEJHe1n+cAF9FNVbytqh5s7XsD2/XWpwHrAL8D7AZcVlWvAr9K8qMlfP4U4ObeZ1XV/KX0Yy9g62TxANraSX6j3eOP2rX/mOTp5fhOM5JMaz9v2vo6D3gN+G5r/3vg6naPqcCVffcevxz3kCTpDRnYJEkrwsKq2r6/oQWX5/ubgGOravaI8z62AvsxDphSVS8uoS/LLcnudOFvl6p6IclNwFpLOb3afZ8Z+TeQJOntcg2bJGm0zAY+m2QNgCQfTDIRuBk4uK1x2wTYYwnX/hTYLclvt2vXa+3PAe/uO+964NjeL0l6AepmYHpr2xd4zzL6ug7wdAtrW9KN8PWMA3qjhNPpplo+CzyY5KB2jyT58DLuIUnSMhnYJEmjZSbd+rQ7k9wLfJ1upsf3gF+2YxcDPxl5YVU9CXyGbvrh3bw+JfEHwLRe0RFgBrBjK2oyl9erVf4NXeC7j25q5CPL6Ot1wOpJ/h04jS4w9jwP/F77DnsCp7T2TwKHt/7dBxywHH8TSZLeUKpq0H2QJEmSJC2BI2ySJEmSNKQMbJIkSZI0pAxskiRJkjSkDGySJEmSNKQMbJIkSZI0pAxskiRJkjSkDGySJEmSNKQMbJIkSZI0pP4XI4usnoC2+9YAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1080x720 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Emzn5VAnJKU"
      },
      "source": [
        "Â "
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EyL4HDhTKDa"
      },
      "source": [
        ""
      ],
      "execution_count": 21,
      "outputs": []
    }
  ]
}