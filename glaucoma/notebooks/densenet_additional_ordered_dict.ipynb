{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "densenet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqHnaptr-kuA",
        "outputId": "5274e4b7-4130-4584-d2da-456210ec3846"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue May 11 04:07:22 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   74C    P0    91W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7-9XFsaZnKQ"
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oGJ2hstm39V"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from imutils import contours\n",
        "from skimage import measure\n",
        "import imutils\n",
        "import os\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import copy\n",
        "import time\n",
        "\n",
        "import torch\n",
        "from torchvision import datasets, models, transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader, Dataset, TensorDataset, Subset, WeightedRandomSampler\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import pickle\n",
        "from collections import OrderedDict"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u899MaWr-ZF0"
      },
      "source": [
        "# Top level data directory. Here we assume the format of the directory conforms\n",
        "#   to the ImageFolder structure\n",
        "data_dir = '/content/drive/MyDrive/disk_dataset_kaggle'\n",
        "\n",
        "# Models to choose from [resnet, alexnet, vgg, squeezenet, densenet, inception]\n",
        "model_name = \"densenet\"\n",
        "# inception\n",
        "input_size = 224\n",
        "\n",
        "# Number of classes in the dataset\n",
        "num_classes = 2\n",
        "\n",
        "# Batch size for training (change depending on how much memory you have)\n",
        "batch_size = 32\n",
        "\n",
        "# Number of epochs to train for\n",
        "num_epochs = 10\n",
        "\n",
        "# Flag for feature extracting. When False, we finetune the whole model,\n",
        "#   when True we only update the reshaped layer params\n",
        "feature_extract = False\n",
        "\n",
        "num_workers = 2\n",
        "\n",
        "train_size = 0.60\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYnO7mxJZywE"
      },
      "source": [
        "\n",
        "class ben_color(object):\n",
        "    def __call__(self, img, sigmaX=10):\n",
        "        \"\"\"\n",
        "        :param img: PIL): Image \n",
        "\n",
        "        :return: Normalized image\n",
        "        \"\"\"\n",
        "\n",
        "        img = np.asarray(img)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        img = self.crop_image_from_gray(img)\n",
        "        img = cv2.resize(img, (input_size, input_size))\n",
        "        img = cv2.addWeighted (img, 4, cv2.GaussianBlur(img, (0,0), sigmaX), -4, 128)\n",
        "        return Image.fromarray(img)\n",
        "\n",
        "    def crop_image_from_gray(self, img, tol=7):\n",
        "        if img.ndim ==2:\n",
        "            mask = img>tol\n",
        "            return img[np.ix_(mask.any(1),mask.any(0))]\n",
        "        elif img.ndim==3:\n",
        "            gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "            mask = gray_img>tol\n",
        "            \n",
        "            check_shape = img[:,:,0][np.ix_(mask.any(1),mask.any(0))].shape[0]\n",
        "            if (check_shape == 0):\n",
        "                return img \n",
        "            else:\n",
        "                img1=img[:,:,0][np.ix_(mask.any(1),mask.any(0))]\n",
        "                img2=img[:,:,1][np.ix_(mask.any(1),mask.any(0))]\n",
        "                img3=img[:,:,2][np.ix_(mask.any(1),mask.any(0))]\n",
        "                img = np.stack([img1,img2,img3],axis=-1)\n",
        "            return img\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__+'()'"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jj74frLDrZd"
      },
      "source": [
        "# Todos: shuffle in validation set\n",
        "# add more augmentations  \n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "        ben_color(),\n",
        "        transforms.RandomRotation(degrees=(0, 360)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.Resize((input_size, input_size)),\n",
        "        transforms.ToTensor(),\n",
        "        # transforms.Normalize((0.5,), (0.5,))])\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "\n",
        "\n",
        "valid_transform = transforms.Compose([\n",
        "        ben_color(),\n",
        "        transforms.Resize((input_size, input_size)),\n",
        "        transforms.ToTensor(),\n",
        "        # transforms.Normalize((0.5,), (0.5,))])\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "\n",
        "\n",
        "class DR(Dataset):\n",
        "    def __init__(self, dataset, transform=None):\n",
        "        self.dataset = dataset\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        if self.transform:\n",
        "            x = self.transform(dataset[index][0])\n",
        "        else:\n",
        "            x = dataset[index][0]\n",
        "        y = dataset[index][1]\n",
        "        return x, y\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(dataset)\n",
        "    \n",
        "\n",
        "dataset = ImageFolder(data_dir)\n",
        "\n",
        "traindataset = DR(dataset, train_transform)\n",
        "valdataset = DR(dataset, valid_transform)\n",
        "testdataset = DR(dataset, valid_transform)\n",
        "\n",
        "# Create the index splits for training, validation and test\n",
        "\n",
        "num_train = len(dataset)\n",
        "indices = list(range(num_train))\n",
        "split = int(np.floor(train_size * num_train))\n",
        "split2 = int(np.floor((train_size+(1-train_size)/2) * num_train))\n",
        "np.random.shuffle(indices)\n",
        "train_idx, valid_idx, test_idx = indices[:split], indices[split:split2], indices[split2:]\n",
        "\n",
        "traindata = Subset(traindataset, indices=train_idx)\n",
        "valdata = Subset(valdataset, indices=valid_idx)\n",
        "testdata = Subset(testdataset, indices=test_idx)\n",
        "\n",
        "# class_weights = []\n",
        "# for root, subdir, files in os.walk(data_dir):\n",
        "#   if len(files)>0:\n",
        "#     class_weights.append(1/len(files))\n",
        "\n",
        "# sample_weights = [0] * len(traindata)\n",
        "\n",
        "# for idx, (data, label) in enumerate(traindata):\n",
        "#   class_weight = class_weights[label]\n",
        "#   sample_weights[idx] = class_weight\n",
        "\n",
        "\n",
        "# with open('/content/drive/MyDrive/clean_weights.pkl', 'wb') as f:\n",
        "#   pickle.dump(sample_weights, f)\n",
        "\n",
        "with open('/content/drive/MyDrive/clean_weights.pkl', 'rb') as f:\n",
        "  sample_weights = pickle.load(f)\n",
        "\n",
        "sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)\n",
        "\n",
        "trainLoader = torch.utils.data.DataLoader(traindata, sampler=sampler, batch_size=batch_size, \n",
        "                                          num_workers=num_workers, drop_last=True)\n",
        "valLoader = torch.utils.data.DataLoader(valdata, batch_size=batch_size, \n",
        "                                          num_workers=num_workers, drop_last=True)\n",
        "testLoader = torch.utils.data.DataLoader(testdata, batch_size=batch_size,\n",
        "                                          num_workers=num_workers, drop_last=True)\n",
        "dataloaders = {'train': trainLoader, 'val': valLoader, 'test': testLoader}"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyThMaR4nbLF"
      },
      "source": [
        "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False):\n",
        "    since = time.time()\n",
        "\n",
        "    val_acc_history = []\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    # Get model outputs and calculate loss\n",
        "                    # Special case for inception because in training it has an auxiliary output. In train\n",
        "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
        "                    #   but in testing we only consider the final output.\n",
        "                    if is_inception and phase == 'train':\n",
        "                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
        "                        outputs, aux_outputs = model(inputs)\n",
        "                        loss1 = criterion(outputs, labels)\n",
        "                        loss2 = criterion(aux_outputs, labels)\n",
        "                        loss = loss1 + 0.4*loss2\n",
        "                    else:\n",
        "                        outputs = model(inputs)\n",
        "                        loss = criterion(outputs, labels)\n",
        "\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
        "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            if phase == 'val':\n",
        "                val_acc_history.append(epoch_acc)\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, val_acc_history"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75VdlQ8ln1a9"
      },
      "source": [
        "def set_parameter_requires_grad(model, feature_extracting):\n",
        "    if feature_extracting:\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4O8Uqptn8Sb",
        "outputId": "df6912f5-0060-4c1e-9d6d-37603f3bd1fe"
      },
      "source": [
        "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
        "    # Initialize these variables which will be set in this if statement. Each of these\n",
        "    #   variables is model specific.\n",
        "    model_ft = None\n",
        "    input_size = 0\n",
        "\n",
        "    if model_name == \"resnet\":\n",
        "        \"\"\" Resnet18\n",
        "        \"\"\"\n",
        "        model_ft = models.resnet18(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.fc.in_features\n",
        "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"alexnet\":\n",
        "        \"\"\" Alexnet\n",
        "        \"\"\"\n",
        "        model_ft = models.alexnet(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.classifier[6].in_features\n",
        "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"vgg\":\n",
        "        \"\"\" VGG11_bn\n",
        "        \"\"\"\n",
        "        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.classifier[6].in_features\n",
        "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"squeezenet\":\n",
        "        \"\"\" Squeezenet\n",
        "        \"\"\"\n",
        "        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
        "        model_ft.num_classes = num_classes\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"densenet\":\n",
        "        \"\"\" Densenet\n",
        "        \"\"\"\n",
        "        model_ft = models.densenet121(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.classifier.in_features\n",
        "        # model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n",
        "        input_size = 224\n",
        "        classifier_dict = OrderedDict([\n",
        "            ('fc1', nn.Linear(1024, 512)),\n",
        "            ('relu1', nn.ReLU()),\n",
        "            ('dropout1', nn.Dropout(p=0.2)),\n",
        "            ('fc2', nn.Linear(512, 128)),\n",
        "            ('relu2', nn.ReLU()),\n",
        "            ('dropout2', nn.Dropout(p=0.2)),\n",
        "            ('fc3', nn.Linear(128, num_classes)),\n",
        "            ('output', nn.LogSoftmax(dim=1)),\n",
        "            ])\n",
        "            \n",
        "        # creating the classifier for our usage using the ordered dictionary\n",
        "        classifier = nn.Sequential(classifier_dict)\n",
        "\n",
        "        # replacing the pretrained model classifier with our classifier\n",
        "        model_ft.classifier = classifier\n",
        "\n",
        "    elif model_name == \"inception\":\n",
        "        \"\"\" Inception v3\n",
        "        Be careful, expects (299,299) sized images and has auxiliary output\n",
        "        \"\"\"\n",
        "        model_ft = models.inception_v3(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        # Handle the auxilary net\n",
        "        num_ftrs = model_ft.AuxLogits.fc.in_features\n",
        "        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n",
        "        # Handle the primary net\n",
        "        num_ftrs = model_ft.fc.in_features\n",
        "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
        "        input_size = 299\n",
        "\n",
        "    else:\n",
        "        print(\"Invalid model name, exiting...\")\n",
        "        exit()\n",
        "\n",
        "    return model_ft, input_size\n",
        "\n",
        "# Initialize the model for this run\n",
        "model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n",
        "\n",
        "# Print the model we just instantiated\n",
        "print(model_ft)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DenseNet(\n",
            "  (features): Sequential(\n",
            "    (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "    (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu0): ReLU(inplace=True)\n",
            "    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (denseblock1): _DenseBlock(\n",
            "      (denselayer1): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer2): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer3): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer4): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer5): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer6): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (transition1): _Transition(\n",
            "      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "    )\n",
            "    (denseblock2): _DenseBlock(\n",
            "      (denselayer1): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer2): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer3): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer4): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer5): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer6): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer7): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer8): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer9): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer10): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer11): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer12): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (transition2): _Transition(\n",
            "      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "    )\n",
            "    (denseblock3): _DenseBlock(\n",
            "      (denselayer1): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer2): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer3): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer4): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer5): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer6): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer7): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer8): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer9): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer10): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer11): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer12): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer13): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer14): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer15): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer16): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer17): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer18): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer19): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer20): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer21): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer22): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer23): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer24): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (transition3): _Transition(\n",
            "      (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "    )\n",
            "    (denseblock4): _DenseBlock(\n",
            "      (denselayer1): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer2): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer3): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer4): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer5): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer6): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer7): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer8): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer9): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer10): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer11): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer12): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer13): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer14): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer15): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer16): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (fc1): Linear(in_features=1024, out_features=512, bias=True)\n",
            "    (relu1): ReLU()\n",
            "    (dropout1): Dropout(p=0.2, inplace=False)\n",
            "    (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
            "    (relu2): ReLU()\n",
            "    (dropout2): Dropout(p=0.2, inplace=False)\n",
            "    (fc3): Linear(in_features=128, out_features=2, bias=True)\n",
            "    (output): LogSoftmax(dim=1)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6151ULNdzuq",
        "outputId": "56452d1d-8bd8-4090-b2a6-0f79333a70da"
      },
      "source": [
        "# Send the model to GPU\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "# Gather the parameters to be optimized/updated in this run. If we are\n",
        "#  finetuning we will be updating all parameters. However, if we are\n",
        "#  doing feature extract method, we will only update the parameters\n",
        "#  that we have just initialized, i.e. the parameters with requires_grad\n",
        "#  is True.\n",
        "params_to_update = model_ft.parameters()\n",
        "print(\"Params to learn:\")\n",
        "if feature_extract:\n",
        "    params_to_update = []\n",
        "    for name,param in model_ft.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            params_to_update.append(param)\n",
        "            print(\"\\t\",name)\n",
        "else:\n",
        "    for name,param in model_ft.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            print(\"\\t\",name)\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Params to learn:\n",
            "\t features.conv0.weight\n",
            "\t features.norm0.weight\n",
            "\t features.norm0.bias\n",
            "\t features.denseblock1.denselayer1.norm1.weight\n",
            "\t features.denseblock1.denselayer1.norm1.bias\n",
            "\t features.denseblock1.denselayer1.conv1.weight\n",
            "\t features.denseblock1.denselayer1.norm2.weight\n",
            "\t features.denseblock1.denselayer1.norm2.bias\n",
            "\t features.denseblock1.denselayer1.conv2.weight\n",
            "\t features.denseblock1.denselayer2.norm1.weight\n",
            "\t features.denseblock1.denselayer2.norm1.bias\n",
            "\t features.denseblock1.denselayer2.conv1.weight\n",
            "\t features.denseblock1.denselayer2.norm2.weight\n",
            "\t features.denseblock1.denselayer2.norm2.bias\n",
            "\t features.denseblock1.denselayer2.conv2.weight\n",
            "\t features.denseblock1.denselayer3.norm1.weight\n",
            "\t features.denseblock1.denselayer3.norm1.bias\n",
            "\t features.denseblock1.denselayer3.conv1.weight\n",
            "\t features.denseblock1.denselayer3.norm2.weight\n",
            "\t features.denseblock1.denselayer3.norm2.bias\n",
            "\t features.denseblock1.denselayer3.conv2.weight\n",
            "\t features.denseblock1.denselayer4.norm1.weight\n",
            "\t features.denseblock1.denselayer4.norm1.bias\n",
            "\t features.denseblock1.denselayer4.conv1.weight\n",
            "\t features.denseblock1.denselayer4.norm2.weight\n",
            "\t features.denseblock1.denselayer4.norm2.bias\n",
            "\t features.denseblock1.denselayer4.conv2.weight\n",
            "\t features.denseblock1.denselayer5.norm1.weight\n",
            "\t features.denseblock1.denselayer5.norm1.bias\n",
            "\t features.denseblock1.denselayer5.conv1.weight\n",
            "\t features.denseblock1.denselayer5.norm2.weight\n",
            "\t features.denseblock1.denselayer5.norm2.bias\n",
            "\t features.denseblock1.denselayer5.conv2.weight\n",
            "\t features.denseblock1.denselayer6.norm1.weight\n",
            "\t features.denseblock1.denselayer6.norm1.bias\n",
            "\t features.denseblock1.denselayer6.conv1.weight\n",
            "\t features.denseblock1.denselayer6.norm2.weight\n",
            "\t features.denseblock1.denselayer6.norm2.bias\n",
            "\t features.denseblock1.denselayer6.conv2.weight\n",
            "\t features.transition1.norm.weight\n",
            "\t features.transition1.norm.bias\n",
            "\t features.transition1.conv.weight\n",
            "\t features.denseblock2.denselayer1.norm1.weight\n",
            "\t features.denseblock2.denselayer1.norm1.bias\n",
            "\t features.denseblock2.denselayer1.conv1.weight\n",
            "\t features.denseblock2.denselayer1.norm2.weight\n",
            "\t features.denseblock2.denselayer1.norm2.bias\n",
            "\t features.denseblock2.denselayer1.conv2.weight\n",
            "\t features.denseblock2.denselayer2.norm1.weight\n",
            "\t features.denseblock2.denselayer2.norm1.bias\n",
            "\t features.denseblock2.denselayer2.conv1.weight\n",
            "\t features.denseblock2.denselayer2.norm2.weight\n",
            "\t features.denseblock2.denselayer2.norm2.bias\n",
            "\t features.denseblock2.denselayer2.conv2.weight\n",
            "\t features.denseblock2.denselayer3.norm1.weight\n",
            "\t features.denseblock2.denselayer3.norm1.bias\n",
            "\t features.denseblock2.denselayer3.conv1.weight\n",
            "\t features.denseblock2.denselayer3.norm2.weight\n",
            "\t features.denseblock2.denselayer3.norm2.bias\n",
            "\t features.denseblock2.denselayer3.conv2.weight\n",
            "\t features.denseblock2.denselayer4.norm1.weight\n",
            "\t features.denseblock2.denselayer4.norm1.bias\n",
            "\t features.denseblock2.denselayer4.conv1.weight\n",
            "\t features.denseblock2.denselayer4.norm2.weight\n",
            "\t features.denseblock2.denselayer4.norm2.bias\n",
            "\t features.denseblock2.denselayer4.conv2.weight\n",
            "\t features.denseblock2.denselayer5.norm1.weight\n",
            "\t features.denseblock2.denselayer5.norm1.bias\n",
            "\t features.denseblock2.denselayer5.conv1.weight\n",
            "\t features.denseblock2.denselayer5.norm2.weight\n",
            "\t features.denseblock2.denselayer5.norm2.bias\n",
            "\t features.denseblock2.denselayer5.conv2.weight\n",
            "\t features.denseblock2.denselayer6.norm1.weight\n",
            "\t features.denseblock2.denselayer6.norm1.bias\n",
            "\t features.denseblock2.denselayer6.conv1.weight\n",
            "\t features.denseblock2.denselayer6.norm2.weight\n",
            "\t features.denseblock2.denselayer6.norm2.bias\n",
            "\t features.denseblock2.denselayer6.conv2.weight\n",
            "\t features.denseblock2.denselayer7.norm1.weight\n",
            "\t features.denseblock2.denselayer7.norm1.bias\n",
            "\t features.denseblock2.denselayer7.conv1.weight\n",
            "\t features.denseblock2.denselayer7.norm2.weight\n",
            "\t features.denseblock2.denselayer7.norm2.bias\n",
            "\t features.denseblock2.denselayer7.conv2.weight\n",
            "\t features.denseblock2.denselayer8.norm1.weight\n",
            "\t features.denseblock2.denselayer8.norm1.bias\n",
            "\t features.denseblock2.denselayer8.conv1.weight\n",
            "\t features.denseblock2.denselayer8.norm2.weight\n",
            "\t features.denseblock2.denselayer8.norm2.bias\n",
            "\t features.denseblock2.denselayer8.conv2.weight\n",
            "\t features.denseblock2.denselayer9.norm1.weight\n",
            "\t features.denseblock2.denselayer9.norm1.bias\n",
            "\t features.denseblock2.denselayer9.conv1.weight\n",
            "\t features.denseblock2.denselayer9.norm2.weight\n",
            "\t features.denseblock2.denselayer9.norm2.bias\n",
            "\t features.denseblock2.denselayer9.conv2.weight\n",
            "\t features.denseblock2.denselayer10.norm1.weight\n",
            "\t features.denseblock2.denselayer10.norm1.bias\n",
            "\t features.denseblock2.denselayer10.conv1.weight\n",
            "\t features.denseblock2.denselayer10.norm2.weight\n",
            "\t features.denseblock2.denselayer10.norm2.bias\n",
            "\t features.denseblock2.denselayer10.conv2.weight\n",
            "\t features.denseblock2.denselayer11.norm1.weight\n",
            "\t features.denseblock2.denselayer11.norm1.bias\n",
            "\t features.denseblock2.denselayer11.conv1.weight\n",
            "\t features.denseblock2.denselayer11.norm2.weight\n",
            "\t features.denseblock2.denselayer11.norm2.bias\n",
            "\t features.denseblock2.denselayer11.conv2.weight\n",
            "\t features.denseblock2.denselayer12.norm1.weight\n",
            "\t features.denseblock2.denselayer12.norm1.bias\n",
            "\t features.denseblock2.denselayer12.conv1.weight\n",
            "\t features.denseblock2.denselayer12.norm2.weight\n",
            "\t features.denseblock2.denselayer12.norm2.bias\n",
            "\t features.denseblock2.denselayer12.conv2.weight\n",
            "\t features.transition2.norm.weight\n",
            "\t features.transition2.norm.bias\n",
            "\t features.transition2.conv.weight\n",
            "\t features.denseblock3.denselayer1.norm1.weight\n",
            "\t features.denseblock3.denselayer1.norm1.bias\n",
            "\t features.denseblock3.denselayer1.conv1.weight\n",
            "\t features.denseblock3.denselayer1.norm2.weight\n",
            "\t features.denseblock3.denselayer1.norm2.bias\n",
            "\t features.denseblock3.denselayer1.conv2.weight\n",
            "\t features.denseblock3.denselayer2.norm1.weight\n",
            "\t features.denseblock3.denselayer2.norm1.bias\n",
            "\t features.denseblock3.denselayer2.conv1.weight\n",
            "\t features.denseblock3.denselayer2.norm2.weight\n",
            "\t features.denseblock3.denselayer2.norm2.bias\n",
            "\t features.denseblock3.denselayer2.conv2.weight\n",
            "\t features.denseblock3.denselayer3.norm1.weight\n",
            "\t features.denseblock3.denselayer3.norm1.bias\n",
            "\t features.denseblock3.denselayer3.conv1.weight\n",
            "\t features.denseblock3.denselayer3.norm2.weight\n",
            "\t features.denseblock3.denselayer3.norm2.bias\n",
            "\t features.denseblock3.denselayer3.conv2.weight\n",
            "\t features.denseblock3.denselayer4.norm1.weight\n",
            "\t features.denseblock3.denselayer4.norm1.bias\n",
            "\t features.denseblock3.denselayer4.conv1.weight\n",
            "\t features.denseblock3.denselayer4.norm2.weight\n",
            "\t features.denseblock3.denselayer4.norm2.bias\n",
            "\t features.denseblock3.denselayer4.conv2.weight\n",
            "\t features.denseblock3.denselayer5.norm1.weight\n",
            "\t features.denseblock3.denselayer5.norm1.bias\n",
            "\t features.denseblock3.denselayer5.conv1.weight\n",
            "\t features.denseblock3.denselayer5.norm2.weight\n",
            "\t features.denseblock3.denselayer5.norm2.bias\n",
            "\t features.denseblock3.denselayer5.conv2.weight\n",
            "\t features.denseblock3.denselayer6.norm1.weight\n",
            "\t features.denseblock3.denselayer6.norm1.bias\n",
            "\t features.denseblock3.denselayer6.conv1.weight\n",
            "\t features.denseblock3.denselayer6.norm2.weight\n",
            "\t features.denseblock3.denselayer6.norm2.bias\n",
            "\t features.denseblock3.denselayer6.conv2.weight\n",
            "\t features.denseblock3.denselayer7.norm1.weight\n",
            "\t features.denseblock3.denselayer7.norm1.bias\n",
            "\t features.denseblock3.denselayer7.conv1.weight\n",
            "\t features.denseblock3.denselayer7.norm2.weight\n",
            "\t features.denseblock3.denselayer7.norm2.bias\n",
            "\t features.denseblock3.denselayer7.conv2.weight\n",
            "\t features.denseblock3.denselayer8.norm1.weight\n",
            "\t features.denseblock3.denselayer8.norm1.bias\n",
            "\t features.denseblock3.denselayer8.conv1.weight\n",
            "\t features.denseblock3.denselayer8.norm2.weight\n",
            "\t features.denseblock3.denselayer8.norm2.bias\n",
            "\t features.denseblock3.denselayer8.conv2.weight\n",
            "\t features.denseblock3.denselayer9.norm1.weight\n",
            "\t features.denseblock3.denselayer9.norm1.bias\n",
            "\t features.denseblock3.denselayer9.conv1.weight\n",
            "\t features.denseblock3.denselayer9.norm2.weight\n",
            "\t features.denseblock3.denselayer9.norm2.bias\n",
            "\t features.denseblock3.denselayer9.conv2.weight\n",
            "\t features.denseblock3.denselayer10.norm1.weight\n",
            "\t features.denseblock3.denselayer10.norm1.bias\n",
            "\t features.denseblock3.denselayer10.conv1.weight\n",
            "\t features.denseblock3.denselayer10.norm2.weight\n",
            "\t features.denseblock3.denselayer10.norm2.bias\n",
            "\t features.denseblock3.denselayer10.conv2.weight\n",
            "\t features.denseblock3.denselayer11.norm1.weight\n",
            "\t features.denseblock3.denselayer11.norm1.bias\n",
            "\t features.denseblock3.denselayer11.conv1.weight\n",
            "\t features.denseblock3.denselayer11.norm2.weight\n",
            "\t features.denseblock3.denselayer11.norm2.bias\n",
            "\t features.denseblock3.denselayer11.conv2.weight\n",
            "\t features.denseblock3.denselayer12.norm1.weight\n",
            "\t features.denseblock3.denselayer12.norm1.bias\n",
            "\t features.denseblock3.denselayer12.conv1.weight\n",
            "\t features.denseblock3.denselayer12.norm2.weight\n",
            "\t features.denseblock3.denselayer12.norm2.bias\n",
            "\t features.denseblock3.denselayer12.conv2.weight\n",
            "\t features.denseblock3.denselayer13.norm1.weight\n",
            "\t features.denseblock3.denselayer13.norm1.bias\n",
            "\t features.denseblock3.denselayer13.conv1.weight\n",
            "\t features.denseblock3.denselayer13.norm2.weight\n",
            "\t features.denseblock3.denselayer13.norm2.bias\n",
            "\t features.denseblock3.denselayer13.conv2.weight\n",
            "\t features.denseblock3.denselayer14.norm1.weight\n",
            "\t features.denseblock3.denselayer14.norm1.bias\n",
            "\t features.denseblock3.denselayer14.conv1.weight\n",
            "\t features.denseblock3.denselayer14.norm2.weight\n",
            "\t features.denseblock3.denselayer14.norm2.bias\n",
            "\t features.denseblock3.denselayer14.conv2.weight\n",
            "\t features.denseblock3.denselayer15.norm1.weight\n",
            "\t features.denseblock3.denselayer15.norm1.bias\n",
            "\t features.denseblock3.denselayer15.conv1.weight\n",
            "\t features.denseblock3.denselayer15.norm2.weight\n",
            "\t features.denseblock3.denselayer15.norm2.bias\n",
            "\t features.denseblock3.denselayer15.conv2.weight\n",
            "\t features.denseblock3.denselayer16.norm1.weight\n",
            "\t features.denseblock3.denselayer16.norm1.bias\n",
            "\t features.denseblock3.denselayer16.conv1.weight\n",
            "\t features.denseblock3.denselayer16.norm2.weight\n",
            "\t features.denseblock3.denselayer16.norm2.bias\n",
            "\t features.denseblock3.denselayer16.conv2.weight\n",
            "\t features.denseblock3.denselayer17.norm1.weight\n",
            "\t features.denseblock3.denselayer17.norm1.bias\n",
            "\t features.denseblock3.denselayer17.conv1.weight\n",
            "\t features.denseblock3.denselayer17.norm2.weight\n",
            "\t features.denseblock3.denselayer17.norm2.bias\n",
            "\t features.denseblock3.denselayer17.conv2.weight\n",
            "\t features.denseblock3.denselayer18.norm1.weight\n",
            "\t features.denseblock3.denselayer18.norm1.bias\n",
            "\t features.denseblock3.denselayer18.conv1.weight\n",
            "\t features.denseblock3.denselayer18.norm2.weight\n",
            "\t features.denseblock3.denselayer18.norm2.bias\n",
            "\t features.denseblock3.denselayer18.conv2.weight\n",
            "\t features.denseblock3.denselayer19.norm1.weight\n",
            "\t features.denseblock3.denselayer19.norm1.bias\n",
            "\t features.denseblock3.denselayer19.conv1.weight\n",
            "\t features.denseblock3.denselayer19.norm2.weight\n",
            "\t features.denseblock3.denselayer19.norm2.bias\n",
            "\t features.denseblock3.denselayer19.conv2.weight\n",
            "\t features.denseblock3.denselayer20.norm1.weight\n",
            "\t features.denseblock3.denselayer20.norm1.bias\n",
            "\t features.denseblock3.denselayer20.conv1.weight\n",
            "\t features.denseblock3.denselayer20.norm2.weight\n",
            "\t features.denseblock3.denselayer20.norm2.bias\n",
            "\t features.denseblock3.denselayer20.conv2.weight\n",
            "\t features.denseblock3.denselayer21.norm1.weight\n",
            "\t features.denseblock3.denselayer21.norm1.bias\n",
            "\t features.denseblock3.denselayer21.conv1.weight\n",
            "\t features.denseblock3.denselayer21.norm2.weight\n",
            "\t features.denseblock3.denselayer21.norm2.bias\n",
            "\t features.denseblock3.denselayer21.conv2.weight\n",
            "\t features.denseblock3.denselayer22.norm1.weight\n",
            "\t features.denseblock3.denselayer22.norm1.bias\n",
            "\t features.denseblock3.denselayer22.conv1.weight\n",
            "\t features.denseblock3.denselayer22.norm2.weight\n",
            "\t features.denseblock3.denselayer22.norm2.bias\n",
            "\t features.denseblock3.denselayer22.conv2.weight\n",
            "\t features.denseblock3.denselayer23.norm1.weight\n",
            "\t features.denseblock3.denselayer23.norm1.bias\n",
            "\t features.denseblock3.denselayer23.conv1.weight\n",
            "\t features.denseblock3.denselayer23.norm2.weight\n",
            "\t features.denseblock3.denselayer23.norm2.bias\n",
            "\t features.denseblock3.denselayer23.conv2.weight\n",
            "\t features.denseblock3.denselayer24.norm1.weight\n",
            "\t features.denseblock3.denselayer24.norm1.bias\n",
            "\t features.denseblock3.denselayer24.conv1.weight\n",
            "\t features.denseblock3.denselayer24.norm2.weight\n",
            "\t features.denseblock3.denselayer24.norm2.bias\n",
            "\t features.denseblock3.denselayer24.conv2.weight\n",
            "\t features.transition3.norm.weight\n",
            "\t features.transition3.norm.bias\n",
            "\t features.transition3.conv.weight\n",
            "\t features.denseblock4.denselayer1.norm1.weight\n",
            "\t features.denseblock4.denselayer1.norm1.bias\n",
            "\t features.denseblock4.denselayer1.conv1.weight\n",
            "\t features.denseblock4.denselayer1.norm2.weight\n",
            "\t features.denseblock4.denselayer1.norm2.bias\n",
            "\t features.denseblock4.denselayer1.conv2.weight\n",
            "\t features.denseblock4.denselayer2.norm1.weight\n",
            "\t features.denseblock4.denselayer2.norm1.bias\n",
            "\t features.denseblock4.denselayer2.conv1.weight\n",
            "\t features.denseblock4.denselayer2.norm2.weight\n",
            "\t features.denseblock4.denselayer2.norm2.bias\n",
            "\t features.denseblock4.denselayer2.conv2.weight\n",
            "\t features.denseblock4.denselayer3.norm1.weight\n",
            "\t features.denseblock4.denselayer3.norm1.bias\n",
            "\t features.denseblock4.denselayer3.conv1.weight\n",
            "\t features.denseblock4.denselayer3.norm2.weight\n",
            "\t features.denseblock4.denselayer3.norm2.bias\n",
            "\t features.denseblock4.denselayer3.conv2.weight\n",
            "\t features.denseblock4.denselayer4.norm1.weight\n",
            "\t features.denseblock4.denselayer4.norm1.bias\n",
            "\t features.denseblock4.denselayer4.conv1.weight\n",
            "\t features.denseblock4.denselayer4.norm2.weight\n",
            "\t features.denseblock4.denselayer4.norm2.bias\n",
            "\t features.denseblock4.denselayer4.conv2.weight\n",
            "\t features.denseblock4.denselayer5.norm1.weight\n",
            "\t features.denseblock4.denselayer5.norm1.bias\n",
            "\t features.denseblock4.denselayer5.conv1.weight\n",
            "\t features.denseblock4.denselayer5.norm2.weight\n",
            "\t features.denseblock4.denselayer5.norm2.bias\n",
            "\t features.denseblock4.denselayer5.conv2.weight\n",
            "\t features.denseblock4.denselayer6.norm1.weight\n",
            "\t features.denseblock4.denselayer6.norm1.bias\n",
            "\t features.denseblock4.denselayer6.conv1.weight\n",
            "\t features.denseblock4.denselayer6.norm2.weight\n",
            "\t features.denseblock4.denselayer6.norm2.bias\n",
            "\t features.denseblock4.denselayer6.conv2.weight\n",
            "\t features.denseblock4.denselayer7.norm1.weight\n",
            "\t features.denseblock4.denselayer7.norm1.bias\n",
            "\t features.denseblock4.denselayer7.conv1.weight\n",
            "\t features.denseblock4.denselayer7.norm2.weight\n",
            "\t features.denseblock4.denselayer7.norm2.bias\n",
            "\t features.denseblock4.denselayer7.conv2.weight\n",
            "\t features.denseblock4.denselayer8.norm1.weight\n",
            "\t features.denseblock4.denselayer8.norm1.bias\n",
            "\t features.denseblock4.denselayer8.conv1.weight\n",
            "\t features.denseblock4.denselayer8.norm2.weight\n",
            "\t features.denseblock4.denselayer8.norm2.bias\n",
            "\t features.denseblock4.denselayer8.conv2.weight\n",
            "\t features.denseblock4.denselayer9.norm1.weight\n",
            "\t features.denseblock4.denselayer9.norm1.bias\n",
            "\t features.denseblock4.denselayer9.conv1.weight\n",
            "\t features.denseblock4.denselayer9.norm2.weight\n",
            "\t features.denseblock4.denselayer9.norm2.bias\n",
            "\t features.denseblock4.denselayer9.conv2.weight\n",
            "\t features.denseblock4.denselayer10.norm1.weight\n",
            "\t features.denseblock4.denselayer10.norm1.bias\n",
            "\t features.denseblock4.denselayer10.conv1.weight\n",
            "\t features.denseblock4.denselayer10.norm2.weight\n",
            "\t features.denseblock4.denselayer10.norm2.bias\n",
            "\t features.denseblock4.denselayer10.conv2.weight\n",
            "\t features.denseblock4.denselayer11.norm1.weight\n",
            "\t features.denseblock4.denselayer11.norm1.bias\n",
            "\t features.denseblock4.denselayer11.conv1.weight\n",
            "\t features.denseblock4.denselayer11.norm2.weight\n",
            "\t features.denseblock4.denselayer11.norm2.bias\n",
            "\t features.denseblock4.denselayer11.conv2.weight\n",
            "\t features.denseblock4.denselayer12.norm1.weight\n",
            "\t features.denseblock4.denselayer12.norm1.bias\n",
            "\t features.denseblock4.denselayer12.conv1.weight\n",
            "\t features.denseblock4.denselayer12.norm2.weight\n",
            "\t features.denseblock4.denselayer12.norm2.bias\n",
            "\t features.denseblock4.denselayer12.conv2.weight\n",
            "\t features.denseblock4.denselayer13.norm1.weight\n",
            "\t features.denseblock4.denselayer13.norm1.bias\n",
            "\t features.denseblock4.denselayer13.conv1.weight\n",
            "\t features.denseblock4.denselayer13.norm2.weight\n",
            "\t features.denseblock4.denselayer13.norm2.bias\n",
            "\t features.denseblock4.denselayer13.conv2.weight\n",
            "\t features.denseblock4.denselayer14.norm1.weight\n",
            "\t features.denseblock4.denselayer14.norm1.bias\n",
            "\t features.denseblock4.denselayer14.conv1.weight\n",
            "\t features.denseblock4.denselayer14.norm2.weight\n",
            "\t features.denseblock4.denselayer14.norm2.bias\n",
            "\t features.denseblock4.denselayer14.conv2.weight\n",
            "\t features.denseblock4.denselayer15.norm1.weight\n",
            "\t features.denseblock4.denselayer15.norm1.bias\n",
            "\t features.denseblock4.denselayer15.conv1.weight\n",
            "\t features.denseblock4.denselayer15.norm2.weight\n",
            "\t features.denseblock4.denselayer15.norm2.bias\n",
            "\t features.denseblock4.denselayer15.conv2.weight\n",
            "\t features.denseblock4.denselayer16.norm1.weight\n",
            "\t features.denseblock4.denselayer16.norm1.bias\n",
            "\t features.denseblock4.denselayer16.conv1.weight\n",
            "\t features.denseblock4.denselayer16.norm2.weight\n",
            "\t features.denseblock4.denselayer16.norm2.bias\n",
            "\t features.denseblock4.denselayer16.conv2.weight\n",
            "\t features.norm5.weight\n",
            "\t features.norm5.bias\n",
            "\t classifier.fc1.weight\n",
            "\t classifier.fc1.bias\n",
            "\t classifier.fc2.weight\n",
            "\t classifier.fc2.bias\n",
            "\t classifier.fc3.weight\n",
            "\t classifier.fc3.bias\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXg5BAG1oo-f",
        "outputId": "262fa265-72ed-44ac-c549-dc32a10494e9"
      },
      "source": [
        "# # Setup the loss fxn\n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# NLLLoss because our output is LogSoftmax\n",
        "criterion = nn.NLLLoss()\n",
        "\n",
        "# Adam optimizer with a learning rate\n",
        "optimizer_ft = optim.Adam(model_ft.classifier.parameters(), lr = 0.001)\n",
        "\n",
        "\n",
        "# Train and evaluate\n",
        "model_ft, hist = train_model(model_ft, dataloaders, criterion, optimizer_ft, num_epochs=num_epochs, is_inception=(model_name==\"inception\"))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/9\n",
            "----------\n",
            "train Loss: 0.5767 Acc: 0.7198\n",
            "val Loss: 0.4843 Acc: 0.7846\n",
            "\n",
            "Epoch 1/9\n",
            "----------\n",
            "train Loss: 0.5195 Acc: 0.7609\n",
            "val Loss: 0.4330 Acc: 0.7846\n",
            "\n",
            "Epoch 2/9\n",
            "----------\n",
            "train Loss: 0.5108 Acc: 0.7481\n",
            "val Loss: 0.4553 Acc: 0.8154\n",
            "\n",
            "Epoch 3/9\n",
            "----------\n",
            "train Loss: 0.5805 Acc: 0.6684\n",
            "val Loss: 0.6295 Acc: 0.6385\n",
            "\n",
            "Epoch 4/9\n",
            "----------\n",
            "train Loss: 0.5145 Acc: 0.7404\n",
            "val Loss: 0.4538 Acc: 0.7846\n",
            "\n",
            "Epoch 5/9\n",
            "----------\n",
            "train Loss: 0.4888 Acc: 0.7789\n",
            "val Loss: 0.3980 Acc: 0.7923\n",
            "\n",
            "Epoch 6/9\n",
            "----------\n",
            "train Loss: 0.5402 Acc: 0.7404\n",
            "val Loss: 0.4263 Acc: 0.8000\n",
            "\n",
            "Epoch 7/9\n",
            "----------\n",
            "train Loss: 0.4970 Acc: 0.7326\n",
            "val Loss: 0.3740 Acc: 0.8000\n",
            "\n",
            "Epoch 8/9\n",
            "----------\n",
            "train Loss: 0.4798 Acc: 0.7404\n",
            "val Loss: 0.5001 Acc: 0.7000\n",
            "\n",
            "Epoch 9/9\n",
            "----------\n",
            "train Loss: 0.4971 Acc: 0.7198\n",
            "val Loss: 0.3700 Acc: 0.7923\n",
            "\n",
            "Training complete in 2m 19s\n",
            "Best val Acc: 0.815385\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgYraiAjiys8"
      },
      "source": [
        "torch.save(model_ft,'/content/drive/MyDrive/saved_models/densenet_ordered_dict.h5')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpGRminVjRIY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 820
        },
        "outputId": "a9979aa3-bb2f-4a81-aa0f-1ead2d94e9ac"
      },
      "source": [
        "import seaborn as sns\n",
        "nb_classes = num_classes\n",
        "confusion_matrix = np.zeros((nb_classes, nb_classes))\n",
        "with torch.no_grad():\n",
        "    for i, (inputs, classes) in enumerate(dataloaders['test']):\n",
        "        inputs = inputs.to(device)\n",
        "        classes = classes.to(device)\n",
        "        outputs = model_ft(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        print (preds)\n",
        "        for t, p in zip(classes.view(-1), preds.view(-1)):\n",
        "                confusion_matrix[t.long(), p.long()] += 1\n",
        "\n",
        "plt.figure(figsize=(15,10))\n",
        "\n",
        "class_names = ['Normal', 'Glaucoma']\n",
        "df_cm = pd.DataFrame(confusion_matrix, index=class_names, columns=class_names).astype(int)\n",
        "heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
        "\n",
        "heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right',fontsize=15)\n",
        "heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right',fontsize=15)\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n",
            "        0, 1, 0, 1, 1, 1, 1, 0], device='cuda:0')\n",
            "tensor([0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 1], device='cuda:0')\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 1], device='cuda:0')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 69.0, 'Predicted label')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2UAAAKDCAYAAACaHKJ4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd5ildXk38O+9u1QVBcuKaABL9NUkNiTWIGKJmiixa1SiRnxjQaN5LdHYYo8ttpi1ROwFC2InCJZEQbDXWCIKIiiKKGVhd+73j3NWx2F2tnBmzjw7n4/XuWbO8zznmXuWy3PNfb6/Ut0dAAAApmPVtAsAAABYyTRlAAAAU6QpAwAAmCJNGQAAwBRpygAAAKZIUwYAADBFa6ZdAAu7+Oc/sGcBwDba7Wq3mXYJAIOz4aLTa9o1bI2l/Pt4pytdc0n+TSRlAAAAUyQpAwAAhmNm47QrmDhJGQAAwBRpygAAAKbI8EUAAGA4embaFUycpAwAAGCKJGUAAMBwzEjKAAAAmCBJGQAAMBhtThkAAACTJCkDAACGw5wyAAAAJklSBgAADIc5ZQAAAEySpAwAABiOmY3TrmDiJGUAAABTpCkDAACGo2eW7rEFVfX3VfWNqvp6Vb2jqnatqv2r6sSq+l5Vvauqdt7SfTRlAAAA26iq9klyRJIDuvuPkqxOcr8kL0zysu6+dpJfJnnYlu6lKQMAAIZjZmbpHlu2JsluVbUmye5JzkhyuyRHjc8fmeTQLd1EUwYAADCPqjq8qk6e9Th807nuPj3Ji5P8KKNm7FdJTklyTndvGF92WpJ9tvRzrL4IAAAwj+5el2TdfOeqas8kd0+yf5JzkrwnyZ9vz8/RlAEAAIPRy2fz6Nsn+d/u/lmSVNX7ktwqyRWqas04Lbt6ktO3dCPDFwEAALbdj5LcvKp2r6pKckiSbyY5Psm9xtccluToLd1IUgYAAAzH1i3Asei6+8SqOirJF5NsSPKljIY6fjjJO6vqOeNjb9jSvTRlAAAA26G7n5HkGXMO/yDJgdtyH00ZAAAwHMtnTtnEmFMGAAAwRZIyAABgOGY2TruCiZOUAQAATJGkDAAAGA5zygAAAJgkSRkAADAcy2SfskmSlAEAAEyRpAwAABgOc8oAAACYJEkZAAAwHOaUAQAAMEmaMgAAgCkyfBEAABiM7o3TLmHiJGUAAABTJCkDAACGw5L4AAAATJKkDAAAGA5L4gMAADBJkjIAAGA4zCkDAABgkiRlAADAcMzYpwwAAIAJkpQBAADDYU4ZAAAAkyQpAwAAhsM+ZQAAAEySpAwAABgOc8oAAACYJE0ZAADAFBm+CAAADIeFPgAAAJgkSRkAADAckjIAAAAmSVIGAAAMRvfGaZcwcZIyAACAKZKUAQAAw2FOGQAAAJMkKQMAAIajJWUAAABMkKQMAAAYDnPKAAAAmCRJGQAAMBzmlAEAADBJkjIAAGA4zCkDAABgkjRlAAAAU2T4IgAAMBwW+gAAAGCSJGUAAMBwWOgDAACASZKUAQAAwyEpAwAAYJIkZQAAwHBYfREAAIBJkpQBAADDYU4ZAAAAkyQpAwAAhsOcMgAAACZJUgYAAAzHMppTVlXXTfKuWYeumeTpSd48Pr5fkh8muU93/3Jz95GUAQAAbIfu/k5336i7b5TkpknOT/L+JE9Oclx3XyfJcePnmyUpAwAAhmP5zik7JMn3u/vUqrp7ktuOjx+Z5IQkT9rcCyVlAAAA86iqw6vq5FmPwxe4/H5J3jH+fm13nzH+/qdJ1i70cyRlAAAA8+judUnWbem6qto5yd2SPGWee3RV9UKv15QBAADDsYwW+pjlzkm+2N1njp+fWVV7d/cZVbV3krMWerHhiwAAAJfO/fO7oYtJ8sEkh42/PyzJ0Qu9WFIGAAAMxzJLyqrqMknukOQRsw6/IMm7q+phSU5Ncp+F7qEpAwAA2E7dfV6SK845dnZGqzFuFU0ZAAAwHL3gmhmDZE4ZAADAFEnKAACA4Vhmc8omQVIGAAAwRZIyAABgOCRlAAAATJKkDAAAGI6WlAEAADBBkjIAAGA4zCkDAABgkiRlAADAcHRPu4KJk5QBAABMkaYMAABgigxfBAAAhsNCHwAAAEySpAwAABgOSRkAAACTJCkDAACGoyVlAAAATJCkDAAAGIyesXk0AAAAEyQpAwAAhsPqiwAAAEySpAwAABgOqy8CAAAwSZIyAABgOKy+CAAAwCRJygAAgOGw+iIAAACTpCkDAACYIsMXAQCA4TB8EQAAgEmSlAEAAMPRlsQHAABggiRlAADAcJhTBgAAwCQNrimrqmdWVVfVx+c5d1RVnTCFsrZJVd12/Dv80bRrAQCAQZnppXsskSEPX7xjVd2su78w7UJgJXjzO9+f9x7zsVRVrnOt/fKcf3x8nvPSV+cb3/5uujv7XWOfPPepT8juu+827VIBlp1ddtklJ3zyvdl5l12yZs3qvO99H86znv2SaZcFLBNDbcp+keT0JE9Ncugkb1xVu3X3BZO8JwzdmT/7ed521NE5+m3/nl132SVP+Kfn5aP/+ak86YjDc9nLXCZJ8qJXrMvb33tM/vZB95lytQDLz/r163P7O94n5513ftasWZNPn/D+fOxjx+fEk7447dJgeNqcsuWikzw3yd2q6o83d1FV3aiqjquq86vql1X1tqpaO+v8fuNhhH9dVW+uqnOSHDPr+P2q6j+q6tyqOq2qHjh+3ROr6idV9bOqemFVrZp1z+tV1Tur6sfjn/uNqnrc7GtgiDZs3Jj16y/Khg0bc8GF63PlK+3124asu3Ph+vWpmnKRAMvYeeednyTZaac1WbPTTukdcFlvYPsMuVF4T5LvZpSWXUJVXTnJCUl2T/KAJI9JclCSY6tq5zmXvzjJr5PcO8nzZh1/YZIzktwzyWeSHFlVL0lyYJKHJnl5kicmmR0N7JPkO0kemeQuSV6X5FlJnrR9vyZM39orXyl/c/975vb3eHAOvvsDcrnL7J5b/elNkyRPe+5Lc9BfPiD/e+ppecC97jblSgGWr1WrVuXkL3wiZ5z+1Rx33Kdz0he+NO2SYJh2wDllg23KunsmyfOT3Luq/nCeS54w/nqn7v5Ad781o+bqj8dfZ/t8dz+qu4/t7k/OOv7J7v7H7j42ySOSzCS5W5L7dvfHuvu5Sb6Q5K9m1XVcdz+ju49J8qkkr8qouXv4pf6lYUp+de6vc/xnPp+Pv+c/8smj35YLLlyfYz4++r/Kc576+Bx/9Ftzzf2ukY8d9+kpVwqwfM3MzOSAm90x++5/QG52wI1zgxtcd9olAcvEYJuysbcm+VGSp8xz7sAkn+juczcd6O4Tk/wwya3nXPvhzdz/uFmvPTfJz5J8qrs3zrrmexmlY0mSqtq1qp5VVd9Lsj7JxRkNtdy/qrZqDl9VHV5VJ1fVya9/8zu25iWwqD5/8pezz9XWZq89r5Cd1qzJIQfdMl/+2jd/e3716tW58+0PyrEn/NcUqwQYhl/96tyc8Kn/yp3ueNtplwKD1DMzS/ZYKoNuyrp7Q5IXJXlgVe075/TeSc6c52VnJtlrnmPzOWfO84s2c2zXWc9fmOQfkqzLaPjizZI8Z3xu12yF7l7X3Qd09wF/++D7b81LYFHtvfbK+erXv50LLrww3Z0TT/5yrrnvNfKj036SZDSn7PjPfj7773v1KVcKsDxd6Up75fKX3yNJsuuuu+b2h/xZvvOd70+5KmC5GOrqi7O9McnTcsk5W2ckuco8169NcsqcY5McMHrvJK/s7hdtOlBVd53g/WHJ/ckNrpc7HHzr3Ochj8nq1atzvT+8Vu599zvnoUc8Jeedd366O9e99v75p//36GmXCrAs7b332rzxDS/P6tWrsmrVqhx11DH58Ef+c9plwTAt4VyvpTL4pqy711fVizOaX3ZKRsMFk+TEJH9XVZfr7l8nSVXdLMl+ST67iCXtltGwxYx/5uok91vEnwdL4tF/+6A8+m8f9HvH3vpae+wAbI2vfe1budmBd5p2GcAyNejhi7P8e0arJ95y1rGXjr9+vKruXlV/neR9Sb6W5L2LWMuxSR5VVQ8aJ2THJNllEX8eAACsHD2zdI8lskM0Zd19fpKXzTn2syQHJ7kwyTuSvDqjZe3v0N0XLWI5jxn/nFdnNLTy6xmleAAAAJdQNi5c3i7++Q/8BwLYRrtd7TbTLgFgcDZcdHpNu4atcd5zHrhkfx9f5mlvXZJ/k8HPKQMAAFaQHXChjx1i+CIAAMBQScoAAIDhWMJNnZeKpAwAAGCKJGUAAMBwmFMGAADAJEnKAACA4VjCTZ2XiqQMAABgiiRlAADAcJhTBgAAwCZVdYWqOqqqvl1V36qqW1TVXlV1bFV9d/x1z4XuoSkDAAAGo2dmluyxlf41yce6+3pJbpjkW0menOS47r5OkuPGzzdLUwYAALAdqurySf4syRuSpLsv6u5zktw9yZHjy45McuhC9zGnDAAAGI7lNads/yQ/S/IfVXXDJKckeWyStd19xvianyZZu9BNJGUAAADzqKrDq+rkWY/D51yyJslNkvxbd984yXmZM1SxuzvJgp2kpAwAABiOJUzKuntdknULXHJaktO6+8Tx86MyasrOrKq9u/uMqto7yVkL/RxJGQAAwHbo7p8m+XFVXXd86JAk30zywSSHjY8dluTohe4jKQMAANh+j0nytqraOckPkjwko/Dr3VX1sCSnJrnPQjfQlAEAAMPRW71U/ZLo7i8nOWCeU4ds7T0MXwQAAJgiSRkAADAcy2tJ/ImQlAEAAEyRpAwAABiMlpQBAAAwSZIyAABgOCRlAAAATJKkDAAAGI6Z5bVP2SRIygAAAKZIUgYAAAyHOWUAAABMkqQMAAAYDkkZAAAAkyQpAwAABqNbUgYAAMAEacoAAACmyPBFAABgOCz0AQAAwCRJygAAgOGQlAEAADBJkjIAAGAwWlIGAADAJEnKAACA4ZCUAQAAMEmSMgAAYDhmpl3A5EnKAAAApkhSBgAADIbVFwEAAJgoSRkAADAckjIAAAAmSVIGAAAMh9UXAQAAmCRNGQAAwBQZvggAAAyGJfEBAACYKEkZAAAwHBb6AAAAYJIkZQAAwGCYUwYAAMBEScoAAIDhMKcMAACASZKUAQAAg9GSMgAAACZJUgYAAAyHpAwAAIBJkpQBAACDYU4ZAAAAEyUpAwAAhkNSBgAAwCRpygAAAKbI8EUAAGAwLPQBAADAREnKAACAwZCUAQAAMFGSMgAAYDAkZQAAAEyUpAwAABiOrmlXMHGSMgAAgCmSlAEAAIOxI84p05QBAABsp6r6YZJfJ9mYZEN3H1BVeyV5V5L9kvwwyX26+5ebu4fhiwAAwGD0TC3ZYxsc3N036u4Dxs+fnOS47r5OkuPGzzdLUwYAADBZd09y5Pj7I5McutDFhi8CAACDsQznlHWST1RVJ/n37l6XZG13nzE+/9Mkaxe6gaYMAABgHlV1eJLDZx1aN266Zrt1d59eVVdJcmxVfXv2ye7uccO2WZoyAABgMHoJ9ykbN2Bzm7C515w+/npWVb0/yYFJzqyqvbv7jKraO8lZC93DnDIAAIDtUFWXqarLbfo+yR2TfD3JB5McNr7ssCRHL3QfSRkAAMD2WZvk/VWVjHqrt3f3x6rqC0neXVUPS3JqkvssdBNNGQAAMBjLaaGP7v5BkhvOc/zsJIds7X0MXwQAAJgiSRkAADAY27ip8yBIygAAAKZIUgYAAAxGL7jj1zBJygAAAKZIUgYAAAyGOWUAAABMlKQMAAAYDEkZAAAAEyUpAwAABsPqiwAAAEyUpAwAABgMc8oAAACYKEkZAAAwGN2SMgAAACZIUwYAADBFhi8CAACD0TPTrmDyJGUAAABTJCkDAAAGY8ZCHwAAAEzSZpOyqnplkt7c+e4+YlEqAgAA2IwdcUn8hYYvnrxkVQAAAKxQm23KuvvI2c+ravfuPn/xSwIAAJhfz+x4SdkW55RV1S2q6ptJvj1+fsOqes2iVwYAALACbM1CHy9PcqckZydJd38lyZ8tZlEAAADz6V66x1LZqtUXu/vHcw5tXIRaAAAAVpyt2afsx1V1yyRdVTsleWySby1uWQAAAJe0IueUJfm/SR6VZJ8kP0lyo/FzAAAALqUtJmXd/fMkf70EtQAAACxoZgfcp2xrVl+8ZlUdU1U/q6qzquroqrrmUhQHAACwo9ua4YtvT/LuJHsnuVqS9yR5x2IWBQAAMJ/uWrLHUtmapmz37n5Ld28YP96aZNfFLgwAAGAl2Oycsqraa/ztR6vqyUnemaST3DfJR5agNgAAgB3eQgt9nJJRE7Ypt3vErHOd5CmLVRQAAMB8lnJT56Wy2aasu/dfykIAAABWoq3ZPDpV9UdJrp9Zc8m6+82LVRQAAMB8dsQl8bfYlFXVM5LcNqOm7CNJ7pzks0k0ZQAAAJfS1iRl90pywyRf6u6HVNXaJG9d3LIAAAAuaSmXql8qW7Mk/gXdPZNkQ1XtkeSsJNdY3LIAAABWhq1Jyk6uqiskeV1GKzL+JsnnFrUqAACAeayo1Rc36e5Hjr99bVV9LMke3f3VxS0LAABgZVho8+ibLHSuu7+4OCUBAADMb6WtvviSBc51kttNuBbm8eKbPn3aJQAMznX3vPq0SwCArbbQ5tEHL2UhAAAAW7JSV18EAABgkWzN6osAAADLwo44p0xSBgAAMEVbbMpq5IFV9fTx8z+oqgMXvzQAAIDf10v4WCpbk5S9Jsktktx//PzXSV69aBUBAACsIFszp+xPu/smVfWlJOnuX1bVzotcFwAAwIqwNU3ZxVW1OuMEr6qunGRmUasCAACYx0pd6OMVSd6f5CpV9dwkn03yvEWtCgAAYIXYYlLW3W+rqlOSHJKkkhza3d9a9MoAAADm2BE3j95iU1ZVf5Dk/CTHzD7W3T9azMIAAABWgq2ZU/bhjOaTVZJdk+yf5DtJbrCIdQEAAFzCjri4xdYMX/zj2c+r6iZJHrloFQEAAKwgW5OU/Z7u/mJV/eliFAMAALCQzsqcU/b4WU9XJblJkp8sWkUAAAAryNYkZZeb9f2GjOaYvXdxygEAANi8mZ52BZO3YFM23jT6ct39D0tUDwAAwGCMe6aTk5ze3X9RVfsneWeSKyY5JcmDuvuihe6x2c2jq2pNd29McqsJ1gwAALDdZlJL9thKj00yex/nFyZ5WXdfO8kvkzxsSzfYbFOW5KTx1y9X1Qer6kFVdY9Nj62tEAAAYEdUVVdPctckrx8/ryS3S3LU+JIjkxy6pftszZyyXZOcPb75pv3KOsn7trlqAACAS2GZrb748iRPzO/W4bhiknO6e8P4+WlJ9tnSTRZqyq4yXnnx6/ldM7bJDji9DgAA4Heq6vAkh886tK67143P/UWSs7r7lKq67aX5OQs1ZauTXDaZtxXVlAEAAEtuZgl/1rgBW7eZ07dKcrequktGowv3SPKvSa4wXp9jQ5KrJzl9Sz9noabsjO5+9raVDQAAsOPr7qckeUqSjJOyf+juv66q9yS5V0YrMB6W5Ogt3WuhhT6W1WBNAACAAXhSksdX1fcymmP2hi29YKGk7JBJVQUAADAJy2yhjyRJd5+Q5ITx9z9IcuC2vH6zSVl3/+LSFAYAAMCWbc2S+AAAAMvCUi70sVQWmlMGAADAIpOUAQAAgyEpAwAAYKIkZQAAwGAsx9UXLy1JGQAAwBRJygAAgMGY2fGCMkkZAADANEnKAACAwZgxpwwAAIBJkpQBAACD0dMuYBFIygAAAKZIUgYAAAzGzLQLWASSMgAAgCmSlAEAAIMxU1ZfBAAAYII0ZQAAAFNk+CIAADAYlsQHAABgoiRlAADAYFgSHwAAgImSlAEAAIMxs+OtiC8pAwAAmCZJGQAAMBgz2fGiMkkZAADAFEnKAACAwbBPGQAAABMlKQMAAAbD6osAAABMlKQMAAAYjJlpF7AIJGUAAABTJCkDAAAGw+qLAAAATJSmDAAAYIoMXwQAAAbDkvgAAABMlKQMAAAYDEviAwAAMFGSMgAAYDAkZQAAAEyUpAwAABiMtvoiAAAAkyQpAwAABsOcMgAAACZKUgYAAAyGpAwAAICJkpQBAACD0dMuYBFIygAAAKZIUgYAAAzGjH3KAAAAmCRNGQAAwBQZvggAAAyGJfEBAACYKEkZAAAwGJIyAAAAJkpSBgAADIbNowEAAJgoSRkAADAYNo8GAAAgSVJVu1bVSVX1lar6RlU9a3x8/6o6saq+V1XvqqqdF7qPpgwAABiMmSV8bIX1SW7X3TdMcqMkf15VN0/ywiQv6+5rJ/llkoctdBNNGQAAwHbokd+Mn+40fnSS2yU5anz8yCSHLnQfTRkAADAYvYSPrVFVq6vqy0nOSnJsku8nOae7N4wvOS3JPgvdQ1MGAAAwj6o6vKpOnvU4fO413b2xu2+U5OpJDkxyvW39OVZfBAAABmNmCXcq6+51SdZt5bXnVNXxSW6R5ApVtWacll09yekLvVZSBgAAsB2q6spVdYXx97sluUOSbyU5Psm9xpcdluTohe4jKQMAAAZjK1dFXCp7JzmyqlZnFHi9u7s/VFXfTPLOqnpOki8lecNCN9GUAQAAbIfu/mqSG89z/AcZzS/bKoYvAgAATJGkDAAAGIylW+Zj6UjKAAAApkhSBgAADMYyW+hjIiRlAAAAUyQpAwAABmOmpl3B5EnKAAAApkhSBgAADMbMDrj+oqQMAABgiiRlAADAYOx4OZmkDAAAYKokZQAAwGDYpwwAAICJkpQBAACDYfVFAAAAJkpSBgAADMaOl5NJygAAAKZKUwYAADBFhi8CAACDYUl8AAAAJkpSBgAADIYl8QEAAJgoSRkAADAYO15OJikDAACYKkkZAAAwGFZfBAAAYKIkZQAAwGD0DjirTFIGAAAwRZIyAABgMMwpAwAAYKIkZQAAwGDMmFMGAADAJEnKAACAwdjxcjJJGQAAwFRpygAAAKbI8EUAAGAwLPQBAADARC1JU1ZVh1bVJ6rq7Kq6qKpOr6qjqurPZ13TVfXopagHAAAYppklfCyVRR++WFUvS3JEkjcn+bckZyfZN8n9kny0qq7d3d9f7DqA7bd6l53ywHc/Lat3XpNVa1bnOx85KZ952fty+WtcOYe+8lHZbc/L5Yyv/W+O+ft/y8zFG6ddLsCy8M8vf1oOusOt8ouf/zKHHvSAJMkTnv6Y3PaOt87FF1+cH//w9Dztsf+cX5/7mylXCkzboiZlVXX3JI9L8rDufkh3v7+7P93db+nuuya5W5ILFrMG4NLbuP7ivP3+z8sb7/zUvPHOT801D/qTXO3G18rBT75fTnrDx/Lag56QC391Xm5439tOu1SAZeMD7/xQHnG/x/3esc996qQcetADco+DH5hTv/+jPPyIw6ZUHQxXL+H/lspiD198XJIvdPeb5jvZ3cd090/mO1dVd62qY6vqrKo6t6o+X1V3nHPNm6rq5DnH9hsPhfyLWcdWV9VTqup/qmp9VZ1WVW+a87pHV9V3x+e/V1V/P+f8M6vq51X1p1V1clVdUFWfrar9q+oqVfWBqvpNVX2rqm4357UPHl/7i6r6ZVUdX1UHbMW/HywbF5+/Pkmyas3qrNppTdLJvre8fr79kZOSJF9/72fyh3e86TRLBFhWTvn8l/Orc879vWP//akTs3HjaETBV075etZe7SrTKA1YZhZt+GJVrUlyiyQv3s5b7J/kmPHrZ5LcOaPhjn/W3f+1jff69yQPTvKiJJ9KsleSe86q9eFJXpnkpUk+nuTgJC+pql26+wWz7rN7knXj+5yX5BVJ3pJkfZKPJnlNkicmeU9VXaO7zx+/br+Mhm9+P8nOSe6f5DNVdYPu/sE2/i4wFbWq8pAPPSd77rc2p7z52Pzy1DOz/tzz0xtHI67PPeMXudxV95xylQDDcY8H/GU++oH/nHYZMDhLOddrqSzmnLIrJtklyY9nH6yqSrJ61qGN3X2JbLC7XzXrNauSHJ/kBkkelmSrm7Kqut74NY/t7lfMOvWuWfd+ZpI3dfcTxuc+UVWXT/KUqnp5d184Pr5bkiO6+1Pj114tyauTPKO7Xzw+dlqSbyQ5KKNGLd397Dm/y7FJDkzywCS/PQfLWc903niXp2aXPXbPPdc9Lle81tWmXRLAYB3+uL/Jhg0b86H3fmzapQDLwFKsvji34XpCkotnPR4134uq6upVdWRVnZ5kw/jaOyb5w238+QePv75pM+evnuRqSd4z5/i7kuyR5I9nHbsoyWdmPf/e+Osn5zm2z6YDVfV/qur9VXVmko0Z/S7XzWZ+l6o6fDxE8uSTfvPdzZQN07H+3PNz6n9/M/vc9DrZZY/dU6tHbyN77L1Xfv3TX065OoDl79D73jUH3eHWedIjnz7tUmCQzCnbNmdnNKzv6nOOvyXJzcaPeY3TpA8muWWSp2fUWN0so+Rp122s44pJzuvuczdzfu/x1zPnHN/0fK9Zx37d3bMT04vGX8/ZdKC7Nx3bNUmq6nJJPpHkGkken+Q2Gf0uX8lmfpfuXtfdB3T3AQde9jqb+71gyey21+Wyyx67J0nW7LJT9r/NH+fs756eUz/3zVzvLgcmSf7onrfJd4/94jTLBFj2bn3wzfPQRz0oj37wP+TCC9ZPuxxgmVi04YvdvaGqPpdRuvX0WcfPzLjhGY1knNe1k9w4yZ27+7e5flXtNue6CzOaozXb3EktZye5TFXtsZnG7Izx17kzbdeOv/5ic0VupVtk1Jjeobu/vengeHgkDMJlr3KF/MVLH5FVq1alVlW+9aET871Pfjk//+7pufurHp2D/uHe+ek3fpivvOuEaZcKsGz8y2v/OTe75U1yhb2ukOO+dExe/S/r8vAjDstOO++c17/7lUlGi308+4kvnHKlMCzmlG27lyf5QFU9qLvfsg2v29R8/fYjpKraN8mtknx11nWnJdmvqnadNe/r91ZozO+GFj44yatySacl+UmSe2c8B2zsPknOTfK1bah7PvP9LrfMaPGPUy7lvWFJ/OzbP85/3OVplzh+zo9/liPv/owpVASw/P2///tPlzj2vrcfM4VKgOVuUZuy7j66ql6e5E1VdYe9G3sAABmISURBVHBGqyn+PKMhhZuap/l2TPx2Rs3SS6rqn5JcLsmzkpw+57oPZLRQxuvHS9zfOMlD59TwnapaN77XVZJ8OskVktyru+/X3TNV9cwk/15VZ2e0CMdBSf4uyT/Oava21+fHv+PrqupFGaVmz5zndwEAALZg5pJrBA7eoi/00d1/n+ReGc2pekNGydVrMhoeeJf59jDr7vVJ7pHRAh9HJfnnJM/PaDn72dd9PaMm7BYZzUE7KMlD5injkRk1dQ9M8pGMErxNy9Wnu1+X5LFJ/irJhzJasv4Jc5bD3y7j4Zr3TnLVJEdntHfb/83vFgQBAABWsJpnNXqWkefv+0D/gQC20VsvtHItwLb6xpknbnbBh+XkgfveY8n+Pn7rqe9bkn+TpVgSHwAAgM3QlAEAAEzRYq++CAAAMDEzS7ip81KRlAEAAEyRpAwAABiMlpQBAAAwSZIyAABgMGamXcAikJQBAABMkaQMAAAYDKsvAgAAkCSpqmtU1fFV9c2q+kZVPXZ8fK+qOraqvjv+uudC99GUAQAAg9FL+L+tsCHJE7r7+klunuRRVXX9JE9Oclx3XyfJcePnm6UpAwAA2A7dfUZ3f3H8/a+TfCvJPknunuTI8WVHJjl0ofuYUwYAAAzGcl19sar2S3LjJCcmWdvdZ4xP/TTJ2oVeKykDAACYR1UdXlUnz3ocvpnrLpvkvUke193nzj7X3Z0sPBZSUgYAAAzGqMdZsp+1Lsm6ha6pqp0yasje1t3vGx8+s6r27u4zqmrvJGctdA9JGQAAwHaoqkryhiTf6u6Xzjr1wSSHjb8/LMnRC91HUgYAAAzGMtun7FZJHpTka1X15fGxf0zygiTvrqqHJTk1yX0WuommDAAAYDt092eT1GZOH7K19zF8EQAAYIokZQAAwGAs1yXxLw1JGQAAwBRJygAAgMHo5bXQx0RIygAAAKZIUgYAAAzGMlsSfyIkZQAAAFMkKQMAAAajW1IGAADABEnKAACAwbBPGQAAABMlKQMAAAbDPmUAAABMlKQMAAAYDPuUAQAAMFGSMgAAYDDsUwYAAMBEacoAAACmyPBFAABgMCz0AQAAwERJygAAgMGweTQAAAATJSkDAAAGY8aS+AAAAEySpAwAABiMHS8nk5QBAABMlaQMAAAYDPuUAQAAMFGSMgAAYDAkZQAAAEyUpAwAABiMtk8ZAAAAkyQpAwAABsOcMgAAACZKUwYAADBFhi8CAACD0YYvAgAAMEmSMgAAYDAsiQ8AAMBEScoAAIDBsCQ+AAAAEyUpAwAABsOcMgAAACZKUgYAAAyGOWUAAABMlKQMAAAYjJaUAQAAMEmSMgAAYDBmrL4IAADAJEnKAACAwTCnDAAAgImSlAEAAINhThkAAAATpSkDAACYIsMXAQCAwbDQBwAAABMlKQMAAAbDQh8AAABMlKQMAAAYDHPKAAAASJJU1Rur6qyq+vqsY3tV1bFV9d3x1z23dB9NGQAAMBgz3Uv22ApvSvLnc449Oclx3X2dJMeNny9IUwYAALAduvvTSX4x5/Ddkxw5/v7IJIdu6T7mlAEAAIMxgDlla7v7jPH3P02ydksvkJQBAADMo6oOr6qTZz0O35bXd3cnW+4iJWUAAMBgdM8s4c/qdUnWbePLzqyqvbv7jKraO8lZW3qBpAwAAGByPpjksPH3hyU5eksvkJQBAACDMbOM5pRV1TuS3DbJlarqtCTPSPKCJO+uqoclOTXJfbZ0H00ZAADAduju+2/m1CHbch9NGQAAMBi9dfuHDYo5ZQAAAFOkKQMAAJgiwxcBAIDBWE4LfUyKpAwAAGCKJGUAAMBgWOgDAACAiZKUAQAAgzEjKQMAAGCSJGUAAMBgtNUXAQAAmCRJGQAAMBhWXwQAAGCiJGUAAMBgzJhTBgAAwCRJygAAgMEwpwwAAICJkpQBAACDMSMpAwAAYJI0ZQAAAFNk+CIAADAYFvoAAABgoiRlAADAYNg8GgAAgImSlAEAAINhThkAAAATJSkDAAAGw+bRAAAATJSkDAAAGIy2+iIAAACTJCkDAAAGw5wyAAAAJkpSBgAADIZ9ygAAAJgoSRkAADAYVl8EAABgojRlAAAAU2T4IgAAMBgW+gAAAGCiJGUAAMBgSMoAAACYKEkZAAAwGDteTpbUjhj/AUujqg7v7nXTrgNgKLxvAvMxfBG4NA6fdgEAA+N9E7gETRkAAMAUacoAAACmSFMGXBrmRQBsG++bwCVY6AMAAGCKJGUAAABTpCkDAACYIk0ZAADAFGnKAAAApkhTBqSqdq2qK067DgCAlUhTBitcVa1KcnSSE6pq7bTrAQBYaTRlsMJ190ySFye5XJJ3aswAtqyqVk+7BmDHYZ8yIFVVSW6T5O1Jvpfkvt195nSrAlieqmp1d28cf/+0JNdOsm+SNyb5z+4+Y5r1AcMjKQPSo09nPpPkARn9cfEuiRnAJVVVzWrI3pnk4UnOTfKTJM9L8tyq2m9qBQKDpCmDFWqcjv3WuDH7ryR/HY0ZwLzG75WpqucluUmSe3f3EUk+m2SfJIckeU5V/cH0qgSGRlMGK9B46M2mPyz2GD92GX/6+7lozAA2q6qunuRqSZ7d3SdV1ZOSvDLJvZO8Jcl9MmrM9p1imcCAmFMGK8ycuRAvSHJgkism+UGSv+vun1bVTklumeRtMccM4BKq6v5JPpnk+knekeSfuvt143MnZPTB1heTPKa7T51WncAwSMpgBZlnLsT9khyT0Se8t0zyX1V17e6+OL8byrhvko9V1VWmVDbA1GxulcXufsf4w6qbJDkzySdmnb4wyW+SXCnJxYteJDB4mjJYQWYNWXxykj/JKAF7WZI9M1oSf5cknx43ZhsyaswenmTnJLtNp2qA6ZgzsuCeVfWQqrrOnDm510hy1U1pWFXtleRXGb133rW7f7LkhQODY/girDBVtXuSxyfZ0N0vqKrHJ3lBkgdn9Gnvu5L8Osntu/t/q2pNkp26+4KpFQ0wReORBX+RZGOSXZM8M8mbuvuMqvrDJJ9O8s2M0rIDkhyU5Cbd/ePpVAwMzZppFwAsnfGnuxck+XCS06rqBkmOSPKEJO/q7q6qDyX5myTfqKo/6e7vJdkwrZoBltp4qPemkQV/ltH8sLsl+VGSByZ5bpI9q+pfu/t/quohSf4lyd8lOTvJIRoyYFtoymAHNnvoTfJ7wxe/PG7Abptk9ySf7t/F5mclOXr8vSHOwIoy930zo7+VPp/k+PH75DOr6oIkz0+yqqpe1N0frapjk1w1ybndfe7SVw4MmaYMdlBVtWrWXIjHJfmDjFYC++/u/sH4sl2TzCS5WlV9NckeSa6V0bL4/9rd65e+coDpmLMY0vMzarKuldHQ7l2q6qLununuF1bVTJIXJtlYVa/t7v9NctrUigcGzZwy2MFV1duS3CHJOUkun+RrSZ7a3SdW1eUz2vB0p4zmQ+yc5FZJbjYetgiwIow/yJoZf/+2jDaB/kGSyya5TpJ7dvdH5lz3hIyGLT4noz3LDPUGtouhSbCDmb0qWFVdM8k+Se6R5HoZzR3bPcmrq+o23f2rJAcn+WpGe5WtSXIbDRmw0sxqtC6f5Lwk98zoA637ZbQf2Vuq6rbdPVNVq8aveUmSxyV5p4YMuDQkZbADmbN8865J9s5oQvojuvvX4+P3zGj1xV2T/H13f7qqds5oMY9drLIIrFRV9aIkD8lobu3duvv74+N/kOTfktw8o8TshNmJGcClJSmDHcScuRD/luQ/k5yQ5PpJLrPpuu5+b5KXZLS56b+MP/ndNE9CQwasSONNon+c5IdJrpLRe+SmYY0/ymhlxc8leWdV3UFDBkySpgx2AOOEbNPKii9OcmhGQxL/J6NNop9YVVfddH13vy+jeRCXTfKMcaoGsGJsGoK4yfhDrdcneU1GIwc+UFW7jIcr1qzG7LtJXjve8xFgIqy+CDuAWQnZ/kn2TPLI7n7/+NirM5oTcUFVvaK7zxy/5gNVtTHJ17r7wimVDrDk5gz1vlqSzmjXkJ9W1dszWpX2mUk+XlV/3t0XjhuzH1fV/ZKs6u7zp/YLADscSRkM2OxPeqvqKUm+n+TWSU7fdLy7H5XkvUkemuSIqlo769wx3f3DJSsYYMrmbBfymiQfSvL1JCdU1UPHW4G8LcmzMtpK5OPjxKzHjdnpNoYGJk1SBgM1Z1nmByV5e5KDktwxyU3HG0RflCTd/ZjxoowPSnKZqnped581pdIBpmbW++ZbM3rPfFlGfw/dOMnrqur6SZ6S5B0ZfXj9xCQnVdWB9m4EFoumDAZo/Gntpj8s3pTkFhkt3/w3Sd6f5ElJvlZV/73punFjdtkkd8poRUaAFamqbpbklkke393vGR/bNcl/Z9Sknd7dLxsPZdwlyeEZbSR96pRKBnZwlsSHgRk3ZJsW9bh+RpPSn5/k+O6+aLygx4eT7JHR0s6/bczGr1m7aV4ZwEpUVQclOT7JQd39mVnHK8nLM3rvPKC7/2e8Zchu430dARaFOWUwMLMasjcm+deMEu+Txw3Zqu7+aZK7JPlVkjclueXsuWcaMmAlGS91P9dvMtqL7Hqb3h9nfeD1oYzeV6+aJOMtQzRkwKLSlMFwfS3JIUlumOTayWiuxPgPizOT3DXJz5N8MMmfTq1KgCmZs8riEeOVE9PdpyQ5JcmTk1x3fGzT0KH1SX6ZZOPSVwysVJoyGIA5qyyuSpLufllGQ2wuk+Rvq+oq4+M9qzH7qyRfTvKzpa8aYHrG74ObGrJ3J3lUkkNn7dn4kCTnJXlfVf1lVV2lqq6d5GHj49+bRt3AymROGSxzcz7p3T3JHuMhipvOPzLJq5K8NMkLuvvn4+M1btB++3qAlaaqXpzRXo33zmhfxt/Men/cL8l/JLlJRnuT/TSjvR7v1N1fmVLJwApk9UVYxuY0ZC/PaA+ya1fVSRn9IXF0d79mnJ69YnRZPb+7f75pKI6GDFipqmqvjN4339jdn9t0fNb74w+THFxV90qyd5Lzkxxn/0ZgqWnKYJmaM/Tm7UluldGGpm/PaL+x5yf5k6p6Tne/qqpmMkrLLlNVT+3us6dVO8AysWtGc27fnfzug65ZSVn1yFHTLRNY6cwpg2Wkqnatqv8z59gtk9wuyWOTPLW7X5rk5hkt53zfJA8e/6Hxmow2PL13kvlWGwPYYc2Ze1vjb89Lck5GwxMzbsjWzFrU43FV9TdLWijAPDRlsEyMl21+Y5J3V9WNZ/3RsDbJXklOGn+yu0t3r0/yiCQ/SvLwJJX8dvGPa3X3WUv/GwBMz6b9GKvqpUnuWlU7j5ey/5ckD6iqI8bXbRhft2dGH3Ddqap2m1LZAEk0ZbBsjIcqfiqjOQ0vraqbjE/9T0bJ18Hj69aPG7OLkjw1yY2S3HzTJ8Pdfc6SFw+wDIybqzsleW2SPxsf/mCS12f0vvrSqrpFVd0tyasz2lbk2d19wVQKBv5/e/caa3dVp3H8+5RLp4MKA6Kigox4gUIcZWDEqgQIYUQzko4aZ+oMChit4TLWmJqJpiLeQE1IiIqXggbl4hAQcWZsO2gIRUZFG2igM0awQkAx2oLcilD4+WKtDTsnrRygnP9pz/fzap/1v629X+ycZ6+1fkud1RelaaBPpxn9evuvtKmK9wIfBFYBy2g/oiypqmvGrnsLcDYwr6os3yxpRhnb8Jkks/pejbsAl9L2H3tnVV2RZC/aWtwP0WYW3Av8th+3yqKkwRnKpAFtrlx9kncCJ9P+cTge2A24mLZh9NKq+k6SfWhryF4NHFFV7kUmacYYD2RjbdtX1cYezC4DXgYcW1VX9ON79rZ1wG2jLUQkaWiGMmkgSXYCvk37tfZrwM1VdcvY8XcB76ctUn8HsDdwBm3B+nraNMddgKOq6rqp7LskTRdJPgPMrqp/63+PB7PLad+dJwArq+qB4XoqSZtnKJMGkuTjtDVhAKtpBT3OA1ZV1bf6OccApwF30kbM/gC8hlaN8SZgeVXdPMVdl6Rpoe9D9kXgYOD8qlrS20fBbH/gf4DbgVOBZe7dKGk6MpRJA0nyQuCjwD8AK4CrgcW0DUxvBq4APg+8GTiGtg7ilKpavalpO5K0rdvMlMW9aFO5/x64oKo+MnZsDu379bXAz4G/rar7p7DLkjQpVl+UBlJVt9FC2Qpa8Lqpql4CHEYbOTuKtobszcBewD7AeUn2N5BJmmn6Gtwa+3tWL+5xK/AZ2ojYgiSfHLvs2cBaYC5wpIFM0nS1/dAdkGayqvp1kg8Bs4HLkry3qi4E/qX/wjsfOAjYjza9cRda8Q9JmjHGiyIlWUKrrLgH8N0kF1TV2iSfBjYCxyZ5MfDfwBtp36Hr3b9R0nTm9EVpGkjyPOBM4GjgxKo6f8Lx3YAjgR9X1a+mvoeSNIwJZe8vAuYBFwG70r4XVwEnV9XtvbriPwEn0X7sWgcssOy9pOnOUCZNExOC2cKquqi371BVDw3aOUkaWJJPAG+jlbj/cZJFwOeA24A1wAl99sEOwBzghcAdVbV+sE5L0iS5pkyaJqrqDmAR8D3gS0ne3tsNZJJmjCQ7JTkuye5jbc+njYyd0QPZYuCztO1CzgYOBc5O8ryqeqiq7q6qNQYySVsLQ5k0jYwFs/8ELkzyloG7JElT7STgHOC4PnUb4A7gB7Q1ZK+n7eF4YlVdVFWnAz8FDgcu7bMOJGmrYqEPaZqpqjv6r8APADcM3R9JmkpVdUaSPYBPA7OSnFNVv0tySVVVkgXAXbRtQ0bWA/8PbAB2nPpeS9JTYyiTpqG+LmJhVW0cui+S9HRLMptWwOMQ4AtV9f4kAT7Zjy+tqt/30/ekVaJd34/tAjwMfAq4sqrumur+S9JTZaEPSZI0mCTPBP4DeD7wYuD4qrq4HzsLOBH4MDAaMXsRcC1tH8drgH1pUxcP7HuWSdJWx5EySZI0iB7IfkaroLiENiVxw6gMflWdkmQ0CkaSc6vqliTzgS8D/0ybyniEgUzS1sxQJkmSplySHWn7jd0GHAfc2teMPboNSJK9q2pRkod4LJh9tap+mORVwM7AH6vqnoHehiRtEYYySZI0hP2BFwCn8VggmzUWyBYDJyX5QFUtbkvM+BTwSJJvVNVvgN9v7uaStDUxlEmSpCEcSFtDdk31Be5V9Qg8ulH0Ylop/C8k2diD2cPA6cCDSc4anS9JWztDmSRJGsKOtK0/7gMYrSNL8grgDcBbq+ryJFcC5/RRtH9Psh2w3EAmaVti9UVJkjTlkhwMLAdOraqzxtrnAM8Bbh9tC5LkbuD8qnrfIJ2VpKfZrKE7IEmSZqRfAjcBx/aABkBVbaiqW6pqY5LtkuwH/Ai4CtqI2jDdlaSnj6FMkiRNuapaBywE5gKnJjlwE6c9C/gAbeRsZb/OKT6StjlOX5QkSYNJcjRwCXA9sBT4Ou1H40OAdwPzgddV1eqh+ihJTzdDmSRJGlSfvngusAdwP/AIcA/wIHCcgUzSts5QJkmSBpfkucABwDzaSNk1wOqq+u2gHZOkKWAokyRJkqQBWehDkiRNC+OVFa2yKGkmcaRMkiRJkgbkSJkkSZIkDchQJkmSJEkDMpRJkiRJ0oAMZZIkSZI0IEOZJEmSJA3IUCZJesqSPJzkuiQ3JLk4yV8+hXt9Pclb++ulSeb+mXMPSzLvSTzjV0mePdn2Cefc+wSfdWqSDz7RPkqSZg5DmSRpS9hQVa+sqgOAB4GF4weTbP9kblpV766qNX/mlMOAJxzKJEmaTgxlkqQtbSXwkj6KtTLJ5cCaJNsl+WySa5OsTvJeaJsEJ/l8kp8nuQJ4zuhGSa5MclB//YYkq5Jcn+T7Sfamhb9FfZTu9Ul2T3JJf8a1SV7br90tyYokNyZZCjzuxsRJLkvys37NeyYcO7O3fz/J7r1tnyTL+jUrk+y7JT5MSdK270n9cilJ0qb0EbGjgWW96UDggKpa24PNH6rq4CSzgR8mWQG8Cng5MBd4LrAGOHfCfXcHvgoc2u+1a1WtT/Il4N6q+lw/7wLgzKq6OslewHJgP+CjwNVVdVqSNwEnTOLtHN+fMQe4NsklVbUO2An4aVUtSrKk3/sk4CvAwqr6RZJXA18EjngSH6MkaYYxlEmStoQ5Sa7rr1cC59CmFf6kqtb29qOAV4zWiwE7Ay8FDgUurKqHgV8n+cEm7n8IcNXoXlW1fjP9OBKYmzw6EPasJM/oz/jHfu1/JblzEu/plCTz++s9e1/XAY8A3+rt3wQu7c+YB1w89uzZk3iGJEmGMknSFrGhql453tDDyX3jTcDJVbV8wnlv3IL9mAUcUlUPbKIvk5bkMFrAe01V3Z/kSuAvNnN69efeNfEzkCRpMlxTJkmaKsuB9yXZASDJy5LsBFwFvL2vOdsDOHwT1/4IODTJX/drd+3t9wDPHDtvBXDy6I8ko5B0FbCgtx0N/NXj9HVn4M4eyPaljdSNzAJGo30LaNMi7wbWJnlbf0aS/M3jPEOSJMBQJkmaOktp68VWJbkB+DJtxsa3gV/0Y+cB/zvxwqr6HfAe2lTB63ls+uB3gfmjQh/AKcBBvZDIGh6rAvkxWqi7kTaN8dbH6esyYPsk/wecTguFI/cBf9ffwxHAab39HcAJvX83AsdM4jORJIlU1dB9kCRJkqQZy5EySZIkSRqQoUySJEmSBmQokyRJkqQBGcokSZIkaUCGMkmSJEkakKFMkiRJkgZkKJMkSZKkARnKJEmSJGlAfwKGLJpCmkcGCAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 1080x720 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EyL4HDhTKDa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "outputId": "2bb7bb9b-3d5d-4116-a5d4-db7d96e7430c"
      },
      "source": [
        "confusion_matrix = np.zeros((nb_classes, nb_classes))\n",
        "with torch.no_grad():\n",
        "    for i, (inputs, classes) in enumerate(dataloaders['train']):\n",
        "        inputs = inputs.to(device)\n",
        "        classes = classes.to(device)\n",
        "        outputs = model_ft(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        for t, p in zip(classes.view(-1), preds.view(-1)):\n",
        "                confusion_matrix[t.long(), p.long()] += 1\n",
        "\n",
        "plt.figure(figsize=(15,10))\n",
        "\n",
        "class_names = ['Normal', 'Glaucoma']\n",
        "df_cm = pd.DataFrame(confusion_matrix, index=class_names, columns=class_names).astype(int)\n",
        "heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
        "\n",
        "heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right',fontsize=15)\n",
        "heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right',fontsize=15)\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 69.0, 'Predicted label')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x720 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pryRZOM_O64w"
      },
      "source": [
        ""
      ],
      "execution_count": 85,
      "outputs": []
    }
  ]
}