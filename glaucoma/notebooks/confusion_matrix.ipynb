{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "decent_model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9f30202a78504485af62354bb95a55e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0d3fdd3bc4f9441ba2d16dc760c215d5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7ce2a783fd864920ad481a1fda86d538",
              "IPY_MODEL_512c992311dc456a9718e139b3b27716"
            ]
          }
        },
        "0d3fdd3bc4f9441ba2d16dc760c215d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7ce2a783fd864920ad481a1fda86d538": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e9c8ec6548234b6292923052a6212e47",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 108857766,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 108857766,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_94d957e83b504511ba9611d19a1414a1"
          }
        },
        "512c992311dc456a9718e139b3b27716": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_371500e0b92b415d97fefa9755cafb7e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 104M/104M [00:30&lt;00:00, 3.54MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_75e5d7a38dcf46658cd68997b6bd63cd"
          }
        },
        "e9c8ec6548234b6292923052a6212e47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "94d957e83b504511ba9611d19a1414a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "371500e0b92b415d97fefa9755cafb7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "75e5d7a38dcf46658cd68997b6bd63cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqHnaptr-kuA",
        "outputId": "e50272c3-5eb3-4dfb-9d84-2051bec8aaf7"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon May  3 08:32:47 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mI9F5EeeXOzF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uP5kBx8eXPjE",
        "outputId": "1c01001e-968b-4bdf-b7be-cd32fc3ed0b3"
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oGJ2hstm39V"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import copy\n",
        "import time\n",
        "\n",
        "import torch\n",
        "from torchvision import datasets, models, transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader, Dataset, TensorDataset, Subset, WeightedRandomSampler\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import pickle"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMzw_DRLY1VG"
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u899MaWr-ZF0"
      },
      "source": [
        "# Top level data directory. Here we assume the format of the directory conforms\n",
        "#   to the ImageFolder structure\n",
        "data_dir = '/content/drive/MyDrive/ocular'\n",
        "\n",
        "# Models to choose from [resnet, alexnet, vgg, squeezenet, densenet, inception]\n",
        "model_name = \"inception\"\n",
        "# inception\n",
        "input_size = 299\n",
        "\n",
        "# Number of classes in the dataset\n",
        "num_classes = 2\n",
        "\n",
        "# Batch size for training (change depending on how much memory you have)\n",
        "batch_size = 16\n",
        "\n",
        "# Number of epochs to train for\n",
        "num_epochs = 10\n",
        "\n",
        "# Flag for feature extracting. When False, we finetune the whole model,\n",
        "#   when True we only update the reshaped layer params\n",
        "feature_extract = False\n",
        "\n",
        "num_workers = 2\n",
        "\n",
        "train_size = 0.70\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jj74frLDrZd"
      },
      "source": [
        "# Todos: shuffle in validation set\n",
        "# add more augmentations  \n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "        transforms.RandomRotation(degrees=(0, 360)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.Resize((input_size, input_size)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "\n",
        "\n",
        "valid_transform = transforms.Compose([\n",
        "        transforms.Resize((input_size, input_size)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "\n",
        "\n",
        "class DR(Dataset):\n",
        "    def __init__(self, dataset, transform=None):\n",
        "        self.dataset = dataset\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        if self.transform:\n",
        "            x = self.transform(dataset[index][0])\n",
        "        else:\n",
        "            x = dataset[index][0]\n",
        "        y = dataset[index][1]\n",
        "        return x, y\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(dataset)\n",
        "    \n",
        "\n",
        "dataset = ImageFolder(data_dir)\n",
        "\n",
        "traindataset = DR(dataset, train_transform)\n",
        "valdataset = DR(dataset, valid_transform)\n",
        "testdataset = DR(dataset, valid_transform)\n",
        "\n",
        "# Create the index splits for training, validation and test\n",
        "\n",
        "num_train = len(dataset)\n",
        "indices = list(range(num_train))\n",
        "split = int(np.floor(train_size * num_train))\n",
        "split2 = int(np.floor((train_size+(1-train_size)/2) * num_train))\n",
        "np.random.shuffle(indices)\n",
        "train_idx, valid_idx, test_idx = indices[:split], indices[split:split2], indices[split2:]\n",
        "\n",
        "traindata = Subset(traindataset, indices=train_idx)\n",
        "valdata = Subset(valdataset, indices=valid_idx)\n",
        "testdata = Subset(testdataset, indices=test_idx)\n",
        "\n",
        "# class_weights = []\n",
        "# for root, subdir, files in os.walk(data_dir):\n",
        "#   if len(files)>0:\n",
        "#     class_weights.append(1/len(files))\n",
        "\n",
        "# sample_weights = [0] * len(traindata)\n",
        "\n",
        "# for idx, (data, label) in enumerate(traindata):\n",
        "#   class_weight = class_weights[label]\n",
        "#   sample_weights[idx] = class_weight\n",
        "\n",
        "\n",
        "# with open('/content/drive/MyDrive/new_weights.pkl', 'wb') as f:\n",
        "#   pickle.dump(sample_weights, f)\n",
        "\n",
        "with open('/content/drive/MyDrive/new_weights.pkl', 'rb') as f:\n",
        "  sample_weights = pickle.load(f)\n",
        "\n",
        "sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)\n",
        "\n",
        "trainLoader = torch.utils.data.DataLoader(traindata, batch_size=batch_size, \n",
        "                                          num_workers=num_workers, drop_last=True)\n",
        "valLoader = torch.utils.data.DataLoader(valdata, batch_size=batch_size, \n",
        "                                          num_workers=num_workers, drop_last=True)\n",
        "testLoader = torch.utils.data.DataLoader(testdata, batch_size=batch_size,\n",
        "                                          num_workers=num_workers, drop_last=True)\n",
        "dataloaders = {'train': trainLoader, 'val': valLoader, 'test': testLoader}"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyThMaR4nbLF"
      },
      "source": [
        "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False):\n",
        "    since = time.time()\n",
        "\n",
        "    val_acc_history = []\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    # Get model outputs and calculate loss\n",
        "                    # Special case for inception because in training it has an auxiliary output. In train\n",
        "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
        "                    #   but in testing we only consider the final output.\n",
        "                    if is_inception and phase == 'train':\n",
        "                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
        "                        outputs, aux_outputs = model(inputs)\n",
        "                        loss1 = criterion(outputs, labels)\n",
        "                        loss2 = criterion(aux_outputs, labels)\n",
        "                        loss = loss1 + 0.4*loss2\n",
        "                    else:\n",
        "                        outputs = model(inputs)\n",
        "                        loss = criterion(outputs, labels)\n",
        "\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
        "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            if phase == 'val':\n",
        "                val_acc_history.append(epoch_acc)\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, val_acc_history"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75VdlQ8ln1a9"
      },
      "source": [
        "def set_parameter_requires_grad(model, feature_extracting):\n",
        "    if feature_extracting:\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "9f30202a78504485af62354bb95a55e3",
            "0d3fdd3bc4f9441ba2d16dc760c215d5",
            "7ce2a783fd864920ad481a1fda86d538",
            "512c992311dc456a9718e139b3b27716",
            "e9c8ec6548234b6292923052a6212e47",
            "94d957e83b504511ba9611d19a1414a1",
            "371500e0b92b415d97fefa9755cafb7e",
            "75e5d7a38dcf46658cd68997b6bd63cd"
          ]
        },
        "id": "Y4O8Uqptn8Sb",
        "outputId": "e4e58917-0fb9-4d5e-cdf7-7aaea217eebf"
      },
      "source": [
        "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
        "    # Initialize these variables which will be set in this if statement. Each of these\n",
        "    #   variables is model specific.\n",
        "    model_ft = None\n",
        "    input_size = 0\n",
        "\n",
        "    if model_name == \"resnet\":\n",
        "        \"\"\" Resnet18\n",
        "        \"\"\"\n",
        "        model_ft = models.resnet18(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.fc.in_features\n",
        "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"alexnet\":\n",
        "        \"\"\" Alexnet\n",
        "        \"\"\"\n",
        "        model_ft = models.alexnet(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.classifier[6].in_features\n",
        "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"vgg\":\n",
        "        \"\"\" VGG11_bn\n",
        "        \"\"\"\n",
        "        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.classifier[6].in_features\n",
        "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"squeezenet\":\n",
        "        \"\"\" Squeezenet\n",
        "        \"\"\"\n",
        "        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
        "        model_ft.num_classes = num_classes\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"densenet\":\n",
        "        \"\"\" Densenet\n",
        "        \"\"\"\n",
        "        model_ft = models.densenet121(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.classifier.in_features\n",
        "        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"inception\":\n",
        "        \"\"\" Inception v3\n",
        "        Be careful, expects (299,299) sized images and has auxiliary output\n",
        "        \"\"\"\n",
        "        model_ft = models.inception_v3(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        # Handle the auxilary net\n",
        "        num_ftrs = model_ft.AuxLogits.fc.in_features\n",
        "        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n",
        "        # Handle the primary net\n",
        "        num_ftrs = model_ft.fc.in_features\n",
        "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
        "        input_size = 299\n",
        "\n",
        "    else:\n",
        "        print(\"Invalid model name, exiting...\")\n",
        "        exit()\n",
        "\n",
        "    return model_ft, input_size\n",
        "\n",
        "# Initialize the model for this run\n",
        "model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n",
        "\n",
        "# Print the model we just instantiated\n",
        "print(model_ft)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/inception_v3_google-1a9a5a14.pth\" to /root/.cache/torch/hub/checkpoints/inception_v3_google-1a9a5a14.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9f30202a78504485af62354bb95a55e3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=108857766.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Inception3(\n",
            "  (Conv2d_1a_3x3): BasicConv2d(\n",
            "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
            "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (Conv2d_2a_3x3): BasicConv2d(\n",
            "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (Conv2d_2b_3x3): BasicConv2d(\n",
            "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (Conv2d_3b_1x1): BasicConv2d(\n",
            "    (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (Conv2d_4a_3x3): BasicConv2d(\n",
            "    (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (Mixed_5b): InceptionA(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_1): BasicConv2d(\n",
            "      (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_2): BasicConv2d(\n",
            "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_5c): InceptionA(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_1): BasicConv2d(\n",
            "      (conv): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_2): BasicConv2d(\n",
            "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_5d): InceptionA(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_1): BasicConv2d(\n",
            "      (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_2): BasicConv2d(\n",
            "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_6a): InceptionB(\n",
            "    (branch3x3): BasicConv2d(\n",
            "      (conv): Conv2d(288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_6b): InceptionC(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_2): BasicConv2d(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_3): BasicConv2d(\n",
            "      (conv): Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_4): BasicConv2d(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_5): BasicConv2d(\n",
            "      (conv): Conv2d(128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_6c): InceptionC(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_2): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_3): BasicConv2d(\n",
            "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_4): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_5): BasicConv2d(\n",
            "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_6d): InceptionC(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_2): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_3): BasicConv2d(\n",
            "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_4): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_5): BasicConv2d(\n",
            "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_6e): InceptionC(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_2): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_3): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_4): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_5): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (AuxLogits): InceptionAux(\n",
            "    (conv0): BasicConv2d(\n",
            "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (conv1): BasicConv2d(\n",
            "      (conv): Conv2d(128, 768, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fc): Linear(in_features=768, out_features=2, bias=True)\n",
            "  )\n",
            "  (Mixed_7a): InceptionD(\n",
            "    (branch3x3_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_2): BasicConv2d(\n",
            "      (conv): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7x3_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7x3_2): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7x3_3): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7x3_4): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_7b): InceptionE(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_1): BasicConv2d(\n",
            "      (conv): Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_2a): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_2b): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3a): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3b): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_7c): InceptionE(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_1): BasicConv2d(\n",
            "      (conv): Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_2a): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_2b): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3a): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3b): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (fc): Linear(in_features=2048, out_features=2, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6151ULNdzuq",
        "outputId": "b49f8542-8982-4be2-8f34-9a2516a079fe"
      },
      "source": [
        "# Send the model to GPU\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "# Gather the parameters to be optimized/updated in this run. If we are\n",
        "#  finetuning we will be updating all parameters. However, if we are\n",
        "#  doing feature extract method, we will only update the parameters\n",
        "#  that we have just initialized, i.e. the parameters with requires_grad\n",
        "#  is True.\n",
        "params_to_update = model_ft.parameters()\n",
        "print(\"Params to learn:\")\n",
        "if feature_extract:\n",
        "    params_to_update = []\n",
        "    for name,param in model_ft.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            params_to_update.append(param)\n",
        "            print(\"\\t\",name)\n",
        "else:\n",
        "    for name,param in model_ft.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            print(\"\\t\",name)\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Params to learn:\n",
            "\t Conv2d_1a_3x3.conv.weight\n",
            "\t Conv2d_1a_3x3.bn.weight\n",
            "\t Conv2d_1a_3x3.bn.bias\n",
            "\t Conv2d_2a_3x3.conv.weight\n",
            "\t Conv2d_2a_3x3.bn.weight\n",
            "\t Conv2d_2a_3x3.bn.bias\n",
            "\t Conv2d_2b_3x3.conv.weight\n",
            "\t Conv2d_2b_3x3.bn.weight\n",
            "\t Conv2d_2b_3x3.bn.bias\n",
            "\t Conv2d_3b_1x1.conv.weight\n",
            "\t Conv2d_3b_1x1.bn.weight\n",
            "\t Conv2d_3b_1x1.bn.bias\n",
            "\t Conv2d_4a_3x3.conv.weight\n",
            "\t Conv2d_4a_3x3.bn.weight\n",
            "\t Conv2d_4a_3x3.bn.bias\n",
            "\t Mixed_5b.branch1x1.conv.weight\n",
            "\t Mixed_5b.branch1x1.bn.weight\n",
            "\t Mixed_5b.branch1x1.bn.bias\n",
            "\t Mixed_5b.branch5x5_1.conv.weight\n",
            "\t Mixed_5b.branch5x5_1.bn.weight\n",
            "\t Mixed_5b.branch5x5_1.bn.bias\n",
            "\t Mixed_5b.branch5x5_2.conv.weight\n",
            "\t Mixed_5b.branch5x5_2.bn.weight\n",
            "\t Mixed_5b.branch5x5_2.bn.bias\n",
            "\t Mixed_5b.branch3x3dbl_1.conv.weight\n",
            "\t Mixed_5b.branch3x3dbl_1.bn.weight\n",
            "\t Mixed_5b.branch3x3dbl_1.bn.bias\n",
            "\t Mixed_5b.branch3x3dbl_2.conv.weight\n",
            "\t Mixed_5b.branch3x3dbl_2.bn.weight\n",
            "\t Mixed_5b.branch3x3dbl_2.bn.bias\n",
            "\t Mixed_5b.branch3x3dbl_3.conv.weight\n",
            "\t Mixed_5b.branch3x3dbl_3.bn.weight\n",
            "\t Mixed_5b.branch3x3dbl_3.bn.bias\n",
            "\t Mixed_5b.branch_pool.conv.weight\n",
            "\t Mixed_5b.branch_pool.bn.weight\n",
            "\t Mixed_5b.branch_pool.bn.bias\n",
            "\t Mixed_5c.branch1x1.conv.weight\n",
            "\t Mixed_5c.branch1x1.bn.weight\n",
            "\t Mixed_5c.branch1x1.bn.bias\n",
            "\t Mixed_5c.branch5x5_1.conv.weight\n",
            "\t Mixed_5c.branch5x5_1.bn.weight\n",
            "\t Mixed_5c.branch5x5_1.bn.bias\n",
            "\t Mixed_5c.branch5x5_2.conv.weight\n",
            "\t Mixed_5c.branch5x5_2.bn.weight\n",
            "\t Mixed_5c.branch5x5_2.bn.bias\n",
            "\t Mixed_5c.branch3x3dbl_1.conv.weight\n",
            "\t Mixed_5c.branch3x3dbl_1.bn.weight\n",
            "\t Mixed_5c.branch3x3dbl_1.bn.bias\n",
            "\t Mixed_5c.branch3x3dbl_2.conv.weight\n",
            "\t Mixed_5c.branch3x3dbl_2.bn.weight\n",
            "\t Mixed_5c.branch3x3dbl_2.bn.bias\n",
            "\t Mixed_5c.branch3x3dbl_3.conv.weight\n",
            "\t Mixed_5c.branch3x3dbl_3.bn.weight\n",
            "\t Mixed_5c.branch3x3dbl_3.bn.bias\n",
            "\t Mixed_5c.branch_pool.conv.weight\n",
            "\t Mixed_5c.branch_pool.bn.weight\n",
            "\t Mixed_5c.branch_pool.bn.bias\n",
            "\t Mixed_5d.branch1x1.conv.weight\n",
            "\t Mixed_5d.branch1x1.bn.weight\n",
            "\t Mixed_5d.branch1x1.bn.bias\n",
            "\t Mixed_5d.branch5x5_1.conv.weight\n",
            "\t Mixed_5d.branch5x5_1.bn.weight\n",
            "\t Mixed_5d.branch5x5_1.bn.bias\n",
            "\t Mixed_5d.branch5x5_2.conv.weight\n",
            "\t Mixed_5d.branch5x5_2.bn.weight\n",
            "\t Mixed_5d.branch5x5_2.bn.bias\n",
            "\t Mixed_5d.branch3x3dbl_1.conv.weight\n",
            "\t Mixed_5d.branch3x3dbl_1.bn.weight\n",
            "\t Mixed_5d.branch3x3dbl_1.bn.bias\n",
            "\t Mixed_5d.branch3x3dbl_2.conv.weight\n",
            "\t Mixed_5d.branch3x3dbl_2.bn.weight\n",
            "\t Mixed_5d.branch3x3dbl_2.bn.bias\n",
            "\t Mixed_5d.branch3x3dbl_3.conv.weight\n",
            "\t Mixed_5d.branch3x3dbl_3.bn.weight\n",
            "\t Mixed_5d.branch3x3dbl_3.bn.bias\n",
            "\t Mixed_5d.branch_pool.conv.weight\n",
            "\t Mixed_5d.branch_pool.bn.weight\n",
            "\t Mixed_5d.branch_pool.bn.bias\n",
            "\t Mixed_6a.branch3x3.conv.weight\n",
            "\t Mixed_6a.branch3x3.bn.weight\n",
            "\t Mixed_6a.branch3x3.bn.bias\n",
            "\t Mixed_6a.branch3x3dbl_1.conv.weight\n",
            "\t Mixed_6a.branch3x3dbl_1.bn.weight\n",
            "\t Mixed_6a.branch3x3dbl_1.bn.bias\n",
            "\t Mixed_6a.branch3x3dbl_2.conv.weight\n",
            "\t Mixed_6a.branch3x3dbl_2.bn.weight\n",
            "\t Mixed_6a.branch3x3dbl_2.bn.bias\n",
            "\t Mixed_6a.branch3x3dbl_3.conv.weight\n",
            "\t Mixed_6a.branch3x3dbl_3.bn.weight\n",
            "\t Mixed_6a.branch3x3dbl_3.bn.bias\n",
            "\t Mixed_6b.branch1x1.conv.weight\n",
            "\t Mixed_6b.branch1x1.bn.weight\n",
            "\t Mixed_6b.branch1x1.bn.bias\n",
            "\t Mixed_6b.branch7x7_1.conv.weight\n",
            "\t Mixed_6b.branch7x7_1.bn.weight\n",
            "\t Mixed_6b.branch7x7_1.bn.bias\n",
            "\t Mixed_6b.branch7x7_2.conv.weight\n",
            "\t Mixed_6b.branch7x7_2.bn.weight\n",
            "\t Mixed_6b.branch7x7_2.bn.bias\n",
            "\t Mixed_6b.branch7x7_3.conv.weight\n",
            "\t Mixed_6b.branch7x7_3.bn.weight\n",
            "\t Mixed_6b.branch7x7_3.bn.bias\n",
            "\t Mixed_6b.branch7x7dbl_1.conv.weight\n",
            "\t Mixed_6b.branch7x7dbl_1.bn.weight\n",
            "\t Mixed_6b.branch7x7dbl_1.bn.bias\n",
            "\t Mixed_6b.branch7x7dbl_2.conv.weight\n",
            "\t Mixed_6b.branch7x7dbl_2.bn.weight\n",
            "\t Mixed_6b.branch7x7dbl_2.bn.bias\n",
            "\t Mixed_6b.branch7x7dbl_3.conv.weight\n",
            "\t Mixed_6b.branch7x7dbl_3.bn.weight\n",
            "\t Mixed_6b.branch7x7dbl_3.bn.bias\n",
            "\t Mixed_6b.branch7x7dbl_4.conv.weight\n",
            "\t Mixed_6b.branch7x7dbl_4.bn.weight\n",
            "\t Mixed_6b.branch7x7dbl_4.bn.bias\n",
            "\t Mixed_6b.branch7x7dbl_5.conv.weight\n",
            "\t Mixed_6b.branch7x7dbl_5.bn.weight\n",
            "\t Mixed_6b.branch7x7dbl_5.bn.bias\n",
            "\t Mixed_6b.branch_pool.conv.weight\n",
            "\t Mixed_6b.branch_pool.bn.weight\n",
            "\t Mixed_6b.branch_pool.bn.bias\n",
            "\t Mixed_6c.branch1x1.conv.weight\n",
            "\t Mixed_6c.branch1x1.bn.weight\n",
            "\t Mixed_6c.branch1x1.bn.bias\n",
            "\t Mixed_6c.branch7x7_1.conv.weight\n",
            "\t Mixed_6c.branch7x7_1.bn.weight\n",
            "\t Mixed_6c.branch7x7_1.bn.bias\n",
            "\t Mixed_6c.branch7x7_2.conv.weight\n",
            "\t Mixed_6c.branch7x7_2.bn.weight\n",
            "\t Mixed_6c.branch7x7_2.bn.bias\n",
            "\t Mixed_6c.branch7x7_3.conv.weight\n",
            "\t Mixed_6c.branch7x7_3.bn.weight\n",
            "\t Mixed_6c.branch7x7_3.bn.bias\n",
            "\t Mixed_6c.branch7x7dbl_1.conv.weight\n",
            "\t Mixed_6c.branch7x7dbl_1.bn.weight\n",
            "\t Mixed_6c.branch7x7dbl_1.bn.bias\n",
            "\t Mixed_6c.branch7x7dbl_2.conv.weight\n",
            "\t Mixed_6c.branch7x7dbl_2.bn.weight\n",
            "\t Mixed_6c.branch7x7dbl_2.bn.bias\n",
            "\t Mixed_6c.branch7x7dbl_3.conv.weight\n",
            "\t Mixed_6c.branch7x7dbl_3.bn.weight\n",
            "\t Mixed_6c.branch7x7dbl_3.bn.bias\n",
            "\t Mixed_6c.branch7x7dbl_4.conv.weight\n",
            "\t Mixed_6c.branch7x7dbl_4.bn.weight\n",
            "\t Mixed_6c.branch7x7dbl_4.bn.bias\n",
            "\t Mixed_6c.branch7x7dbl_5.conv.weight\n",
            "\t Mixed_6c.branch7x7dbl_5.bn.weight\n",
            "\t Mixed_6c.branch7x7dbl_5.bn.bias\n",
            "\t Mixed_6c.branch_pool.conv.weight\n",
            "\t Mixed_6c.branch_pool.bn.weight\n",
            "\t Mixed_6c.branch_pool.bn.bias\n",
            "\t Mixed_6d.branch1x1.conv.weight\n",
            "\t Mixed_6d.branch1x1.bn.weight\n",
            "\t Mixed_6d.branch1x1.bn.bias\n",
            "\t Mixed_6d.branch7x7_1.conv.weight\n",
            "\t Mixed_6d.branch7x7_1.bn.weight\n",
            "\t Mixed_6d.branch7x7_1.bn.bias\n",
            "\t Mixed_6d.branch7x7_2.conv.weight\n",
            "\t Mixed_6d.branch7x7_2.bn.weight\n",
            "\t Mixed_6d.branch7x7_2.bn.bias\n",
            "\t Mixed_6d.branch7x7_3.conv.weight\n",
            "\t Mixed_6d.branch7x7_3.bn.weight\n",
            "\t Mixed_6d.branch7x7_3.bn.bias\n",
            "\t Mixed_6d.branch7x7dbl_1.conv.weight\n",
            "\t Mixed_6d.branch7x7dbl_1.bn.weight\n",
            "\t Mixed_6d.branch7x7dbl_1.bn.bias\n",
            "\t Mixed_6d.branch7x7dbl_2.conv.weight\n",
            "\t Mixed_6d.branch7x7dbl_2.bn.weight\n",
            "\t Mixed_6d.branch7x7dbl_2.bn.bias\n",
            "\t Mixed_6d.branch7x7dbl_3.conv.weight\n",
            "\t Mixed_6d.branch7x7dbl_3.bn.weight\n",
            "\t Mixed_6d.branch7x7dbl_3.bn.bias\n",
            "\t Mixed_6d.branch7x7dbl_4.conv.weight\n",
            "\t Mixed_6d.branch7x7dbl_4.bn.weight\n",
            "\t Mixed_6d.branch7x7dbl_4.bn.bias\n",
            "\t Mixed_6d.branch7x7dbl_5.conv.weight\n",
            "\t Mixed_6d.branch7x7dbl_5.bn.weight\n",
            "\t Mixed_6d.branch7x7dbl_5.bn.bias\n",
            "\t Mixed_6d.branch_pool.conv.weight\n",
            "\t Mixed_6d.branch_pool.bn.weight\n",
            "\t Mixed_6d.branch_pool.bn.bias\n",
            "\t Mixed_6e.branch1x1.conv.weight\n",
            "\t Mixed_6e.branch1x1.bn.weight\n",
            "\t Mixed_6e.branch1x1.bn.bias\n",
            "\t Mixed_6e.branch7x7_1.conv.weight\n",
            "\t Mixed_6e.branch7x7_1.bn.weight\n",
            "\t Mixed_6e.branch7x7_1.bn.bias\n",
            "\t Mixed_6e.branch7x7_2.conv.weight\n",
            "\t Mixed_6e.branch7x7_2.bn.weight\n",
            "\t Mixed_6e.branch7x7_2.bn.bias\n",
            "\t Mixed_6e.branch7x7_3.conv.weight\n",
            "\t Mixed_6e.branch7x7_3.bn.weight\n",
            "\t Mixed_6e.branch7x7_3.bn.bias\n",
            "\t Mixed_6e.branch7x7dbl_1.conv.weight\n",
            "\t Mixed_6e.branch7x7dbl_1.bn.weight\n",
            "\t Mixed_6e.branch7x7dbl_1.bn.bias\n",
            "\t Mixed_6e.branch7x7dbl_2.conv.weight\n",
            "\t Mixed_6e.branch7x7dbl_2.bn.weight\n",
            "\t Mixed_6e.branch7x7dbl_2.bn.bias\n",
            "\t Mixed_6e.branch7x7dbl_3.conv.weight\n",
            "\t Mixed_6e.branch7x7dbl_3.bn.weight\n",
            "\t Mixed_6e.branch7x7dbl_3.bn.bias\n",
            "\t Mixed_6e.branch7x7dbl_4.conv.weight\n",
            "\t Mixed_6e.branch7x7dbl_4.bn.weight\n",
            "\t Mixed_6e.branch7x7dbl_4.bn.bias\n",
            "\t Mixed_6e.branch7x7dbl_5.conv.weight\n",
            "\t Mixed_6e.branch7x7dbl_5.bn.weight\n",
            "\t Mixed_6e.branch7x7dbl_5.bn.bias\n",
            "\t Mixed_6e.branch_pool.conv.weight\n",
            "\t Mixed_6e.branch_pool.bn.weight\n",
            "\t Mixed_6e.branch_pool.bn.bias\n",
            "\t AuxLogits.conv0.conv.weight\n",
            "\t AuxLogits.conv0.bn.weight\n",
            "\t AuxLogits.conv0.bn.bias\n",
            "\t AuxLogits.conv1.conv.weight\n",
            "\t AuxLogits.conv1.bn.weight\n",
            "\t AuxLogits.conv1.bn.bias\n",
            "\t AuxLogits.fc.weight\n",
            "\t AuxLogits.fc.bias\n",
            "\t Mixed_7a.branch3x3_1.conv.weight\n",
            "\t Mixed_7a.branch3x3_1.bn.weight\n",
            "\t Mixed_7a.branch3x3_1.bn.bias\n",
            "\t Mixed_7a.branch3x3_2.conv.weight\n",
            "\t Mixed_7a.branch3x3_2.bn.weight\n",
            "\t Mixed_7a.branch3x3_2.bn.bias\n",
            "\t Mixed_7a.branch7x7x3_1.conv.weight\n",
            "\t Mixed_7a.branch7x7x3_1.bn.weight\n",
            "\t Mixed_7a.branch7x7x3_1.bn.bias\n",
            "\t Mixed_7a.branch7x7x3_2.conv.weight\n",
            "\t Mixed_7a.branch7x7x3_2.bn.weight\n",
            "\t Mixed_7a.branch7x7x3_2.bn.bias\n",
            "\t Mixed_7a.branch7x7x3_3.conv.weight\n",
            "\t Mixed_7a.branch7x7x3_3.bn.weight\n",
            "\t Mixed_7a.branch7x7x3_3.bn.bias\n",
            "\t Mixed_7a.branch7x7x3_4.conv.weight\n",
            "\t Mixed_7a.branch7x7x3_4.bn.weight\n",
            "\t Mixed_7a.branch7x7x3_4.bn.bias\n",
            "\t Mixed_7b.branch1x1.conv.weight\n",
            "\t Mixed_7b.branch1x1.bn.weight\n",
            "\t Mixed_7b.branch1x1.bn.bias\n",
            "\t Mixed_7b.branch3x3_1.conv.weight\n",
            "\t Mixed_7b.branch3x3_1.bn.weight\n",
            "\t Mixed_7b.branch3x3_1.bn.bias\n",
            "\t Mixed_7b.branch3x3_2a.conv.weight\n",
            "\t Mixed_7b.branch3x3_2a.bn.weight\n",
            "\t Mixed_7b.branch3x3_2a.bn.bias\n",
            "\t Mixed_7b.branch3x3_2b.conv.weight\n",
            "\t Mixed_7b.branch3x3_2b.bn.weight\n",
            "\t Mixed_7b.branch3x3_2b.bn.bias\n",
            "\t Mixed_7b.branch3x3dbl_1.conv.weight\n",
            "\t Mixed_7b.branch3x3dbl_1.bn.weight\n",
            "\t Mixed_7b.branch3x3dbl_1.bn.bias\n",
            "\t Mixed_7b.branch3x3dbl_2.conv.weight\n",
            "\t Mixed_7b.branch3x3dbl_2.bn.weight\n",
            "\t Mixed_7b.branch3x3dbl_2.bn.bias\n",
            "\t Mixed_7b.branch3x3dbl_3a.conv.weight\n",
            "\t Mixed_7b.branch3x3dbl_3a.bn.weight\n",
            "\t Mixed_7b.branch3x3dbl_3a.bn.bias\n",
            "\t Mixed_7b.branch3x3dbl_3b.conv.weight\n",
            "\t Mixed_7b.branch3x3dbl_3b.bn.weight\n",
            "\t Mixed_7b.branch3x3dbl_3b.bn.bias\n",
            "\t Mixed_7b.branch_pool.conv.weight\n",
            "\t Mixed_7b.branch_pool.bn.weight\n",
            "\t Mixed_7b.branch_pool.bn.bias\n",
            "\t Mixed_7c.branch1x1.conv.weight\n",
            "\t Mixed_7c.branch1x1.bn.weight\n",
            "\t Mixed_7c.branch1x1.bn.bias\n",
            "\t Mixed_7c.branch3x3_1.conv.weight\n",
            "\t Mixed_7c.branch3x3_1.bn.weight\n",
            "\t Mixed_7c.branch3x3_1.bn.bias\n",
            "\t Mixed_7c.branch3x3_2a.conv.weight\n",
            "\t Mixed_7c.branch3x3_2a.bn.weight\n",
            "\t Mixed_7c.branch3x3_2a.bn.bias\n",
            "\t Mixed_7c.branch3x3_2b.conv.weight\n",
            "\t Mixed_7c.branch3x3_2b.bn.weight\n",
            "\t Mixed_7c.branch3x3_2b.bn.bias\n",
            "\t Mixed_7c.branch3x3dbl_1.conv.weight\n",
            "\t Mixed_7c.branch3x3dbl_1.bn.weight\n",
            "\t Mixed_7c.branch3x3dbl_1.bn.bias\n",
            "\t Mixed_7c.branch3x3dbl_2.conv.weight\n",
            "\t Mixed_7c.branch3x3dbl_2.bn.weight\n",
            "\t Mixed_7c.branch3x3dbl_2.bn.bias\n",
            "\t Mixed_7c.branch3x3dbl_3a.conv.weight\n",
            "\t Mixed_7c.branch3x3dbl_3a.bn.weight\n",
            "\t Mixed_7c.branch3x3dbl_3a.bn.bias\n",
            "\t Mixed_7c.branch3x3dbl_3b.conv.weight\n",
            "\t Mixed_7c.branch3x3dbl_3b.bn.weight\n",
            "\t Mixed_7c.branch3x3dbl_3b.bn.bias\n",
            "\t Mixed_7c.branch_pool.conv.weight\n",
            "\t Mixed_7c.branch_pool.bn.weight\n",
            "\t Mixed_7c.branch_pool.bn.bias\n",
            "\t fc.weight\n",
            "\t fc.bias\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXg5BAG1oo-f",
        "outputId": "623d836e-81b1-473e-8f11-bbea9d172cb8"
      },
      "source": [
        "# Setup the loss fxn\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Train and evaluate\n",
        "model_ft, hist = train_model(model_ft, dataloaders, criterion, optimizer_ft, num_epochs=num_epochs, is_inception=(model_name==\"inception\"))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/9\n",
            "----------\n",
            "train Loss: 0.4240 Acc: 0.8919\n",
            "val Loss: 0.2876 Acc: 0.8949\n",
            "\n",
            "Epoch 1/9\n",
            "----------\n",
            "train Loss: 0.3210 Acc: 0.9061\n",
            "val Loss: 0.2337 Acc: 0.9066\n",
            "\n",
            "Epoch 2/9\n",
            "----------\n",
            "train Loss: 0.2823 Acc: 0.9207\n",
            "val Loss: 0.2296 Acc: 0.9008\n",
            "\n",
            "Epoch 3/9\n",
            "----------\n",
            "train Loss: 0.2451 Acc: 0.9249\n",
            "val Loss: 0.2438 Acc: 0.9047\n",
            "\n",
            "Epoch 4/9\n",
            "----------\n",
            "train Loss: 0.2309 Acc: 0.9278\n",
            "val Loss: 0.2319 Acc: 0.9144\n",
            "\n",
            "Epoch 5/9\n",
            "----------\n",
            "train Loss: 0.2058 Acc: 0.9353\n",
            "val Loss: 0.2836 Acc: 0.8813\n",
            "\n",
            "Epoch 6/9\n",
            "----------\n",
            "train Loss: 0.2032 Acc: 0.9361\n",
            "val Loss: 0.2373 Acc: 0.9047\n",
            "\n",
            "Epoch 7/9\n",
            "----------\n",
            "train Loss: 0.1748 Acc: 0.9482\n",
            "val Loss: 0.2465 Acc: 0.9047\n",
            "\n",
            "Epoch 8/9\n",
            "----------\n",
            "train Loss: 0.1772 Acc: 0.9428\n",
            "val Loss: 0.2387 Acc: 0.8911\n",
            "\n",
            "Epoch 9/9\n",
            "----------\n",
            "train Loss: 0.1541 Acc: 0.9508\n",
            "val Loss: 0.2946 Acc: 0.8716\n",
            "\n",
            "Training complete in 67m 0s\n",
            "Best val Acc: 0.914397\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgYraiAjiys8"
      },
      "source": [
        "torch.save(model_ft,'/content/drive/MyDrive/saved_models/'+model_name+'new.h5')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpGRminVjRIY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 682
        },
        "outputId": "8aa2cb22-829b-45d2-d8ea-c840a5fdd4ca"
      },
      "source": [
        "import seaborn as sns\n",
        "nb_classes = num_classes\n",
        "confusion_matrix = np.zeros((nb_classes, nb_classes))\n",
        "with torch.no_grad():\n",
        "    for i, (inputs, classes) in enumerate(dataloaders['test']):\n",
        "        inputs = inputs.to(device)\n",
        "        classes = classes.to(device)\n",
        "        outputs = model_ft(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        for t, p in zip(classes.view(-1), preds.view(-1)):\n",
        "                confusion_matrix[t.long(), p.long()] += 1\n",
        "\n",
        "plt.figure(figsize=(15,10))\n",
        "\n",
        "class_names = ['Normal', 'Glaucoma']\n",
        "df_cm = pd.DataFrame(confusion_matrix, index=class_names, columns=class_names).astype(int)\n",
        "heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
        "\n",
        "heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right',fontsize=15)\n",
        "heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right',fontsize=15)\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 69.0, 'Predicted label')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x720 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Emzn5VAnJKU"
      },
      "source": [
        "Â "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EyL4HDhTKDa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}