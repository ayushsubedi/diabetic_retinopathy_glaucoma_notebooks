{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "inceptionv3_ben.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqHnaptr-kuA",
        "outputId": "03427be9-b3b2-484f-f988-63a2e51bbfc4"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon May 10 02:34:22 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   73C    P0    32W /  70W |   5522MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7-9XFsaZnKQ"
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oGJ2hstm39V"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from imutils import contours\n",
        "from skimage import measure\n",
        "import imutils\n",
        "import os\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import copy\n",
        "import time\n",
        "\n",
        "import torch\n",
        "from torchvision import datasets, models, transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader, Dataset, TensorDataset, Subset, WeightedRandomSampler\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import pickle"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u899MaWr-ZF0"
      },
      "source": [
        "# Top level data directory. Here we assume the format of the directory conforms\n",
        "#   to the ImageFolder structure\n",
        "data_dir = '/content/drive/MyDrive/kaggle_dataset'\n",
        "\n",
        "# Models to choose from [resnet, alexnet, vgg, squeezenet, densenet, inception]\n",
        "model_name = \"inception\"\n",
        "# inception\n",
        "input_size = 299\n",
        "\n",
        "# Number of classes in the dataset\n",
        "num_classes = 2\n",
        "\n",
        "# Batch size for training (change depending on how much memory you have)\n",
        "batch_size = 32\n",
        "\n",
        "# Number of epochs to train for\n",
        "num_epochs = 10\n",
        "\n",
        "# Flag for feature extracting. When False, we finetune the whole model,\n",
        "#   when True we only update the reshaped layer params\n",
        "feature_extract = False\n",
        "\n",
        "num_workers = 2\n",
        "\n",
        "train_size = 0.60\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYnO7mxJZywE"
      },
      "source": [
        "\n",
        "class ben_color(object):\n",
        "    def __call__(self, img, sigmaX=10):\n",
        "        \"\"\"\n",
        "        :param img: PIL): Image \n",
        "\n",
        "        :return: Normalized image\n",
        "        \"\"\"\n",
        "\n",
        "        img = np.asarray(img)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        img = self.crop_image_from_gray(img)\n",
        "        img = cv2.resize(img, (input_size, input_size))\n",
        "        img = cv2.addWeighted (img, 4, cv2.GaussianBlur(img, (0,0), sigmaX), -4, 128)\n",
        "        return Image.fromarray(img)\n",
        "\n",
        "    def crop_image_from_gray(self, img, tol=7):\n",
        "        if img.ndim ==2:\n",
        "            mask = img>tol\n",
        "            return img[np.ix_(mask.any(1),mask.any(0))]\n",
        "        elif img.ndim==3:\n",
        "            gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "            mask = gray_img>tol\n",
        "            \n",
        "            check_shape = img[:,:,0][np.ix_(mask.any(1),mask.any(0))].shape[0]\n",
        "            if (check_shape == 0):\n",
        "                return img \n",
        "            else:\n",
        "                img1=img[:,:,0][np.ix_(mask.any(1),mask.any(0))]\n",
        "                img2=img[:,:,1][np.ix_(mask.any(1),mask.any(0))]\n",
        "                img3=img[:,:,2][np.ix_(mask.any(1),mask.any(0))]\n",
        "                img = np.stack([img1,img2,img3],axis=-1)\n",
        "            return img\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__+'()'"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jj74frLDrZd"
      },
      "source": [
        "# Todos: shuffle in validation set\n",
        "# add more augmentations  \n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "        ben_color(),\n",
        "        transforms.RandomRotation(degrees=(0, 360)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.Resize((input_size, input_size)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "\n",
        "\n",
        "valid_transform = transforms.Compose([\n",
        "        ben_color(),\n",
        "        transforms.Resize((input_size, input_size)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "\n",
        "\n",
        "class DR(Dataset):\n",
        "    def __init__(self, dataset, transform=None):\n",
        "        self.dataset = dataset\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        if self.transform:\n",
        "            x = self.transform(dataset[index][0])\n",
        "        else:\n",
        "            x = dataset[index][0]\n",
        "        y = dataset[index][1]\n",
        "        return x, y\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(dataset)\n",
        "    \n",
        "\n",
        "dataset = ImageFolder(data_dir)\n",
        "\n",
        "traindataset = DR(dataset, train_transform)\n",
        "valdataset = DR(dataset, valid_transform)\n",
        "testdataset = DR(dataset, valid_transform)\n",
        "\n",
        "# Create the index splits for training, validation and test\n",
        "\n",
        "num_train = len(dataset)\n",
        "indices = list(range(num_train))\n",
        "split = int(np.floor(train_size * num_train))\n",
        "split2 = int(np.floor((train_size+(1-train_size)/2) * num_train))\n",
        "np.random.shuffle(indices)\n",
        "train_idx, valid_idx, test_idx = indices[:split], indices[split:split2], indices[split2:]\n",
        "\n",
        "traindata = Subset(traindataset, indices=train_idx)\n",
        "valdata = Subset(valdataset, indices=valid_idx)\n",
        "testdata = Subset(testdataset, indices=test_idx)\n",
        "\n",
        "class_weights = []\n",
        "for root, subdir, files in os.walk(data_dir):\n",
        "  if len(files)>0:\n",
        "    class_weights.append(1/len(files))\n",
        "\n",
        "sample_weights = [0] * len(traindata)\n",
        "\n",
        "for idx, (data, label) in enumerate(traindata):\n",
        "  class_weight = class_weights[label]\n",
        "  sample_weights[idx] = class_weight\n",
        "\n",
        "\n",
        "with open('/content/drive/MyDrive/clean_weights.pkl', 'wb') as f:\n",
        "  pickle.dump(sample_weights, f)\n",
        "\n",
        "with open('/content/drive/MyDrive/clean_weights.pkl', 'rb') as f:\n",
        "  sample_weights = pickle.load(f)\n",
        "\n",
        "sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)\n",
        "\n",
        "trainLoader = torch.utils.data.DataLoader(traindata, sampler=sampler, batch_size=batch_size, \n",
        "                                          num_workers=num_workers, drop_last=True)\n",
        "valLoader = torch.utils.data.DataLoader(valdata, batch_size=batch_size, \n",
        "                                          num_workers=num_workers, drop_last=True)\n",
        "testLoader = torch.utils.data.DataLoader(testdata, batch_size=batch_size,\n",
        "                                          num_workers=num_workers, drop_last=True)\n",
        "dataloaders = {'train': trainLoader, 'val': valLoader, 'test': testLoader}"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyThMaR4nbLF"
      },
      "source": [
        "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False):\n",
        "    since = time.time()\n",
        "\n",
        "    val_acc_history = []\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    # Get model outputs and calculate loss\n",
        "                    # Special case for inception because in training it has an auxiliary output. In train\n",
        "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
        "                    #   but in testing we only consider the final output.\n",
        "                    if is_inception and phase == 'train':\n",
        "                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
        "                        outputs, aux_outputs = model(inputs)\n",
        "                        loss1 = criterion(outputs, labels)\n",
        "                        loss2 = criterion(aux_outputs, labels)\n",
        "                        loss = loss1 + 0.4*loss2\n",
        "                    else:\n",
        "                        outputs = model(inputs)\n",
        "                        loss = criterion(outputs, labels)\n",
        "\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
        "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            if phase == 'val':\n",
        "                val_acc_history.append(epoch_acc)\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, val_acc_history"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75VdlQ8ln1a9"
      },
      "source": [
        "def set_parameter_requires_grad(model, feature_extracting):\n",
        "    if feature_extracting:\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4O8Uqptn8Sb",
        "outputId": "554e867e-32eb-42d6-be4a-c51befc5cdd7"
      },
      "source": [
        "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
        "    # Initialize these variables which will be set in this if statement. Each of these\n",
        "    #   variables is model specific.\n",
        "    model_ft = None\n",
        "    input_size = 0\n",
        "\n",
        "    if model_name == \"resnet\":\n",
        "        \"\"\" Resnet18\n",
        "        \"\"\"\n",
        "        model_ft = models.resnet18(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.fc.in_features\n",
        "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"alexnet\":\n",
        "        \"\"\" Alexnet\n",
        "        \"\"\"\n",
        "        model_ft = models.alexnet(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.classifier[6].in_features\n",
        "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"vgg\":\n",
        "        \"\"\" VGG11_bn\n",
        "        \"\"\"\n",
        "        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.classifier[6].in_features\n",
        "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"squeezenet\":\n",
        "        \"\"\" Squeezenet\n",
        "        \"\"\"\n",
        "        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
        "        model_ft.num_classes = num_classes\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"densenet\":\n",
        "        \"\"\" Densenet\n",
        "        \"\"\"\n",
        "        model_ft = models.densenet121(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.classifier.in_features\n",
        "        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"inception\":\n",
        "        \"\"\" Inception v3\n",
        "        Be careful, expects (299,299) sized images and has auxiliary output\n",
        "        \"\"\"\n",
        "        model_ft = models.inception_v3(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        # Handle the auxilary net\n",
        "        num_ftrs = model_ft.AuxLogits.fc.in_features\n",
        "        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n",
        "        # Handle the primary net\n",
        "        num_ftrs = model_ft.fc.in_features\n",
        "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
        "        input_size = 299\n",
        "\n",
        "    else:\n",
        "        print(\"Invalid model name, exiting...\")\n",
        "        exit()\n",
        "\n",
        "    return model_ft, input_size\n",
        "\n",
        "# Initialize the model for this run\n",
        "model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n",
        "\n",
        "# Print the model we just instantiated\n",
        "print(model_ft)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Inception3(\n",
            "  (Conv2d_1a_3x3): BasicConv2d(\n",
            "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
            "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (Conv2d_2a_3x3): BasicConv2d(\n",
            "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (Conv2d_2b_3x3): BasicConv2d(\n",
            "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (Conv2d_3b_1x1): BasicConv2d(\n",
            "    (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (Conv2d_4a_3x3): BasicConv2d(\n",
            "    (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (Mixed_5b): InceptionA(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_1): BasicConv2d(\n",
            "      (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_2): BasicConv2d(\n",
            "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_5c): InceptionA(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_1): BasicConv2d(\n",
            "      (conv): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_2): BasicConv2d(\n",
            "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_5d): InceptionA(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_1): BasicConv2d(\n",
            "      (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_2): BasicConv2d(\n",
            "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_6a): InceptionB(\n",
            "    (branch3x3): BasicConv2d(\n",
            "      (conv): Conv2d(288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_6b): InceptionC(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_2): BasicConv2d(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_3): BasicConv2d(\n",
            "      (conv): Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_4): BasicConv2d(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_5): BasicConv2d(\n",
            "      (conv): Conv2d(128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_6c): InceptionC(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_2): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_3): BasicConv2d(\n",
            "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_4): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_5): BasicConv2d(\n",
            "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_6d): InceptionC(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_2): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_3): BasicConv2d(\n",
            "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_4): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_5): BasicConv2d(\n",
            "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_6e): InceptionC(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_2): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_3): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_4): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_5): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (AuxLogits): InceptionAux(\n",
            "    (conv0): BasicConv2d(\n",
            "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (conv1): BasicConv2d(\n",
            "      (conv): Conv2d(128, 768, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fc): Linear(in_features=768, out_features=2, bias=True)\n",
            "  )\n",
            "  (Mixed_7a): InceptionD(\n",
            "    (branch3x3_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_2): BasicConv2d(\n",
            "      (conv): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7x3_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7x3_2): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7x3_3): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7x3_4): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_7b): InceptionE(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_1): BasicConv2d(\n",
            "      (conv): Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_2a): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_2b): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3a): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3b): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_7c): InceptionE(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_1): BasicConv2d(\n",
            "      (conv): Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_2a): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_2b): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3a): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3b): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (fc): Linear(in_features=2048, out_features=2, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6151ULNdzuq",
        "outputId": "fc354c69-a982-4406-b9b2-5fe6729f78fc"
      },
      "source": [
        "# Send the model to GPU\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "# Gather the parameters to be optimized/updated in this run. If we are\n",
        "#  finetuning we will be updating all parameters. However, if we are\n",
        "#  doing feature extract method, we will only update the parameters\n",
        "#  that we have just initialized, i.e. the parameters with requires_grad\n",
        "#  is True.\n",
        "params_to_update = model_ft.parameters()\n",
        "print(\"Params to learn:\")\n",
        "if feature_extract:\n",
        "    params_to_update = []\n",
        "    for name,param in model_ft.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            params_to_update.append(param)\n",
        "            print(\"\\t\",name)\n",
        "else:\n",
        "    for name,param in model_ft.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            print(\"\\t\",name)\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Params to learn:\n",
            "\t Conv2d_1a_3x3.conv.weight\n",
            "\t Conv2d_1a_3x3.bn.weight\n",
            "\t Conv2d_1a_3x3.bn.bias\n",
            "\t Conv2d_2a_3x3.conv.weight\n",
            "\t Conv2d_2a_3x3.bn.weight\n",
            "\t Conv2d_2a_3x3.bn.bias\n",
            "\t Conv2d_2b_3x3.conv.weight\n",
            "\t Conv2d_2b_3x3.bn.weight\n",
            "\t Conv2d_2b_3x3.bn.bias\n",
            "\t Conv2d_3b_1x1.conv.weight\n",
            "\t Conv2d_3b_1x1.bn.weight\n",
            "\t Conv2d_3b_1x1.bn.bias\n",
            "\t Conv2d_4a_3x3.conv.weight\n",
            "\t Conv2d_4a_3x3.bn.weight\n",
            "\t Conv2d_4a_3x3.bn.bias\n",
            "\t Mixed_5b.branch1x1.conv.weight\n",
            "\t Mixed_5b.branch1x1.bn.weight\n",
            "\t Mixed_5b.branch1x1.bn.bias\n",
            "\t Mixed_5b.branch5x5_1.conv.weight\n",
            "\t Mixed_5b.branch5x5_1.bn.weight\n",
            "\t Mixed_5b.branch5x5_1.bn.bias\n",
            "\t Mixed_5b.branch5x5_2.conv.weight\n",
            "\t Mixed_5b.branch5x5_2.bn.weight\n",
            "\t Mixed_5b.branch5x5_2.bn.bias\n",
            "\t Mixed_5b.branch3x3dbl_1.conv.weight\n",
            "\t Mixed_5b.branch3x3dbl_1.bn.weight\n",
            "\t Mixed_5b.branch3x3dbl_1.bn.bias\n",
            "\t Mixed_5b.branch3x3dbl_2.conv.weight\n",
            "\t Mixed_5b.branch3x3dbl_2.bn.weight\n",
            "\t Mixed_5b.branch3x3dbl_2.bn.bias\n",
            "\t Mixed_5b.branch3x3dbl_3.conv.weight\n",
            "\t Mixed_5b.branch3x3dbl_3.bn.weight\n",
            "\t Mixed_5b.branch3x3dbl_3.bn.bias\n",
            "\t Mixed_5b.branch_pool.conv.weight\n",
            "\t Mixed_5b.branch_pool.bn.weight\n",
            "\t Mixed_5b.branch_pool.bn.bias\n",
            "\t Mixed_5c.branch1x1.conv.weight\n",
            "\t Mixed_5c.branch1x1.bn.weight\n",
            "\t Mixed_5c.branch1x1.bn.bias\n",
            "\t Mixed_5c.branch5x5_1.conv.weight\n",
            "\t Mixed_5c.branch5x5_1.bn.weight\n",
            "\t Mixed_5c.branch5x5_1.bn.bias\n",
            "\t Mixed_5c.branch5x5_2.conv.weight\n",
            "\t Mixed_5c.branch5x5_2.bn.weight\n",
            "\t Mixed_5c.branch5x5_2.bn.bias\n",
            "\t Mixed_5c.branch3x3dbl_1.conv.weight\n",
            "\t Mixed_5c.branch3x3dbl_1.bn.weight\n",
            "\t Mixed_5c.branch3x3dbl_1.bn.bias\n",
            "\t Mixed_5c.branch3x3dbl_2.conv.weight\n",
            "\t Mixed_5c.branch3x3dbl_2.bn.weight\n",
            "\t Mixed_5c.branch3x3dbl_2.bn.bias\n",
            "\t Mixed_5c.branch3x3dbl_3.conv.weight\n",
            "\t Mixed_5c.branch3x3dbl_3.bn.weight\n",
            "\t Mixed_5c.branch3x3dbl_3.bn.bias\n",
            "\t Mixed_5c.branch_pool.conv.weight\n",
            "\t Mixed_5c.branch_pool.bn.weight\n",
            "\t Mixed_5c.branch_pool.bn.bias\n",
            "\t Mixed_5d.branch1x1.conv.weight\n",
            "\t Mixed_5d.branch1x1.bn.weight\n",
            "\t Mixed_5d.branch1x1.bn.bias\n",
            "\t Mixed_5d.branch5x5_1.conv.weight\n",
            "\t Mixed_5d.branch5x5_1.bn.weight\n",
            "\t Mixed_5d.branch5x5_1.bn.bias\n",
            "\t Mixed_5d.branch5x5_2.conv.weight\n",
            "\t Mixed_5d.branch5x5_2.bn.weight\n",
            "\t Mixed_5d.branch5x5_2.bn.bias\n",
            "\t Mixed_5d.branch3x3dbl_1.conv.weight\n",
            "\t Mixed_5d.branch3x3dbl_1.bn.weight\n",
            "\t Mixed_5d.branch3x3dbl_1.bn.bias\n",
            "\t Mixed_5d.branch3x3dbl_2.conv.weight\n",
            "\t Mixed_5d.branch3x3dbl_2.bn.weight\n",
            "\t Mixed_5d.branch3x3dbl_2.bn.bias\n",
            "\t Mixed_5d.branch3x3dbl_3.conv.weight\n",
            "\t Mixed_5d.branch3x3dbl_3.bn.weight\n",
            "\t Mixed_5d.branch3x3dbl_3.bn.bias\n",
            "\t Mixed_5d.branch_pool.conv.weight\n",
            "\t Mixed_5d.branch_pool.bn.weight\n",
            "\t Mixed_5d.branch_pool.bn.bias\n",
            "\t Mixed_6a.branch3x3.conv.weight\n",
            "\t Mixed_6a.branch3x3.bn.weight\n",
            "\t Mixed_6a.branch3x3.bn.bias\n",
            "\t Mixed_6a.branch3x3dbl_1.conv.weight\n",
            "\t Mixed_6a.branch3x3dbl_1.bn.weight\n",
            "\t Mixed_6a.branch3x3dbl_1.bn.bias\n",
            "\t Mixed_6a.branch3x3dbl_2.conv.weight\n",
            "\t Mixed_6a.branch3x3dbl_2.bn.weight\n",
            "\t Mixed_6a.branch3x3dbl_2.bn.bias\n",
            "\t Mixed_6a.branch3x3dbl_3.conv.weight\n",
            "\t Mixed_6a.branch3x3dbl_3.bn.weight\n",
            "\t Mixed_6a.branch3x3dbl_3.bn.bias\n",
            "\t Mixed_6b.branch1x1.conv.weight\n",
            "\t Mixed_6b.branch1x1.bn.weight\n",
            "\t Mixed_6b.branch1x1.bn.bias\n",
            "\t Mixed_6b.branch7x7_1.conv.weight\n",
            "\t Mixed_6b.branch7x7_1.bn.weight\n",
            "\t Mixed_6b.branch7x7_1.bn.bias\n",
            "\t Mixed_6b.branch7x7_2.conv.weight\n",
            "\t Mixed_6b.branch7x7_2.bn.weight\n",
            "\t Mixed_6b.branch7x7_2.bn.bias\n",
            "\t Mixed_6b.branch7x7_3.conv.weight\n",
            "\t Mixed_6b.branch7x7_3.bn.weight\n",
            "\t Mixed_6b.branch7x7_3.bn.bias\n",
            "\t Mixed_6b.branch7x7dbl_1.conv.weight\n",
            "\t Mixed_6b.branch7x7dbl_1.bn.weight\n",
            "\t Mixed_6b.branch7x7dbl_1.bn.bias\n",
            "\t Mixed_6b.branch7x7dbl_2.conv.weight\n",
            "\t Mixed_6b.branch7x7dbl_2.bn.weight\n",
            "\t Mixed_6b.branch7x7dbl_2.bn.bias\n",
            "\t Mixed_6b.branch7x7dbl_3.conv.weight\n",
            "\t Mixed_6b.branch7x7dbl_3.bn.weight\n",
            "\t Mixed_6b.branch7x7dbl_3.bn.bias\n",
            "\t Mixed_6b.branch7x7dbl_4.conv.weight\n",
            "\t Mixed_6b.branch7x7dbl_4.bn.weight\n",
            "\t Mixed_6b.branch7x7dbl_4.bn.bias\n",
            "\t Mixed_6b.branch7x7dbl_5.conv.weight\n",
            "\t Mixed_6b.branch7x7dbl_5.bn.weight\n",
            "\t Mixed_6b.branch7x7dbl_5.bn.bias\n",
            "\t Mixed_6b.branch_pool.conv.weight\n",
            "\t Mixed_6b.branch_pool.bn.weight\n",
            "\t Mixed_6b.branch_pool.bn.bias\n",
            "\t Mixed_6c.branch1x1.conv.weight\n",
            "\t Mixed_6c.branch1x1.bn.weight\n",
            "\t Mixed_6c.branch1x1.bn.bias\n",
            "\t Mixed_6c.branch7x7_1.conv.weight\n",
            "\t Mixed_6c.branch7x7_1.bn.weight\n",
            "\t Mixed_6c.branch7x7_1.bn.bias\n",
            "\t Mixed_6c.branch7x7_2.conv.weight\n",
            "\t Mixed_6c.branch7x7_2.bn.weight\n",
            "\t Mixed_6c.branch7x7_2.bn.bias\n",
            "\t Mixed_6c.branch7x7_3.conv.weight\n",
            "\t Mixed_6c.branch7x7_3.bn.weight\n",
            "\t Mixed_6c.branch7x7_3.bn.bias\n",
            "\t Mixed_6c.branch7x7dbl_1.conv.weight\n",
            "\t Mixed_6c.branch7x7dbl_1.bn.weight\n",
            "\t Mixed_6c.branch7x7dbl_1.bn.bias\n",
            "\t Mixed_6c.branch7x7dbl_2.conv.weight\n",
            "\t Mixed_6c.branch7x7dbl_2.bn.weight\n",
            "\t Mixed_6c.branch7x7dbl_2.bn.bias\n",
            "\t Mixed_6c.branch7x7dbl_3.conv.weight\n",
            "\t Mixed_6c.branch7x7dbl_3.bn.weight\n",
            "\t Mixed_6c.branch7x7dbl_3.bn.bias\n",
            "\t Mixed_6c.branch7x7dbl_4.conv.weight\n",
            "\t Mixed_6c.branch7x7dbl_4.bn.weight\n",
            "\t Mixed_6c.branch7x7dbl_4.bn.bias\n",
            "\t Mixed_6c.branch7x7dbl_5.conv.weight\n",
            "\t Mixed_6c.branch7x7dbl_5.bn.weight\n",
            "\t Mixed_6c.branch7x7dbl_5.bn.bias\n",
            "\t Mixed_6c.branch_pool.conv.weight\n",
            "\t Mixed_6c.branch_pool.bn.weight\n",
            "\t Mixed_6c.branch_pool.bn.bias\n",
            "\t Mixed_6d.branch1x1.conv.weight\n",
            "\t Mixed_6d.branch1x1.bn.weight\n",
            "\t Mixed_6d.branch1x1.bn.bias\n",
            "\t Mixed_6d.branch7x7_1.conv.weight\n",
            "\t Mixed_6d.branch7x7_1.bn.weight\n",
            "\t Mixed_6d.branch7x7_1.bn.bias\n",
            "\t Mixed_6d.branch7x7_2.conv.weight\n",
            "\t Mixed_6d.branch7x7_2.bn.weight\n",
            "\t Mixed_6d.branch7x7_2.bn.bias\n",
            "\t Mixed_6d.branch7x7_3.conv.weight\n",
            "\t Mixed_6d.branch7x7_3.bn.weight\n",
            "\t Mixed_6d.branch7x7_3.bn.bias\n",
            "\t Mixed_6d.branch7x7dbl_1.conv.weight\n",
            "\t Mixed_6d.branch7x7dbl_1.bn.weight\n",
            "\t Mixed_6d.branch7x7dbl_1.bn.bias\n",
            "\t Mixed_6d.branch7x7dbl_2.conv.weight\n",
            "\t Mixed_6d.branch7x7dbl_2.bn.weight\n",
            "\t Mixed_6d.branch7x7dbl_2.bn.bias\n",
            "\t Mixed_6d.branch7x7dbl_3.conv.weight\n",
            "\t Mixed_6d.branch7x7dbl_3.bn.weight\n",
            "\t Mixed_6d.branch7x7dbl_3.bn.bias\n",
            "\t Mixed_6d.branch7x7dbl_4.conv.weight\n",
            "\t Mixed_6d.branch7x7dbl_4.bn.weight\n",
            "\t Mixed_6d.branch7x7dbl_4.bn.bias\n",
            "\t Mixed_6d.branch7x7dbl_5.conv.weight\n",
            "\t Mixed_6d.branch7x7dbl_5.bn.weight\n",
            "\t Mixed_6d.branch7x7dbl_5.bn.bias\n",
            "\t Mixed_6d.branch_pool.conv.weight\n",
            "\t Mixed_6d.branch_pool.bn.weight\n",
            "\t Mixed_6d.branch_pool.bn.bias\n",
            "\t Mixed_6e.branch1x1.conv.weight\n",
            "\t Mixed_6e.branch1x1.bn.weight\n",
            "\t Mixed_6e.branch1x1.bn.bias\n",
            "\t Mixed_6e.branch7x7_1.conv.weight\n",
            "\t Mixed_6e.branch7x7_1.bn.weight\n",
            "\t Mixed_6e.branch7x7_1.bn.bias\n",
            "\t Mixed_6e.branch7x7_2.conv.weight\n",
            "\t Mixed_6e.branch7x7_2.bn.weight\n",
            "\t Mixed_6e.branch7x7_2.bn.bias\n",
            "\t Mixed_6e.branch7x7_3.conv.weight\n",
            "\t Mixed_6e.branch7x7_3.bn.weight\n",
            "\t Mixed_6e.branch7x7_3.bn.bias\n",
            "\t Mixed_6e.branch7x7dbl_1.conv.weight\n",
            "\t Mixed_6e.branch7x7dbl_1.bn.weight\n",
            "\t Mixed_6e.branch7x7dbl_1.bn.bias\n",
            "\t Mixed_6e.branch7x7dbl_2.conv.weight\n",
            "\t Mixed_6e.branch7x7dbl_2.bn.weight\n",
            "\t Mixed_6e.branch7x7dbl_2.bn.bias\n",
            "\t Mixed_6e.branch7x7dbl_3.conv.weight\n",
            "\t Mixed_6e.branch7x7dbl_3.bn.weight\n",
            "\t Mixed_6e.branch7x7dbl_3.bn.bias\n",
            "\t Mixed_6e.branch7x7dbl_4.conv.weight\n",
            "\t Mixed_6e.branch7x7dbl_4.bn.weight\n",
            "\t Mixed_6e.branch7x7dbl_4.bn.bias\n",
            "\t Mixed_6e.branch7x7dbl_5.conv.weight\n",
            "\t Mixed_6e.branch7x7dbl_5.bn.weight\n",
            "\t Mixed_6e.branch7x7dbl_5.bn.bias\n",
            "\t Mixed_6e.branch_pool.conv.weight\n",
            "\t Mixed_6e.branch_pool.bn.weight\n",
            "\t Mixed_6e.branch_pool.bn.bias\n",
            "\t AuxLogits.conv0.conv.weight\n",
            "\t AuxLogits.conv0.bn.weight\n",
            "\t AuxLogits.conv0.bn.bias\n",
            "\t AuxLogits.conv1.conv.weight\n",
            "\t AuxLogits.conv1.bn.weight\n",
            "\t AuxLogits.conv1.bn.bias\n",
            "\t AuxLogits.fc.weight\n",
            "\t AuxLogits.fc.bias\n",
            "\t Mixed_7a.branch3x3_1.conv.weight\n",
            "\t Mixed_7a.branch3x3_1.bn.weight\n",
            "\t Mixed_7a.branch3x3_1.bn.bias\n",
            "\t Mixed_7a.branch3x3_2.conv.weight\n",
            "\t Mixed_7a.branch3x3_2.bn.weight\n",
            "\t Mixed_7a.branch3x3_2.bn.bias\n",
            "\t Mixed_7a.branch7x7x3_1.conv.weight\n",
            "\t Mixed_7a.branch7x7x3_1.bn.weight\n",
            "\t Mixed_7a.branch7x7x3_1.bn.bias\n",
            "\t Mixed_7a.branch7x7x3_2.conv.weight\n",
            "\t Mixed_7a.branch7x7x3_2.bn.weight\n",
            "\t Mixed_7a.branch7x7x3_2.bn.bias\n",
            "\t Mixed_7a.branch7x7x3_3.conv.weight\n",
            "\t Mixed_7a.branch7x7x3_3.bn.weight\n",
            "\t Mixed_7a.branch7x7x3_3.bn.bias\n",
            "\t Mixed_7a.branch7x7x3_4.conv.weight\n",
            "\t Mixed_7a.branch7x7x3_4.bn.weight\n",
            "\t Mixed_7a.branch7x7x3_4.bn.bias\n",
            "\t Mixed_7b.branch1x1.conv.weight\n",
            "\t Mixed_7b.branch1x1.bn.weight\n",
            "\t Mixed_7b.branch1x1.bn.bias\n",
            "\t Mixed_7b.branch3x3_1.conv.weight\n",
            "\t Mixed_7b.branch3x3_1.bn.weight\n",
            "\t Mixed_7b.branch3x3_1.bn.bias\n",
            "\t Mixed_7b.branch3x3_2a.conv.weight\n",
            "\t Mixed_7b.branch3x3_2a.bn.weight\n",
            "\t Mixed_7b.branch3x3_2a.bn.bias\n",
            "\t Mixed_7b.branch3x3_2b.conv.weight\n",
            "\t Mixed_7b.branch3x3_2b.bn.weight\n",
            "\t Mixed_7b.branch3x3_2b.bn.bias\n",
            "\t Mixed_7b.branch3x3dbl_1.conv.weight\n",
            "\t Mixed_7b.branch3x3dbl_1.bn.weight\n",
            "\t Mixed_7b.branch3x3dbl_1.bn.bias\n",
            "\t Mixed_7b.branch3x3dbl_2.conv.weight\n",
            "\t Mixed_7b.branch3x3dbl_2.bn.weight\n",
            "\t Mixed_7b.branch3x3dbl_2.bn.bias\n",
            "\t Mixed_7b.branch3x3dbl_3a.conv.weight\n",
            "\t Mixed_7b.branch3x3dbl_3a.bn.weight\n",
            "\t Mixed_7b.branch3x3dbl_3a.bn.bias\n",
            "\t Mixed_7b.branch3x3dbl_3b.conv.weight\n",
            "\t Mixed_7b.branch3x3dbl_3b.bn.weight\n",
            "\t Mixed_7b.branch3x3dbl_3b.bn.bias\n",
            "\t Mixed_7b.branch_pool.conv.weight\n",
            "\t Mixed_7b.branch_pool.bn.weight\n",
            "\t Mixed_7b.branch_pool.bn.bias\n",
            "\t Mixed_7c.branch1x1.conv.weight\n",
            "\t Mixed_7c.branch1x1.bn.weight\n",
            "\t Mixed_7c.branch1x1.bn.bias\n",
            "\t Mixed_7c.branch3x3_1.conv.weight\n",
            "\t Mixed_7c.branch3x3_1.bn.weight\n",
            "\t Mixed_7c.branch3x3_1.bn.bias\n",
            "\t Mixed_7c.branch3x3_2a.conv.weight\n",
            "\t Mixed_7c.branch3x3_2a.bn.weight\n",
            "\t Mixed_7c.branch3x3_2a.bn.bias\n",
            "\t Mixed_7c.branch3x3_2b.conv.weight\n",
            "\t Mixed_7c.branch3x3_2b.bn.weight\n",
            "\t Mixed_7c.branch3x3_2b.bn.bias\n",
            "\t Mixed_7c.branch3x3dbl_1.conv.weight\n",
            "\t Mixed_7c.branch3x3dbl_1.bn.weight\n",
            "\t Mixed_7c.branch3x3dbl_1.bn.bias\n",
            "\t Mixed_7c.branch3x3dbl_2.conv.weight\n",
            "\t Mixed_7c.branch3x3dbl_2.bn.weight\n",
            "\t Mixed_7c.branch3x3dbl_2.bn.bias\n",
            "\t Mixed_7c.branch3x3dbl_3a.conv.weight\n",
            "\t Mixed_7c.branch3x3dbl_3a.bn.weight\n",
            "\t Mixed_7c.branch3x3dbl_3a.bn.bias\n",
            "\t Mixed_7c.branch3x3dbl_3b.conv.weight\n",
            "\t Mixed_7c.branch3x3dbl_3b.bn.weight\n",
            "\t Mixed_7c.branch3x3dbl_3b.bn.bias\n",
            "\t Mixed_7c.branch_pool.conv.weight\n",
            "\t Mixed_7c.branch_pool.bn.weight\n",
            "\t Mixed_7c.branch_pool.bn.bias\n",
            "\t fc.weight\n",
            "\t fc.bias\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXg5BAG1oo-f",
        "outputId": "e9f937dd-0171-41a5-8710-81450ab4f674"
      },
      "source": [
        "# Setup the loss fxn\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Train and evaluate\n",
        "model_ft, hist = train_model(model_ft, dataloaders, criterion, optimizer_ft, num_epochs=num_epochs, is_inception=(model_name==\"inception\"))"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/9\n",
            "----------\n",
            "train Loss: 0.9612 Acc: 0.5231\n",
            "val Loss: 0.5871 Acc: 0.7231\n",
            "\n",
            "Epoch 1/9\n",
            "----------\n",
            "train Loss: 0.9341 Acc: 0.5462\n",
            "val Loss: 0.7257 Acc: 0.3846\n",
            "\n",
            "Epoch 2/9\n",
            "----------\n",
            "train Loss: 0.8850 Acc: 0.5846\n",
            "val Loss: 0.6044 Acc: 0.6846\n",
            "\n",
            "Epoch 3/9\n",
            "----------\n",
            "train Loss: 0.8184 Acc: 0.6513\n",
            "val Loss: 0.7041 Acc: 0.5077\n",
            "\n",
            "Epoch 4/9\n",
            "----------\n",
            "train Loss: 0.7322 Acc: 0.7436\n",
            "val Loss: 0.7338 Acc: 0.5385\n",
            "\n",
            "Epoch 5/9\n",
            "----------\n",
            "train Loss: 0.6892 Acc: 0.7641\n",
            "val Loss: 0.7171 Acc: 0.5692\n",
            "\n",
            "Epoch 6/9\n",
            "----------\n",
            "train Loss: 0.6083 Acc: 0.8000\n",
            "val Loss: 0.6559 Acc: 0.6538\n",
            "\n",
            "Epoch 7/9\n",
            "----------\n",
            "train Loss: 0.6207 Acc: 0.7923\n",
            "val Loss: 0.5146 Acc: 0.7538\n",
            "\n",
            "Epoch 8/9\n",
            "----------\n",
            "train Loss: 0.5557 Acc: 0.8179\n",
            "val Loss: 0.7991 Acc: 0.6154\n",
            "\n",
            "Epoch 9/9\n",
            "----------\n",
            "train Loss: 0.5554 Acc: 0.8077\n",
            "val Loss: 0.5994 Acc: 0.6846\n",
            "\n",
            "Training complete in 19m 58s\n",
            "Best val Acc: 0.753846\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgYraiAjiys8"
      },
      "source": [
        "torch.save(model_ft,'/content/drive/MyDrive/saved_models/'+model_name+'glaucoma_ben_inception_kaggle.h5')"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpGRminVjRIY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "outputId": "821e7729-f690-4f9c-915d-ff961c59f00f"
      },
      "source": [
        "import seaborn as sns\n",
        "nb_classes = num_classes\n",
        "confusion_matrix = np.zeros((nb_classes, nb_classes))\n",
        "with torch.no_grad():\n",
        "    for i, (inputs, classes) in enumerate(dataloaders['test']):\n",
        "        inputs = inputs.to(device)\n",
        "        classes = classes.to(device)\n",
        "        outputs = model_ft(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        for t, p in zip(classes.view(-1), preds.view(-1)):\n",
        "                confusion_matrix[t.long(), p.long()] += 1\n",
        "\n",
        "plt.figure(figsize=(15,10))\n",
        "\n",
        "class_names = ['Normal', 'Glaucoma']\n",
        "df_cm = pd.DataFrame(confusion_matrix, index=class_names, columns=class_names).astype(int)\n",
        "heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
        "\n",
        "heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right',fontsize=15)\n",
        "heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right',fontsize=15)\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 69.0, 'Predicted label')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x720 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Emzn5VAnJKU"
      },
      "source": [
        " "
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EyL4HDhTKDa"
      },
      "source": [
        ""
      ],
      "execution_count": 62,
      "outputs": []
    }
  ]
}