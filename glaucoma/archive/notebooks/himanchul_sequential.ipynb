{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "densenet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqHnaptr-kuA",
        "outputId": "a7e60b57-a360-47d6-bfff-755f61fc6a5f"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue May 11 09:47:45 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   73C    P0    76W / 149W |   5296MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7-9XFsaZnKQ"
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oGJ2hstm39V"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from imutils import contours\n",
        "from skimage import measure\n",
        "import imutils\n",
        "import os\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import copy\n",
        "import time\n",
        "\n",
        "import torch\n",
        "from torchvision import datasets, models, transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader, Dataset, TensorDataset, Subset, WeightedRandomSampler\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import pickle\n",
        "from collections import OrderedDict"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u899MaWr-ZF0"
      },
      "source": [
        "# Top level data directory. Here we assume the format of the directory conforms\n",
        "#   to the ImageFolder structure\n",
        "data_dir = '/content/drive/MyDrive/himanshu_original'\n",
        "\n",
        "# Models to choose from [resnet, alexnet, vgg, squeezenet, densenet, inception]\n",
        "model_name = \"densenet\"\n",
        "# inception\n",
        "input_size = 224\n",
        "\n",
        "# Number of classes in the dataset\n",
        "num_classes = 2\n",
        "\n",
        "# Batch size for training (change depending on how much memory you have)\n",
        "batch_size = 32\n",
        "\n",
        "# Number of epochs to train for\n",
        "num_epochs = 10\n",
        "\n",
        "# Flag for feature extracting. When False, we finetune the whole model,\n",
        "#   when True we only update the reshaped layer params\n",
        "feature_extract = False\n",
        "\n",
        "num_workers = 2\n",
        "\n",
        "train_size = 0.60\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYnO7mxJZywE"
      },
      "source": [
        "\n",
        "class ben_color(object):\n",
        "    def __call__(self, img, sigmaX=10):\n",
        "        \"\"\"\n",
        "        :param img: PIL): Image \n",
        "\n",
        "        :return: Normalized image\n",
        "        \"\"\"\n",
        "\n",
        "        img = np.asarray(img)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        img = self.crop_image_from_gray(img)\n",
        "        img = cv2.resize(img, (input_size, input_size))\n",
        "        img = cv2.addWeighted (img, 4, cv2.GaussianBlur(img, (0,0), sigmaX), -4, 128)\n",
        "        return Image.fromarray(img)\n",
        "\n",
        "    def crop_image_from_gray(self, img, tol=7):\n",
        "        if img.ndim ==2:\n",
        "            mask = img>tol\n",
        "            return img[np.ix_(mask.any(1),mask.any(0))]\n",
        "        elif img.ndim==3:\n",
        "            gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "            mask = gray_img>tol\n",
        "            \n",
        "            check_shape = img[:,:,0][np.ix_(mask.any(1),mask.any(0))].shape[0]\n",
        "            if (check_shape == 0):\n",
        "                return img \n",
        "            else:\n",
        "                img1=img[:,:,0][np.ix_(mask.any(1),mask.any(0))]\n",
        "                img2=img[:,:,1][np.ix_(mask.any(1),mask.any(0))]\n",
        "                img3=img[:,:,2][np.ix_(mask.any(1),mask.any(0))]\n",
        "                img = np.stack([img1,img2,img3],axis=-1)\n",
        "            return img\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__+'()'"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jj74frLDrZd"
      },
      "source": [
        "# Todos: shuffle in validation set\n",
        "# add more augmentations  \n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "        ben_color(),\n",
        "        transforms.RandomRotation(degrees=(0, 360)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.Resize((input_size, input_size)),\n",
        "        transforms.ToTensor(),\n",
        "        # transforms.Normalize((0.5,), (0.5,))])\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "\n",
        "\n",
        "valid_transform = transforms.Compose([\n",
        "        ben_color(),\n",
        "        transforms.Resize((input_size, input_size)),\n",
        "        transforms.ToTensor(),\n",
        "        # transforms.Normalize((0.5,), (0.5,))])\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "\n",
        "\n",
        "class DR(Dataset):\n",
        "    def __init__(self, dataset, transform=None):\n",
        "        self.dataset = dataset\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        if self.transform:\n",
        "            x = self.transform(dataset[index][0])\n",
        "        else:\n",
        "            x = dataset[index][0]\n",
        "        y = dataset[index][1]\n",
        "        return x, y\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(dataset)\n",
        "    \n",
        "\n",
        "dataset = ImageFolder(data_dir)\n",
        "\n",
        "traindataset = DR(dataset, train_transform)\n",
        "valdataset = DR(dataset, valid_transform)\n",
        "testdataset = DR(dataset, valid_transform)\n",
        "\n",
        "# Create the index splits for training, validation and test\n",
        "\n",
        "num_train = len(dataset)\n",
        "indices = list(range(num_train))\n",
        "split = int(np.floor(train_size * num_train))\n",
        "split2 = int(np.floor((train_size+(1-train_size)/2) * num_train))\n",
        "np.random.shuffle(indices)\n",
        "train_idx, valid_idx, test_idx = indices[:split], indices[split:split2], indices[split2:]\n",
        "\n",
        "traindata = Subset(traindataset, indices=train_idx)\n",
        "valdata = Subset(valdataset, indices=valid_idx)\n",
        "testdata = Subset(testdataset, indices=test_idx)\n",
        "\n",
        "class_weights = []\n",
        "for root, subdir, files in os.walk(data_dir):\n",
        "  if len(files)>0:\n",
        "    class_weights.append(1/len(files))\n",
        "\n",
        "sample_weights = [0] * len(traindata)\n",
        "\n",
        "for idx, (data, label) in enumerate(traindata):\n",
        "  class_weight = class_weights[label]\n",
        "  sample_weights[idx] = class_weight\n",
        "\n",
        "\n",
        "with open('/content/drive/MyDrive/himanshu.pkl', 'wb') as f:\n",
        "  pickle.dump(sample_weights, f)\n",
        "\n",
        "with open('/content/drive/MyDrive/himanshu.pkl', 'rb') as f:\n",
        "  sample_weights = pickle.load(f)\n",
        "\n",
        "sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)\n",
        "\n",
        "trainLoader = torch.utils.data.DataLoader(traindata, sampler=sampler, batch_size=batch_size, \n",
        "                                          num_workers=num_workers, drop_last=True)\n",
        "valLoader = torch.utils.data.DataLoader(valdata, batch_size=batch_size, \n",
        "                                          num_workers=num_workers, drop_last=True)\n",
        "testLoader = torch.utils.data.DataLoader(testdata, batch_size=batch_size,\n",
        "                                          num_workers=num_workers, drop_last=True)\n",
        "dataloaders = {'train': trainLoader, 'val': valLoader, 'test': testLoader}"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyThMaR4nbLF"
      },
      "source": [
        "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False):\n",
        "    since = time.time()\n",
        "\n",
        "    val_acc_history = []\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    # Get model outputs and calculate loss\n",
        "                    # Special case for inception because in training it has an auxiliary output. In train\n",
        "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
        "                    #   but in testing we only consider the final output.\n",
        "                    if is_inception and phase == 'train':\n",
        "                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
        "                        outputs, aux_outputs = model(inputs)\n",
        "                        loss1 = criterion(outputs, labels)\n",
        "                        loss2 = criterion(aux_outputs, labels)\n",
        "                        loss = loss1 + 0.4*loss2\n",
        "                    else:\n",
        "                        outputs = model(inputs)\n",
        "                        loss = criterion(outputs, labels)\n",
        "\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
        "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            if phase == 'val':\n",
        "                val_acc_history.append(epoch_acc)\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, val_acc_history"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75VdlQ8ln1a9"
      },
      "source": [
        "def set_parameter_requires_grad(model, feature_extracting):\n",
        "    if feature_extracting:\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4O8Uqptn8Sb",
        "outputId": "f0879c6d-825a-452b-c7ed-04f8070a3e85"
      },
      "source": [
        "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
        "    # Initialize these variables which will be set in this if statement. Each of these\n",
        "    #   variables is model specific.\n",
        "    model_ft = None\n",
        "    input_size = 0\n",
        "\n",
        "    if model_name == \"resnet\":\n",
        "        \"\"\" Resnet18\n",
        "        \"\"\"\n",
        "        model_ft = models.resnet18(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.fc.in_features\n",
        "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"alexnet\":\n",
        "        \"\"\" Alexnet\n",
        "        \"\"\"\n",
        "        model_ft = models.alexnet(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.classifier[6].in_features\n",
        "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"vgg\":\n",
        "        \"\"\" VGG11_bn\n",
        "        \"\"\"\n",
        "        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.classifier[6].in_features\n",
        "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"squeezenet\":\n",
        "        \"\"\" Squeezenet\n",
        "        \"\"\"\n",
        "        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
        "        model_ft.num_classes = num_classes\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"densenet\":\n",
        "        \"\"\" Densenet\n",
        "        \"\"\"\n",
        "        model_ft = models.densenet121(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.classifier.in_features\n",
        "        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n",
        "        input_size = 224\n",
        "        # classifier_dict = OrderedDict([\n",
        "        #     ('fc1', nn.Linear(1024, 512)),\n",
        "        #     ('relu1', nn.ReLU()),\n",
        "        #     ('dropout1', nn.Dropout(p=0.2)),\n",
        "        #     ('fc2', nn.Linear(512, 128)),\n",
        "        #     ('relu2', nn.ReLU()),\n",
        "        #     ('dropout2', nn.Dropout(p=0.2)),\n",
        "        #     ('fc3', nn.Linear(128, num_classes)),\n",
        "        #     ('output', nn.LogSoftmax(dim=1)),\n",
        "        #     ])\n",
        "            \n",
        "        # # creating the classifier for our usage using the ordered dictionary\n",
        "        # classifier = nn.Sequential(classifier_dict)\n",
        "\n",
        "        # # replacing the pretrained model classifier with our classifier\n",
        "        # model_ft.classifier = classifier\n",
        "\n",
        "    elif model_name == \"inception\":\n",
        "        \"\"\" Inception v3\n",
        "        Be careful, expects (299,299) sized images and has auxiliary output\n",
        "        \"\"\"\n",
        "        model_ft = models.inception_v3(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        # Handle the auxilary net\n",
        "        num_ftrs = model_ft.AuxLogits.fc.in_features\n",
        "        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n",
        "        # Handle the primary net\n",
        "        num_ftrs = model_ft.fc.in_features\n",
        "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
        "        input_size = 299\n",
        "\n",
        "    else:\n",
        "        print(\"Invalid model name, exiting...\")\n",
        "        exit()\n",
        "\n",
        "    return model_ft, input_size\n",
        "\n",
        "# Initialize the model for this run\n",
        "model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n",
        "\n",
        "# Print the model we just instantiated\n",
        "print(model_ft)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DenseNet(\n",
            "  (features): Sequential(\n",
            "    (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "    (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu0): ReLU(inplace=True)\n",
            "    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (denseblock1): _DenseBlock(\n",
            "      (denselayer1): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer2): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer3): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer4): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer5): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer6): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (transition1): _Transition(\n",
            "      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "    )\n",
            "    (denseblock2): _DenseBlock(\n",
            "      (denselayer1): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer2): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer3): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer4): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer5): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer6): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer7): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer8): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer9): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer10): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer11): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer12): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (transition2): _Transition(\n",
            "      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "    )\n",
            "    (denseblock3): _DenseBlock(\n",
            "      (denselayer1): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer2): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer3): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer4): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer5): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer6): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer7): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer8): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer9): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer10): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer11): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer12): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer13): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer14): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer15): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer16): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer17): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer18): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer19): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer20): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer21): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer22): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer23): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer24): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (transition3): _Transition(\n",
            "      (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "    )\n",
            "    (denseblock4): _DenseBlock(\n",
            "      (denselayer1): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer2): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer3): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer4): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer5): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer6): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer7): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer8): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer9): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer10): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer11): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer12): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer13): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer14): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer15): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer16): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (classifier): Linear(in_features=1024, out_features=2, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6151ULNdzuq",
        "outputId": "cf054d41-07bb-41f0-f7c4-a6f114e29ece"
      },
      "source": [
        "# Send the model to GPU\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "# Gather the parameters to be optimized/updated in this run. If we are\n",
        "#  finetuning we will be updating all parameters. However, if we are\n",
        "#  doing feature extract method, we will only update the parameters\n",
        "#  that we have just initialized, i.e. the parameters with requires_grad\n",
        "#  is True.\n",
        "params_to_update = model_ft.parameters()\n",
        "print(\"Params to learn:\")\n",
        "if feature_extract:\n",
        "    params_to_update = []\n",
        "    for name,param in model_ft.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            params_to_update.append(param)\n",
        "            print(\"\\t\",name)\n",
        "else:\n",
        "    for name,param in model_ft.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            print(\"\\t\",name)\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Params to learn:\n",
            "\t features.conv0.weight\n",
            "\t features.norm0.weight\n",
            "\t features.norm0.bias\n",
            "\t features.denseblock1.denselayer1.norm1.weight\n",
            "\t features.denseblock1.denselayer1.norm1.bias\n",
            "\t features.denseblock1.denselayer1.conv1.weight\n",
            "\t features.denseblock1.denselayer1.norm2.weight\n",
            "\t features.denseblock1.denselayer1.norm2.bias\n",
            "\t features.denseblock1.denselayer1.conv2.weight\n",
            "\t features.denseblock1.denselayer2.norm1.weight\n",
            "\t features.denseblock1.denselayer2.norm1.bias\n",
            "\t features.denseblock1.denselayer2.conv1.weight\n",
            "\t features.denseblock1.denselayer2.norm2.weight\n",
            "\t features.denseblock1.denselayer2.norm2.bias\n",
            "\t features.denseblock1.denselayer2.conv2.weight\n",
            "\t features.denseblock1.denselayer3.norm1.weight\n",
            "\t features.denseblock1.denselayer3.norm1.bias\n",
            "\t features.denseblock1.denselayer3.conv1.weight\n",
            "\t features.denseblock1.denselayer3.norm2.weight\n",
            "\t features.denseblock1.denselayer3.norm2.bias\n",
            "\t features.denseblock1.denselayer3.conv2.weight\n",
            "\t features.denseblock1.denselayer4.norm1.weight\n",
            "\t features.denseblock1.denselayer4.norm1.bias\n",
            "\t features.denseblock1.denselayer4.conv1.weight\n",
            "\t features.denseblock1.denselayer4.norm2.weight\n",
            "\t features.denseblock1.denselayer4.norm2.bias\n",
            "\t features.denseblock1.denselayer4.conv2.weight\n",
            "\t features.denseblock1.denselayer5.norm1.weight\n",
            "\t features.denseblock1.denselayer5.norm1.bias\n",
            "\t features.denseblock1.denselayer5.conv1.weight\n",
            "\t features.denseblock1.denselayer5.norm2.weight\n",
            "\t features.denseblock1.denselayer5.norm2.bias\n",
            "\t features.denseblock1.denselayer5.conv2.weight\n",
            "\t features.denseblock1.denselayer6.norm1.weight\n",
            "\t features.denseblock1.denselayer6.norm1.bias\n",
            "\t features.denseblock1.denselayer6.conv1.weight\n",
            "\t features.denseblock1.denselayer6.norm2.weight\n",
            "\t features.denseblock1.denselayer6.norm2.bias\n",
            "\t features.denseblock1.denselayer6.conv2.weight\n",
            "\t features.transition1.norm.weight\n",
            "\t features.transition1.norm.bias\n",
            "\t features.transition1.conv.weight\n",
            "\t features.denseblock2.denselayer1.norm1.weight\n",
            "\t features.denseblock2.denselayer1.norm1.bias\n",
            "\t features.denseblock2.denselayer1.conv1.weight\n",
            "\t features.denseblock2.denselayer1.norm2.weight\n",
            "\t features.denseblock2.denselayer1.norm2.bias\n",
            "\t features.denseblock2.denselayer1.conv2.weight\n",
            "\t features.denseblock2.denselayer2.norm1.weight\n",
            "\t features.denseblock2.denselayer2.norm1.bias\n",
            "\t features.denseblock2.denselayer2.conv1.weight\n",
            "\t features.denseblock2.denselayer2.norm2.weight\n",
            "\t features.denseblock2.denselayer2.norm2.bias\n",
            "\t features.denseblock2.denselayer2.conv2.weight\n",
            "\t features.denseblock2.denselayer3.norm1.weight\n",
            "\t features.denseblock2.denselayer3.norm1.bias\n",
            "\t features.denseblock2.denselayer3.conv1.weight\n",
            "\t features.denseblock2.denselayer3.norm2.weight\n",
            "\t features.denseblock2.denselayer3.norm2.bias\n",
            "\t features.denseblock2.denselayer3.conv2.weight\n",
            "\t features.denseblock2.denselayer4.norm1.weight\n",
            "\t features.denseblock2.denselayer4.norm1.bias\n",
            "\t features.denseblock2.denselayer4.conv1.weight\n",
            "\t features.denseblock2.denselayer4.norm2.weight\n",
            "\t features.denseblock2.denselayer4.norm2.bias\n",
            "\t features.denseblock2.denselayer4.conv2.weight\n",
            "\t features.denseblock2.denselayer5.norm1.weight\n",
            "\t features.denseblock2.denselayer5.norm1.bias\n",
            "\t features.denseblock2.denselayer5.conv1.weight\n",
            "\t features.denseblock2.denselayer5.norm2.weight\n",
            "\t features.denseblock2.denselayer5.norm2.bias\n",
            "\t features.denseblock2.denselayer5.conv2.weight\n",
            "\t features.denseblock2.denselayer6.norm1.weight\n",
            "\t features.denseblock2.denselayer6.norm1.bias\n",
            "\t features.denseblock2.denselayer6.conv1.weight\n",
            "\t features.denseblock2.denselayer6.norm2.weight\n",
            "\t features.denseblock2.denselayer6.norm2.bias\n",
            "\t features.denseblock2.denselayer6.conv2.weight\n",
            "\t features.denseblock2.denselayer7.norm1.weight\n",
            "\t features.denseblock2.denselayer7.norm1.bias\n",
            "\t features.denseblock2.denselayer7.conv1.weight\n",
            "\t features.denseblock2.denselayer7.norm2.weight\n",
            "\t features.denseblock2.denselayer7.norm2.bias\n",
            "\t features.denseblock2.denselayer7.conv2.weight\n",
            "\t features.denseblock2.denselayer8.norm1.weight\n",
            "\t features.denseblock2.denselayer8.norm1.bias\n",
            "\t features.denseblock2.denselayer8.conv1.weight\n",
            "\t features.denseblock2.denselayer8.norm2.weight\n",
            "\t features.denseblock2.denselayer8.norm2.bias\n",
            "\t features.denseblock2.denselayer8.conv2.weight\n",
            "\t features.denseblock2.denselayer9.norm1.weight\n",
            "\t features.denseblock2.denselayer9.norm1.bias\n",
            "\t features.denseblock2.denselayer9.conv1.weight\n",
            "\t features.denseblock2.denselayer9.norm2.weight\n",
            "\t features.denseblock2.denselayer9.norm2.bias\n",
            "\t features.denseblock2.denselayer9.conv2.weight\n",
            "\t features.denseblock2.denselayer10.norm1.weight\n",
            "\t features.denseblock2.denselayer10.norm1.bias\n",
            "\t features.denseblock2.denselayer10.conv1.weight\n",
            "\t features.denseblock2.denselayer10.norm2.weight\n",
            "\t features.denseblock2.denselayer10.norm2.bias\n",
            "\t features.denseblock2.denselayer10.conv2.weight\n",
            "\t features.denseblock2.denselayer11.norm1.weight\n",
            "\t features.denseblock2.denselayer11.norm1.bias\n",
            "\t features.denseblock2.denselayer11.conv1.weight\n",
            "\t features.denseblock2.denselayer11.norm2.weight\n",
            "\t features.denseblock2.denselayer11.norm2.bias\n",
            "\t features.denseblock2.denselayer11.conv2.weight\n",
            "\t features.denseblock2.denselayer12.norm1.weight\n",
            "\t features.denseblock2.denselayer12.norm1.bias\n",
            "\t features.denseblock2.denselayer12.conv1.weight\n",
            "\t features.denseblock2.denselayer12.norm2.weight\n",
            "\t features.denseblock2.denselayer12.norm2.bias\n",
            "\t features.denseblock2.denselayer12.conv2.weight\n",
            "\t features.transition2.norm.weight\n",
            "\t features.transition2.norm.bias\n",
            "\t features.transition2.conv.weight\n",
            "\t features.denseblock3.denselayer1.norm1.weight\n",
            "\t features.denseblock3.denselayer1.norm1.bias\n",
            "\t features.denseblock3.denselayer1.conv1.weight\n",
            "\t features.denseblock3.denselayer1.norm2.weight\n",
            "\t features.denseblock3.denselayer1.norm2.bias\n",
            "\t features.denseblock3.denselayer1.conv2.weight\n",
            "\t features.denseblock3.denselayer2.norm1.weight\n",
            "\t features.denseblock3.denselayer2.norm1.bias\n",
            "\t features.denseblock3.denselayer2.conv1.weight\n",
            "\t features.denseblock3.denselayer2.norm2.weight\n",
            "\t features.denseblock3.denselayer2.norm2.bias\n",
            "\t features.denseblock3.denselayer2.conv2.weight\n",
            "\t features.denseblock3.denselayer3.norm1.weight\n",
            "\t features.denseblock3.denselayer3.norm1.bias\n",
            "\t features.denseblock3.denselayer3.conv1.weight\n",
            "\t features.denseblock3.denselayer3.norm2.weight\n",
            "\t features.denseblock3.denselayer3.norm2.bias\n",
            "\t features.denseblock3.denselayer3.conv2.weight\n",
            "\t features.denseblock3.denselayer4.norm1.weight\n",
            "\t features.denseblock3.denselayer4.norm1.bias\n",
            "\t features.denseblock3.denselayer4.conv1.weight\n",
            "\t features.denseblock3.denselayer4.norm2.weight\n",
            "\t features.denseblock3.denselayer4.norm2.bias\n",
            "\t features.denseblock3.denselayer4.conv2.weight\n",
            "\t features.denseblock3.denselayer5.norm1.weight\n",
            "\t features.denseblock3.denselayer5.norm1.bias\n",
            "\t features.denseblock3.denselayer5.conv1.weight\n",
            "\t features.denseblock3.denselayer5.norm2.weight\n",
            "\t features.denseblock3.denselayer5.norm2.bias\n",
            "\t features.denseblock3.denselayer5.conv2.weight\n",
            "\t features.denseblock3.denselayer6.norm1.weight\n",
            "\t features.denseblock3.denselayer6.norm1.bias\n",
            "\t features.denseblock3.denselayer6.conv1.weight\n",
            "\t features.denseblock3.denselayer6.norm2.weight\n",
            "\t features.denseblock3.denselayer6.norm2.bias\n",
            "\t features.denseblock3.denselayer6.conv2.weight\n",
            "\t features.denseblock3.denselayer7.norm1.weight\n",
            "\t features.denseblock3.denselayer7.norm1.bias\n",
            "\t features.denseblock3.denselayer7.conv1.weight\n",
            "\t features.denseblock3.denselayer7.norm2.weight\n",
            "\t features.denseblock3.denselayer7.norm2.bias\n",
            "\t features.denseblock3.denselayer7.conv2.weight\n",
            "\t features.denseblock3.denselayer8.norm1.weight\n",
            "\t features.denseblock3.denselayer8.norm1.bias\n",
            "\t features.denseblock3.denselayer8.conv1.weight\n",
            "\t features.denseblock3.denselayer8.norm2.weight\n",
            "\t features.denseblock3.denselayer8.norm2.bias\n",
            "\t features.denseblock3.denselayer8.conv2.weight\n",
            "\t features.denseblock3.denselayer9.norm1.weight\n",
            "\t features.denseblock3.denselayer9.norm1.bias\n",
            "\t features.denseblock3.denselayer9.conv1.weight\n",
            "\t features.denseblock3.denselayer9.norm2.weight\n",
            "\t features.denseblock3.denselayer9.norm2.bias\n",
            "\t features.denseblock3.denselayer9.conv2.weight\n",
            "\t features.denseblock3.denselayer10.norm1.weight\n",
            "\t features.denseblock3.denselayer10.norm1.bias\n",
            "\t features.denseblock3.denselayer10.conv1.weight\n",
            "\t features.denseblock3.denselayer10.norm2.weight\n",
            "\t features.denseblock3.denselayer10.norm2.bias\n",
            "\t features.denseblock3.denselayer10.conv2.weight\n",
            "\t features.denseblock3.denselayer11.norm1.weight\n",
            "\t features.denseblock3.denselayer11.norm1.bias\n",
            "\t features.denseblock3.denselayer11.conv1.weight\n",
            "\t features.denseblock3.denselayer11.norm2.weight\n",
            "\t features.denseblock3.denselayer11.norm2.bias\n",
            "\t features.denseblock3.denselayer11.conv2.weight\n",
            "\t features.denseblock3.denselayer12.norm1.weight\n",
            "\t features.denseblock3.denselayer12.norm1.bias\n",
            "\t features.denseblock3.denselayer12.conv1.weight\n",
            "\t features.denseblock3.denselayer12.norm2.weight\n",
            "\t features.denseblock3.denselayer12.norm2.bias\n",
            "\t features.denseblock3.denselayer12.conv2.weight\n",
            "\t features.denseblock3.denselayer13.norm1.weight\n",
            "\t features.denseblock3.denselayer13.norm1.bias\n",
            "\t features.denseblock3.denselayer13.conv1.weight\n",
            "\t features.denseblock3.denselayer13.norm2.weight\n",
            "\t features.denseblock3.denselayer13.norm2.bias\n",
            "\t features.denseblock3.denselayer13.conv2.weight\n",
            "\t features.denseblock3.denselayer14.norm1.weight\n",
            "\t features.denseblock3.denselayer14.norm1.bias\n",
            "\t features.denseblock3.denselayer14.conv1.weight\n",
            "\t features.denseblock3.denselayer14.norm2.weight\n",
            "\t features.denseblock3.denselayer14.norm2.bias\n",
            "\t features.denseblock3.denselayer14.conv2.weight\n",
            "\t features.denseblock3.denselayer15.norm1.weight\n",
            "\t features.denseblock3.denselayer15.norm1.bias\n",
            "\t features.denseblock3.denselayer15.conv1.weight\n",
            "\t features.denseblock3.denselayer15.norm2.weight\n",
            "\t features.denseblock3.denselayer15.norm2.bias\n",
            "\t features.denseblock3.denselayer15.conv2.weight\n",
            "\t features.denseblock3.denselayer16.norm1.weight\n",
            "\t features.denseblock3.denselayer16.norm1.bias\n",
            "\t features.denseblock3.denselayer16.conv1.weight\n",
            "\t features.denseblock3.denselayer16.norm2.weight\n",
            "\t features.denseblock3.denselayer16.norm2.bias\n",
            "\t features.denseblock3.denselayer16.conv2.weight\n",
            "\t features.denseblock3.denselayer17.norm1.weight\n",
            "\t features.denseblock3.denselayer17.norm1.bias\n",
            "\t features.denseblock3.denselayer17.conv1.weight\n",
            "\t features.denseblock3.denselayer17.norm2.weight\n",
            "\t features.denseblock3.denselayer17.norm2.bias\n",
            "\t features.denseblock3.denselayer17.conv2.weight\n",
            "\t features.denseblock3.denselayer18.norm1.weight\n",
            "\t features.denseblock3.denselayer18.norm1.bias\n",
            "\t features.denseblock3.denselayer18.conv1.weight\n",
            "\t features.denseblock3.denselayer18.norm2.weight\n",
            "\t features.denseblock3.denselayer18.norm2.bias\n",
            "\t features.denseblock3.denselayer18.conv2.weight\n",
            "\t features.denseblock3.denselayer19.norm1.weight\n",
            "\t features.denseblock3.denselayer19.norm1.bias\n",
            "\t features.denseblock3.denselayer19.conv1.weight\n",
            "\t features.denseblock3.denselayer19.norm2.weight\n",
            "\t features.denseblock3.denselayer19.norm2.bias\n",
            "\t features.denseblock3.denselayer19.conv2.weight\n",
            "\t features.denseblock3.denselayer20.norm1.weight\n",
            "\t features.denseblock3.denselayer20.norm1.bias\n",
            "\t features.denseblock3.denselayer20.conv1.weight\n",
            "\t features.denseblock3.denselayer20.norm2.weight\n",
            "\t features.denseblock3.denselayer20.norm2.bias\n",
            "\t features.denseblock3.denselayer20.conv2.weight\n",
            "\t features.denseblock3.denselayer21.norm1.weight\n",
            "\t features.denseblock3.denselayer21.norm1.bias\n",
            "\t features.denseblock3.denselayer21.conv1.weight\n",
            "\t features.denseblock3.denselayer21.norm2.weight\n",
            "\t features.denseblock3.denselayer21.norm2.bias\n",
            "\t features.denseblock3.denselayer21.conv2.weight\n",
            "\t features.denseblock3.denselayer22.norm1.weight\n",
            "\t features.denseblock3.denselayer22.norm1.bias\n",
            "\t features.denseblock3.denselayer22.conv1.weight\n",
            "\t features.denseblock3.denselayer22.norm2.weight\n",
            "\t features.denseblock3.denselayer22.norm2.bias\n",
            "\t features.denseblock3.denselayer22.conv2.weight\n",
            "\t features.denseblock3.denselayer23.norm1.weight\n",
            "\t features.denseblock3.denselayer23.norm1.bias\n",
            "\t features.denseblock3.denselayer23.conv1.weight\n",
            "\t features.denseblock3.denselayer23.norm2.weight\n",
            "\t features.denseblock3.denselayer23.norm2.bias\n",
            "\t features.denseblock3.denselayer23.conv2.weight\n",
            "\t features.denseblock3.denselayer24.norm1.weight\n",
            "\t features.denseblock3.denselayer24.norm1.bias\n",
            "\t features.denseblock3.denselayer24.conv1.weight\n",
            "\t features.denseblock3.denselayer24.norm2.weight\n",
            "\t features.denseblock3.denselayer24.norm2.bias\n",
            "\t features.denseblock3.denselayer24.conv2.weight\n",
            "\t features.transition3.norm.weight\n",
            "\t features.transition3.norm.bias\n",
            "\t features.transition3.conv.weight\n",
            "\t features.denseblock4.denselayer1.norm1.weight\n",
            "\t features.denseblock4.denselayer1.norm1.bias\n",
            "\t features.denseblock4.denselayer1.conv1.weight\n",
            "\t features.denseblock4.denselayer1.norm2.weight\n",
            "\t features.denseblock4.denselayer1.norm2.bias\n",
            "\t features.denseblock4.denselayer1.conv2.weight\n",
            "\t features.denseblock4.denselayer2.norm1.weight\n",
            "\t features.denseblock4.denselayer2.norm1.bias\n",
            "\t features.denseblock4.denselayer2.conv1.weight\n",
            "\t features.denseblock4.denselayer2.norm2.weight\n",
            "\t features.denseblock4.denselayer2.norm2.bias\n",
            "\t features.denseblock4.denselayer2.conv2.weight\n",
            "\t features.denseblock4.denselayer3.norm1.weight\n",
            "\t features.denseblock4.denselayer3.norm1.bias\n",
            "\t features.denseblock4.denselayer3.conv1.weight\n",
            "\t features.denseblock4.denselayer3.norm2.weight\n",
            "\t features.denseblock4.denselayer3.norm2.bias\n",
            "\t features.denseblock4.denselayer3.conv2.weight\n",
            "\t features.denseblock4.denselayer4.norm1.weight\n",
            "\t features.denseblock4.denselayer4.norm1.bias\n",
            "\t features.denseblock4.denselayer4.conv1.weight\n",
            "\t features.denseblock4.denselayer4.norm2.weight\n",
            "\t features.denseblock4.denselayer4.norm2.bias\n",
            "\t features.denseblock4.denselayer4.conv2.weight\n",
            "\t features.denseblock4.denselayer5.norm1.weight\n",
            "\t features.denseblock4.denselayer5.norm1.bias\n",
            "\t features.denseblock4.denselayer5.conv1.weight\n",
            "\t features.denseblock4.denselayer5.norm2.weight\n",
            "\t features.denseblock4.denselayer5.norm2.bias\n",
            "\t features.denseblock4.denselayer5.conv2.weight\n",
            "\t features.denseblock4.denselayer6.norm1.weight\n",
            "\t features.denseblock4.denselayer6.norm1.bias\n",
            "\t features.denseblock4.denselayer6.conv1.weight\n",
            "\t features.denseblock4.denselayer6.norm2.weight\n",
            "\t features.denseblock4.denselayer6.norm2.bias\n",
            "\t features.denseblock4.denselayer6.conv2.weight\n",
            "\t features.denseblock4.denselayer7.norm1.weight\n",
            "\t features.denseblock4.denselayer7.norm1.bias\n",
            "\t features.denseblock4.denselayer7.conv1.weight\n",
            "\t features.denseblock4.denselayer7.norm2.weight\n",
            "\t features.denseblock4.denselayer7.norm2.bias\n",
            "\t features.denseblock4.denselayer7.conv2.weight\n",
            "\t features.denseblock4.denselayer8.norm1.weight\n",
            "\t features.denseblock4.denselayer8.norm1.bias\n",
            "\t features.denseblock4.denselayer8.conv1.weight\n",
            "\t features.denseblock4.denselayer8.norm2.weight\n",
            "\t features.denseblock4.denselayer8.norm2.bias\n",
            "\t features.denseblock4.denselayer8.conv2.weight\n",
            "\t features.denseblock4.denselayer9.norm1.weight\n",
            "\t features.denseblock4.denselayer9.norm1.bias\n",
            "\t features.denseblock4.denselayer9.conv1.weight\n",
            "\t features.denseblock4.denselayer9.norm2.weight\n",
            "\t features.denseblock4.denselayer9.norm2.bias\n",
            "\t features.denseblock4.denselayer9.conv2.weight\n",
            "\t features.denseblock4.denselayer10.norm1.weight\n",
            "\t features.denseblock4.denselayer10.norm1.bias\n",
            "\t features.denseblock4.denselayer10.conv1.weight\n",
            "\t features.denseblock4.denselayer10.norm2.weight\n",
            "\t features.denseblock4.denselayer10.norm2.bias\n",
            "\t features.denseblock4.denselayer10.conv2.weight\n",
            "\t features.denseblock4.denselayer11.norm1.weight\n",
            "\t features.denseblock4.denselayer11.norm1.bias\n",
            "\t features.denseblock4.denselayer11.conv1.weight\n",
            "\t features.denseblock4.denselayer11.norm2.weight\n",
            "\t features.denseblock4.denselayer11.norm2.bias\n",
            "\t features.denseblock4.denselayer11.conv2.weight\n",
            "\t features.denseblock4.denselayer12.norm1.weight\n",
            "\t features.denseblock4.denselayer12.norm1.bias\n",
            "\t features.denseblock4.denselayer12.conv1.weight\n",
            "\t features.denseblock4.denselayer12.norm2.weight\n",
            "\t features.denseblock4.denselayer12.norm2.bias\n",
            "\t features.denseblock4.denselayer12.conv2.weight\n",
            "\t features.denseblock4.denselayer13.norm1.weight\n",
            "\t features.denseblock4.denselayer13.norm1.bias\n",
            "\t features.denseblock4.denselayer13.conv1.weight\n",
            "\t features.denseblock4.denselayer13.norm2.weight\n",
            "\t features.denseblock4.denselayer13.norm2.bias\n",
            "\t features.denseblock4.denselayer13.conv2.weight\n",
            "\t features.denseblock4.denselayer14.norm1.weight\n",
            "\t features.denseblock4.denselayer14.norm1.bias\n",
            "\t features.denseblock4.denselayer14.conv1.weight\n",
            "\t features.denseblock4.denselayer14.norm2.weight\n",
            "\t features.denseblock4.denselayer14.norm2.bias\n",
            "\t features.denseblock4.denselayer14.conv2.weight\n",
            "\t features.denseblock4.denselayer15.norm1.weight\n",
            "\t features.denseblock4.denselayer15.norm1.bias\n",
            "\t features.denseblock4.denselayer15.conv1.weight\n",
            "\t features.denseblock4.denselayer15.norm2.weight\n",
            "\t features.denseblock4.denselayer15.norm2.bias\n",
            "\t features.denseblock4.denselayer15.conv2.weight\n",
            "\t features.denseblock4.denselayer16.norm1.weight\n",
            "\t features.denseblock4.denselayer16.norm1.bias\n",
            "\t features.denseblock4.denselayer16.conv1.weight\n",
            "\t features.denseblock4.denselayer16.norm2.weight\n",
            "\t features.denseblock4.denselayer16.norm2.bias\n",
            "\t features.denseblock4.denselayer16.conv2.weight\n",
            "\t features.norm5.weight\n",
            "\t features.norm5.bias\n",
            "\t classifier.weight\n",
            "\t classifier.bias\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXg5BAG1oo-f",
        "outputId": "c98bc3df-a737-48f3-c833-825297db4b1e"
      },
      "source": [
        "# # Setup the loss fxn\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# NLLLoss because our output is LogSoftmax\n",
        "# criterion = nn.NLLLoss()\n",
        "\n",
        "# Adam optimizer with a learning rate\n",
        "# optimizer_ft = optim.Adam(model_ft.classifier.parameters(), lr = 0.001)\n",
        "\n",
        "\n",
        "# Train and evaluate\n",
        "model_ft, hist = train_model(model_ft, dataloaders, criterion, optimizer_ft, num_epochs=num_epochs, is_inception=(model_name==\"inception\"))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/9\n",
            "----------\n",
            "train Loss: 0.3161 Acc: 0.9025\n",
            "val Loss: 0.2700 Acc: 0.9178\n",
            "\n",
            "Epoch 1/9\n",
            "----------\n",
            "train Loss: 0.2185 Acc: 0.9205\n",
            "val Loss: 0.2308 Acc: 0.9194\n",
            "\n",
            "Epoch 2/9\n",
            "----------\n",
            "train Loss: 0.1861 Acc: 0.9266\n",
            "val Loss: 0.2238 Acc: 0.9227\n",
            "\n",
            "Epoch 3/9\n",
            "----------\n",
            "train Loss: 0.1770 Acc: 0.9342\n",
            "val Loss: 0.2135 Acc: 0.9243\n",
            "\n",
            "Epoch 4/9\n",
            "----------\n",
            "train Loss: 0.1444 Acc: 0.9414\n",
            "val Loss: 0.2085 Acc: 0.9211\n",
            "\n",
            "Epoch 5/9\n",
            "----------\n",
            "train Loss: 0.1354 Acc: 0.9512\n",
            "val Loss: 0.2271 Acc: 0.9260\n",
            "\n",
            "Epoch 6/9\n",
            "----------\n",
            "train Loss: 0.1034 Acc: 0.9622\n",
            "val Loss: 0.2250 Acc: 0.9178\n",
            "\n",
            "Epoch 7/9\n",
            "----------\n",
            "train Loss: 0.1038 Acc: 0.9677\n",
            "val Loss: 0.2272 Acc: 0.9112\n",
            "\n",
            "Epoch 8/9\n",
            "----------\n",
            "train Loss: 0.1047 Acc: 0.9638\n",
            "val Loss: 0.2243 Acc: 0.9178\n",
            "\n",
            "Epoch 9/9\n",
            "----------\n",
            "train Loss: 0.0691 Acc: 0.9764\n",
            "val Loss: 0.2219 Acc: 0.9227\n",
            "\n",
            "Training complete in 82m 7s\n",
            "Best val Acc: 0.925987\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgYraiAjiys8"
      },
      "source": [
        "torch.save(model_ft,'/content/drive/MyDrive/saved_models/densenet_ocular_clean.h5')"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpGRminVjRIY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "12fad8cd-63c3-4238-9fe6-d94a22f6fc16"
      },
      "source": [
        "import seaborn as sns\n",
        "nb_classes = num_classes\n",
        "confusion_matrix = np.zeros((nb_classes, nb_classes))\n",
        "with torch.no_grad():\n",
        "    for i, (inputs, classes) in enumerate(dataloaders['test']):\n",
        "        inputs = inputs.to(device)\n",
        "        classes = classes.to(device)\n",
        "        outputs = model_ft(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        print (preds)\n",
        "        for t, p in zip(classes.view(-1), preds.view(-1)):\n",
        "                confusion_matrix[t.long(), p.long()] += 1\n",
        "\n",
        "plt.figure(figsize=(15,10))\n",
        "\n",
        "class_names = ['Normal', 'Glaucoma']\n",
        "df_cm = pd.DataFrame(confusion_matrix, index=class_names, columns=class_names).astype(int)\n",
        "heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
        "\n",
        "heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right',fontsize=15)\n",
        "heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right',fontsize=15)\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 1, 0, 0], device='cuda:0')\n",
            "tensor([0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "tensor([1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 1, 0], device='cuda:0')\n",
            "tensor([0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "tensor([0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 1, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "tensor([0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 1], device='cuda:0')\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 69.0, 'Predicted label')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x720 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EyL4HDhTKDa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "outputId": "d879cae8-e152-4f41-ab3d-b7dbae3ed959"
      },
      "source": [
        "confusion_matrix = np.zeros((nb_classes, nb_classes))\n",
        "with torch.no_grad():\n",
        "    for i, (inputs, classes) in enumerate(dataloaders['train']):\n",
        "        inputs = inputs.to(device)\n",
        "        classes = classes.to(device)\n",
        "        outputs = model_ft(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        for t, p in zip(classes.view(-1), preds.view(-1)):\n",
        "                confusion_matrix[t.long(), p.long()] += 1\n",
        "\n",
        "plt.figure(figsize=(15,10))\n",
        "\n",
        "class_names = ['Normal', 'Glaucoma']\n",
        "df_cm = pd.DataFrame(confusion_matrix, index=class_names, columns=class_names).astype(int)\n",
        "heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
        "\n",
        "heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right',fontsize=15)\n",
        "heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right',fontsize=15)\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 69.0, 'Predicted label')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x720 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pryRZOM_O64w"
      },
      "source": [
        ""
      ],
      "execution_count": 54,
      "outputs": []
    }
  ]
}