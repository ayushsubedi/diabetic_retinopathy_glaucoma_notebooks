{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "inceptionv3_ben.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqHnaptr-kuA",
        "outputId": "036eb899-3c3e-41cd-aa80-b99ccf370398"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon May 10 10:05:50 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   75C    P0    33W /  70W |   5084MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7-9XFsaZnKQ"
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oGJ2hstm39V"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from imutils import contours\n",
        "from skimage import measure\n",
        "import imutils\n",
        "import os\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import copy\n",
        "import time\n",
        "\n",
        "import torch\n",
        "from torchvision import datasets, models, transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader, Dataset, TensorDataset, Subset, WeightedRandomSampler\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import pickle"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u899MaWr-ZF0"
      },
      "source": [
        "# Top level data directory. Here we assume the format of the directory conforms\n",
        "#   to the ImageFolder structure\n",
        "data_dir = '/content/drive/MyDrive/disk_dataset_kaggle'\n",
        "\n",
        "# Models to choose from [resnet, alexnet, vgg, squeezenet, densenet, inception]\n",
        "model_name = \"inception\"\n",
        "# inception\n",
        "input_size = 299\n",
        "\n",
        "# Number of classes in the dataset\n",
        "num_classes = 2\n",
        "\n",
        "# Batch size for training (change depending on how much memory you have)\n",
        "batch_size = 32\n",
        "\n",
        "# Number of epochs to train for\n",
        "num_epochs = 10\n",
        "\n",
        "# Flag for feature extracting. When False, we finetune the whole model,\n",
        "#   when True we only update the reshaped layer params\n",
        "feature_extract = False\n",
        "\n",
        "num_workers = 2\n",
        "\n",
        "train_size = 0.60\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYnO7mxJZywE"
      },
      "source": [
        "\n",
        "class ben_color(object):\n",
        "    def __call__(self, img, sigmaX=10):\n",
        "        \"\"\"\n",
        "        :param img: PIL): Image \n",
        "\n",
        "        :return: Normalized image\n",
        "        \"\"\"\n",
        "\n",
        "        img = np.asarray(img)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        img = self.crop_image_from_gray(img)\n",
        "        img = cv2.resize(img, (input_size, input_size))\n",
        "        img = cv2.addWeighted (img, 4, cv2.GaussianBlur(img, (0,0), sigmaX), -4, 128)\n",
        "        return Image.fromarray(img)\n",
        "\n",
        "    def crop_image_from_gray(self, img, tol=7):\n",
        "        if img.ndim ==2:\n",
        "            mask = img>tol\n",
        "            return img[np.ix_(mask.any(1),mask.any(0))]\n",
        "        elif img.ndim==3:\n",
        "            gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "            mask = gray_img>tol\n",
        "            \n",
        "            check_shape = img[:,:,0][np.ix_(mask.any(1),mask.any(0))].shape[0]\n",
        "            if (check_shape == 0):\n",
        "                return img \n",
        "            else:\n",
        "                img1=img[:,:,0][np.ix_(mask.any(1),mask.any(0))]\n",
        "                img2=img[:,:,1][np.ix_(mask.any(1),mask.any(0))]\n",
        "                img3=img[:,:,2][np.ix_(mask.any(1),mask.any(0))]\n",
        "                img = np.stack([img1,img2,img3],axis=-1)\n",
        "            return img\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__+'()'"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jj74frLDrZd"
      },
      "source": [
        "# Todos: shuffle in validation set\n",
        "# add more augmentations  \n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "        ben_color(),\n",
        "        transforms.RandomRotation(degrees=(0, 360)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.Resize((input_size, input_size)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "\n",
        "\n",
        "valid_transform = transforms.Compose([\n",
        "        ben_color(),\n",
        "        transforms.Resize((input_size, input_size)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "\n",
        "\n",
        "class DR(Dataset):\n",
        "    def __init__(self, dataset, transform=None):\n",
        "        self.dataset = dataset\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        if self.transform:\n",
        "            x = self.transform(dataset[index][0])\n",
        "        else:\n",
        "            x = dataset[index][0]\n",
        "        y = dataset[index][1]\n",
        "        return x, y\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(dataset)\n",
        "    \n",
        "\n",
        "dataset = ImageFolder(data_dir)\n",
        "\n",
        "traindataset = DR(dataset, train_transform)\n",
        "valdataset = DR(dataset, valid_transform)\n",
        "testdataset = DR(dataset, valid_transform)\n",
        "\n",
        "# Create the index splits for training, validation and test\n",
        "\n",
        "num_train = len(dataset)\n",
        "indices = list(range(num_train))\n",
        "split = int(np.floor(train_size * num_train))\n",
        "split2 = int(np.floor((train_size+(1-train_size)/2) * num_train))\n",
        "np.random.shuffle(indices)\n",
        "train_idx, valid_idx, test_idx = indices[:split], indices[split:split2], indices[split2:]\n",
        "\n",
        "traindata = Subset(traindataset, indices=train_idx)\n",
        "valdata = Subset(valdataset, indices=valid_idx)\n",
        "testdata = Subset(testdataset, indices=test_idx)\n",
        "\n",
        "class_weights = []\n",
        "for root, subdir, files in os.walk(data_dir):\n",
        "  if len(files)>0:\n",
        "    class_weights.append(1/len(files))\n",
        "\n",
        "sample_weights = [0] * len(traindata)\n",
        "\n",
        "for idx, (data, label) in enumerate(traindata):\n",
        "  class_weight = class_weights[label]\n",
        "  sample_weights[idx] = class_weight\n",
        "\n",
        "\n",
        "with open('/content/drive/MyDrive/clean_weights.pkl', 'wb') as f:\n",
        "  pickle.dump(sample_weights, f)\n",
        "\n",
        "with open('/content/drive/MyDrive/clean_weights.pkl', 'rb') as f:\n",
        "  sample_weights = pickle.load(f)\n",
        "\n",
        "sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)\n",
        "\n",
        "trainLoader = torch.utils.data.DataLoader(traindata, sampler=sampler, batch_size=batch_size, \n",
        "                                          num_workers=num_workers, drop_last=True)\n",
        "valLoader = torch.utils.data.DataLoader(valdata, batch_size=batch_size, \n",
        "                                          num_workers=num_workers, drop_last=True)\n",
        "testLoader = torch.utils.data.DataLoader(testdata, batch_size=batch_size,\n",
        "                                          num_workers=num_workers, drop_last=True)\n",
        "dataloaders = {'train': trainLoader, 'val': valLoader, 'test': testLoader}"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyThMaR4nbLF"
      },
      "source": [
        "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False):\n",
        "    since = time.time()\n",
        "\n",
        "    val_acc_history = []\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    # Get model outputs and calculate loss\n",
        "                    # Special case for inception because in training it has an auxiliary output. In train\n",
        "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
        "                    #   but in testing we only consider the final output.\n",
        "                    if is_inception and phase == 'train':\n",
        "                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
        "                        outputs, aux_outputs = model(inputs)\n",
        "                        loss1 = criterion(outputs, labels)\n",
        "                        loss2 = criterion(aux_outputs, labels)\n",
        "                        loss = loss1 + 0.4*loss2\n",
        "                    else:\n",
        "                        outputs = model(inputs)\n",
        "                        loss = criterion(outputs, labels)\n",
        "\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
        "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            if phase == 'val':\n",
        "                val_acc_history.append(epoch_acc)\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, val_acc_history"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75VdlQ8ln1a9"
      },
      "source": [
        "def set_parameter_requires_grad(model, feature_extracting):\n",
        "    if feature_extracting:\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4O8Uqptn8Sb",
        "outputId": "e7ba0d53-7564-4d01-fa36-042e7cc45728"
      },
      "source": [
        "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
        "    # Initialize these variables which will be set in this if statement. Each of these\n",
        "    #   variables is model specific.\n",
        "    model_ft = None\n",
        "    input_size = 0\n",
        "\n",
        "    if model_name == \"resnet\":\n",
        "        \"\"\" Resnet18\n",
        "        \"\"\"\n",
        "        model_ft = models.resnet18(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.fc.in_features\n",
        "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"alexnet\":\n",
        "        \"\"\" Alexnet\n",
        "        \"\"\"\n",
        "        model_ft = models.alexnet(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.classifier[6].in_features\n",
        "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"vgg\":\n",
        "        \"\"\" VGG11_bn\n",
        "        \"\"\"\n",
        "        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.classifier[6].in_features\n",
        "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"squeezenet\":\n",
        "        \"\"\" Squeezenet\n",
        "        \"\"\"\n",
        "        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
        "        model_ft.num_classes = num_classes\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"densenet\":\n",
        "        \"\"\" Densenet\n",
        "        \"\"\"\n",
        "        model_ft = models.densenet121(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.classifier.in_features\n",
        "        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"inception\":\n",
        "        \"\"\" Inception v3\n",
        "        Be careful, expects (299,299) sized images and has auxiliary output\n",
        "        \"\"\"\n",
        "        model_ft = models.inception_v3(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        # Handle the auxilary net\n",
        "        num_ftrs = model_ft.AuxLogits.fc.in_features\n",
        "        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n",
        "        # Handle the primary net\n",
        "        num_ftrs = model_ft.fc.in_features\n",
        "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
        "        input_size = 299\n",
        "\n",
        "    else:\n",
        "        print(\"Invalid model name, exiting...\")\n",
        "        exit()\n",
        "\n",
        "    return model_ft, input_size\n",
        "\n",
        "# Initialize the model for this run\n",
        "model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n",
        "\n",
        "# Print the model we just instantiated\n",
        "print(model_ft)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Inception3(\n",
            "  (Conv2d_1a_3x3): BasicConv2d(\n",
            "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
            "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (Conv2d_2a_3x3): BasicConv2d(\n",
            "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (Conv2d_2b_3x3): BasicConv2d(\n",
            "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (Conv2d_3b_1x1): BasicConv2d(\n",
            "    (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (Conv2d_4a_3x3): BasicConv2d(\n",
            "    (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (Mixed_5b): InceptionA(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_1): BasicConv2d(\n",
            "      (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_2): BasicConv2d(\n",
            "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_5c): InceptionA(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_1): BasicConv2d(\n",
            "      (conv): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_2): BasicConv2d(\n",
            "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_5d): InceptionA(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_1): BasicConv2d(\n",
            "      (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_2): BasicConv2d(\n",
            "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_6a): InceptionB(\n",
            "    (branch3x3): BasicConv2d(\n",
            "      (conv): Conv2d(288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_6b): InceptionC(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_2): BasicConv2d(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_3): BasicConv2d(\n",
            "      (conv): Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_4): BasicConv2d(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_5): BasicConv2d(\n",
            "      (conv): Conv2d(128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_6c): InceptionC(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_2): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_3): BasicConv2d(\n",
            "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_4): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_5): BasicConv2d(\n",
            "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_6d): InceptionC(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_2): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_3): BasicConv2d(\n",
            "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_4): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_5): BasicConv2d(\n",
            "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_6e): InceptionC(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_2): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_3): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_4): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_5): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (AuxLogits): InceptionAux(\n",
            "    (conv0): BasicConv2d(\n",
            "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (conv1): BasicConv2d(\n",
            "      (conv): Conv2d(128, 768, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fc): Linear(in_features=768, out_features=2, bias=True)\n",
            "  )\n",
            "  (Mixed_7a): InceptionD(\n",
            "    (branch3x3_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_2): BasicConv2d(\n",
            "      (conv): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7x3_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7x3_2): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7x3_3): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7x3_4): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_7b): InceptionE(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_1): BasicConv2d(\n",
            "      (conv): Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_2a): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_2b): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3a): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3b): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_7c): InceptionE(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_1): BasicConv2d(\n",
            "      (conv): Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_2a): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_2b): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3a): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3b): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (fc): Linear(in_features=2048, out_features=2, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6151ULNdzuq",
        "outputId": "48e3413b-e9d8-4d92-da8a-a375f1d0430b"
      },
      "source": [
        "# Send the model to GPU\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "# Gather the parameters to be optimized/updated in this run. If we are\n",
        "#  finetuning we will be updating all parameters. However, if we are\n",
        "#  doing feature extract method, we will only update the parameters\n",
        "#  that we have just initialized, i.e. the parameters with requires_grad\n",
        "#  is True.\n",
        "params_to_update = model_ft.parameters()\n",
        "print(\"Params to learn:\")\n",
        "if feature_extract:\n",
        "    params_to_update = []\n",
        "    for name,param in model_ft.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            params_to_update.append(param)\n",
        "            print(\"\\t\",name)\n",
        "else:\n",
        "    for name,param in model_ft.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            print(\"\\t\",name)\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Params to learn:\n",
            "\t Conv2d_1a_3x3.conv.weight\n",
            "\t Conv2d_1a_3x3.bn.weight\n",
            "\t Conv2d_1a_3x3.bn.bias\n",
            "\t Conv2d_2a_3x3.conv.weight\n",
            "\t Conv2d_2a_3x3.bn.weight\n",
            "\t Conv2d_2a_3x3.bn.bias\n",
            "\t Conv2d_2b_3x3.conv.weight\n",
            "\t Conv2d_2b_3x3.bn.weight\n",
            "\t Conv2d_2b_3x3.bn.bias\n",
            "\t Conv2d_3b_1x1.conv.weight\n",
            "\t Conv2d_3b_1x1.bn.weight\n",
            "\t Conv2d_3b_1x1.bn.bias\n",
            "\t Conv2d_4a_3x3.conv.weight\n",
            "\t Conv2d_4a_3x3.bn.weight\n",
            "\t Conv2d_4a_3x3.bn.bias\n",
            "\t Mixed_5b.branch1x1.conv.weight\n",
            "\t Mixed_5b.branch1x1.bn.weight\n",
            "\t Mixed_5b.branch1x1.bn.bias\n",
            "\t Mixed_5b.branch5x5_1.conv.weight\n",
            "\t Mixed_5b.branch5x5_1.bn.weight\n",
            "\t Mixed_5b.branch5x5_1.bn.bias\n",
            "\t Mixed_5b.branch5x5_2.conv.weight\n",
            "\t Mixed_5b.branch5x5_2.bn.weight\n",
            "\t Mixed_5b.branch5x5_2.bn.bias\n",
            "\t Mixed_5b.branch3x3dbl_1.conv.weight\n",
            "\t Mixed_5b.branch3x3dbl_1.bn.weight\n",
            "\t Mixed_5b.branch3x3dbl_1.bn.bias\n",
            "\t Mixed_5b.branch3x3dbl_2.conv.weight\n",
            "\t Mixed_5b.branch3x3dbl_2.bn.weight\n",
            "\t Mixed_5b.branch3x3dbl_2.bn.bias\n",
            "\t Mixed_5b.branch3x3dbl_3.conv.weight\n",
            "\t Mixed_5b.branch3x3dbl_3.bn.weight\n",
            "\t Mixed_5b.branch3x3dbl_3.bn.bias\n",
            "\t Mixed_5b.branch_pool.conv.weight\n",
            "\t Mixed_5b.branch_pool.bn.weight\n",
            "\t Mixed_5b.branch_pool.bn.bias\n",
            "\t Mixed_5c.branch1x1.conv.weight\n",
            "\t Mixed_5c.branch1x1.bn.weight\n",
            "\t Mixed_5c.branch1x1.bn.bias\n",
            "\t Mixed_5c.branch5x5_1.conv.weight\n",
            "\t Mixed_5c.branch5x5_1.bn.weight\n",
            "\t Mixed_5c.branch5x5_1.bn.bias\n",
            "\t Mixed_5c.branch5x5_2.conv.weight\n",
            "\t Mixed_5c.branch5x5_2.bn.weight\n",
            "\t Mixed_5c.branch5x5_2.bn.bias\n",
            "\t Mixed_5c.branch3x3dbl_1.conv.weight\n",
            "\t Mixed_5c.branch3x3dbl_1.bn.weight\n",
            "\t Mixed_5c.branch3x3dbl_1.bn.bias\n",
            "\t Mixed_5c.branch3x3dbl_2.conv.weight\n",
            "\t Mixed_5c.branch3x3dbl_2.bn.weight\n",
            "\t Mixed_5c.branch3x3dbl_2.bn.bias\n",
            "\t Mixed_5c.branch3x3dbl_3.conv.weight\n",
            "\t Mixed_5c.branch3x3dbl_3.bn.weight\n",
            "\t Mixed_5c.branch3x3dbl_3.bn.bias\n",
            "\t Mixed_5c.branch_pool.conv.weight\n",
            "\t Mixed_5c.branch_pool.bn.weight\n",
            "\t Mixed_5c.branch_pool.bn.bias\n",
            "\t Mixed_5d.branch1x1.conv.weight\n",
            "\t Mixed_5d.branch1x1.bn.weight\n",
            "\t Mixed_5d.branch1x1.bn.bias\n",
            "\t Mixed_5d.branch5x5_1.conv.weight\n",
            "\t Mixed_5d.branch5x5_1.bn.weight\n",
            "\t Mixed_5d.branch5x5_1.bn.bias\n",
            "\t Mixed_5d.branch5x5_2.conv.weight\n",
            "\t Mixed_5d.branch5x5_2.bn.weight\n",
            "\t Mixed_5d.branch5x5_2.bn.bias\n",
            "\t Mixed_5d.branch3x3dbl_1.conv.weight\n",
            "\t Mixed_5d.branch3x3dbl_1.bn.weight\n",
            "\t Mixed_5d.branch3x3dbl_1.bn.bias\n",
            "\t Mixed_5d.branch3x3dbl_2.conv.weight\n",
            "\t Mixed_5d.branch3x3dbl_2.bn.weight\n",
            "\t Mixed_5d.branch3x3dbl_2.bn.bias\n",
            "\t Mixed_5d.branch3x3dbl_3.conv.weight\n",
            "\t Mixed_5d.branch3x3dbl_3.bn.weight\n",
            "\t Mixed_5d.branch3x3dbl_3.bn.bias\n",
            "\t Mixed_5d.branch_pool.conv.weight\n",
            "\t Mixed_5d.branch_pool.bn.weight\n",
            "\t Mixed_5d.branch_pool.bn.bias\n",
            "\t Mixed_6a.branch3x3.conv.weight\n",
            "\t Mixed_6a.branch3x3.bn.weight\n",
            "\t Mixed_6a.branch3x3.bn.bias\n",
            "\t Mixed_6a.branch3x3dbl_1.conv.weight\n",
            "\t Mixed_6a.branch3x3dbl_1.bn.weight\n",
            "\t Mixed_6a.branch3x3dbl_1.bn.bias\n",
            "\t Mixed_6a.branch3x3dbl_2.conv.weight\n",
            "\t Mixed_6a.branch3x3dbl_2.bn.weight\n",
            "\t Mixed_6a.branch3x3dbl_2.bn.bias\n",
            "\t Mixed_6a.branch3x3dbl_3.conv.weight\n",
            "\t Mixed_6a.branch3x3dbl_3.bn.weight\n",
            "\t Mixed_6a.branch3x3dbl_3.bn.bias\n",
            "\t Mixed_6b.branch1x1.conv.weight\n",
            "\t Mixed_6b.branch1x1.bn.weight\n",
            "\t Mixed_6b.branch1x1.bn.bias\n",
            "\t Mixed_6b.branch7x7_1.conv.weight\n",
            "\t Mixed_6b.branch7x7_1.bn.weight\n",
            "\t Mixed_6b.branch7x7_1.bn.bias\n",
            "\t Mixed_6b.branch7x7_2.conv.weight\n",
            "\t Mixed_6b.branch7x7_2.bn.weight\n",
            "\t Mixed_6b.branch7x7_2.bn.bias\n",
            "\t Mixed_6b.branch7x7_3.conv.weight\n",
            "\t Mixed_6b.branch7x7_3.bn.weight\n",
            "\t Mixed_6b.branch7x7_3.bn.bias\n",
            "\t Mixed_6b.branch7x7dbl_1.conv.weight\n",
            "\t Mixed_6b.branch7x7dbl_1.bn.weight\n",
            "\t Mixed_6b.branch7x7dbl_1.bn.bias\n",
            "\t Mixed_6b.branch7x7dbl_2.conv.weight\n",
            "\t Mixed_6b.branch7x7dbl_2.bn.weight\n",
            "\t Mixed_6b.branch7x7dbl_2.bn.bias\n",
            "\t Mixed_6b.branch7x7dbl_3.conv.weight\n",
            "\t Mixed_6b.branch7x7dbl_3.bn.weight\n",
            "\t Mixed_6b.branch7x7dbl_3.bn.bias\n",
            "\t Mixed_6b.branch7x7dbl_4.conv.weight\n",
            "\t Mixed_6b.branch7x7dbl_4.bn.weight\n",
            "\t Mixed_6b.branch7x7dbl_4.bn.bias\n",
            "\t Mixed_6b.branch7x7dbl_5.conv.weight\n",
            "\t Mixed_6b.branch7x7dbl_5.bn.weight\n",
            "\t Mixed_6b.branch7x7dbl_5.bn.bias\n",
            "\t Mixed_6b.branch_pool.conv.weight\n",
            "\t Mixed_6b.branch_pool.bn.weight\n",
            "\t Mixed_6b.branch_pool.bn.bias\n",
            "\t Mixed_6c.branch1x1.conv.weight\n",
            "\t Mixed_6c.branch1x1.bn.weight\n",
            "\t Mixed_6c.branch1x1.bn.bias\n",
            "\t Mixed_6c.branch7x7_1.conv.weight\n",
            "\t Mixed_6c.branch7x7_1.bn.weight\n",
            "\t Mixed_6c.branch7x7_1.bn.bias\n",
            "\t Mixed_6c.branch7x7_2.conv.weight\n",
            "\t Mixed_6c.branch7x7_2.bn.weight\n",
            "\t Mixed_6c.branch7x7_2.bn.bias\n",
            "\t Mixed_6c.branch7x7_3.conv.weight\n",
            "\t Mixed_6c.branch7x7_3.bn.weight\n",
            "\t Mixed_6c.branch7x7_3.bn.bias\n",
            "\t Mixed_6c.branch7x7dbl_1.conv.weight\n",
            "\t Mixed_6c.branch7x7dbl_1.bn.weight\n",
            "\t Mixed_6c.branch7x7dbl_1.bn.bias\n",
            "\t Mixed_6c.branch7x7dbl_2.conv.weight\n",
            "\t Mixed_6c.branch7x7dbl_2.bn.weight\n",
            "\t Mixed_6c.branch7x7dbl_2.bn.bias\n",
            "\t Mixed_6c.branch7x7dbl_3.conv.weight\n",
            "\t Mixed_6c.branch7x7dbl_3.bn.weight\n",
            "\t Mixed_6c.branch7x7dbl_3.bn.bias\n",
            "\t Mixed_6c.branch7x7dbl_4.conv.weight\n",
            "\t Mixed_6c.branch7x7dbl_4.bn.weight\n",
            "\t Mixed_6c.branch7x7dbl_4.bn.bias\n",
            "\t Mixed_6c.branch7x7dbl_5.conv.weight\n",
            "\t Mixed_6c.branch7x7dbl_5.bn.weight\n",
            "\t Mixed_6c.branch7x7dbl_5.bn.bias\n",
            "\t Mixed_6c.branch_pool.conv.weight\n",
            "\t Mixed_6c.branch_pool.bn.weight\n",
            "\t Mixed_6c.branch_pool.bn.bias\n",
            "\t Mixed_6d.branch1x1.conv.weight\n",
            "\t Mixed_6d.branch1x1.bn.weight\n",
            "\t Mixed_6d.branch1x1.bn.bias\n",
            "\t Mixed_6d.branch7x7_1.conv.weight\n",
            "\t Mixed_6d.branch7x7_1.bn.weight\n",
            "\t Mixed_6d.branch7x7_1.bn.bias\n",
            "\t Mixed_6d.branch7x7_2.conv.weight\n",
            "\t Mixed_6d.branch7x7_2.bn.weight\n",
            "\t Mixed_6d.branch7x7_2.bn.bias\n",
            "\t Mixed_6d.branch7x7_3.conv.weight\n",
            "\t Mixed_6d.branch7x7_3.bn.weight\n",
            "\t Mixed_6d.branch7x7_3.bn.bias\n",
            "\t Mixed_6d.branch7x7dbl_1.conv.weight\n",
            "\t Mixed_6d.branch7x7dbl_1.bn.weight\n",
            "\t Mixed_6d.branch7x7dbl_1.bn.bias\n",
            "\t Mixed_6d.branch7x7dbl_2.conv.weight\n",
            "\t Mixed_6d.branch7x7dbl_2.bn.weight\n",
            "\t Mixed_6d.branch7x7dbl_2.bn.bias\n",
            "\t Mixed_6d.branch7x7dbl_3.conv.weight\n",
            "\t Mixed_6d.branch7x7dbl_3.bn.weight\n",
            "\t Mixed_6d.branch7x7dbl_3.bn.bias\n",
            "\t Mixed_6d.branch7x7dbl_4.conv.weight\n",
            "\t Mixed_6d.branch7x7dbl_4.bn.weight\n",
            "\t Mixed_6d.branch7x7dbl_4.bn.bias\n",
            "\t Mixed_6d.branch7x7dbl_5.conv.weight\n",
            "\t Mixed_6d.branch7x7dbl_5.bn.weight\n",
            "\t Mixed_6d.branch7x7dbl_5.bn.bias\n",
            "\t Mixed_6d.branch_pool.conv.weight\n",
            "\t Mixed_6d.branch_pool.bn.weight\n",
            "\t Mixed_6d.branch_pool.bn.bias\n",
            "\t Mixed_6e.branch1x1.conv.weight\n",
            "\t Mixed_6e.branch1x1.bn.weight\n",
            "\t Mixed_6e.branch1x1.bn.bias\n",
            "\t Mixed_6e.branch7x7_1.conv.weight\n",
            "\t Mixed_6e.branch7x7_1.bn.weight\n",
            "\t Mixed_6e.branch7x7_1.bn.bias\n",
            "\t Mixed_6e.branch7x7_2.conv.weight\n",
            "\t Mixed_6e.branch7x7_2.bn.weight\n",
            "\t Mixed_6e.branch7x7_2.bn.bias\n",
            "\t Mixed_6e.branch7x7_3.conv.weight\n",
            "\t Mixed_6e.branch7x7_3.bn.weight\n",
            "\t Mixed_6e.branch7x7_3.bn.bias\n",
            "\t Mixed_6e.branch7x7dbl_1.conv.weight\n",
            "\t Mixed_6e.branch7x7dbl_1.bn.weight\n",
            "\t Mixed_6e.branch7x7dbl_1.bn.bias\n",
            "\t Mixed_6e.branch7x7dbl_2.conv.weight\n",
            "\t Mixed_6e.branch7x7dbl_2.bn.weight\n",
            "\t Mixed_6e.branch7x7dbl_2.bn.bias\n",
            "\t Mixed_6e.branch7x7dbl_3.conv.weight\n",
            "\t Mixed_6e.branch7x7dbl_3.bn.weight\n",
            "\t Mixed_6e.branch7x7dbl_3.bn.bias\n",
            "\t Mixed_6e.branch7x7dbl_4.conv.weight\n",
            "\t Mixed_6e.branch7x7dbl_4.bn.weight\n",
            "\t Mixed_6e.branch7x7dbl_4.bn.bias\n",
            "\t Mixed_6e.branch7x7dbl_5.conv.weight\n",
            "\t Mixed_6e.branch7x7dbl_5.bn.weight\n",
            "\t Mixed_6e.branch7x7dbl_5.bn.bias\n",
            "\t Mixed_6e.branch_pool.conv.weight\n",
            "\t Mixed_6e.branch_pool.bn.weight\n",
            "\t Mixed_6e.branch_pool.bn.bias\n",
            "\t AuxLogits.conv0.conv.weight\n",
            "\t AuxLogits.conv0.bn.weight\n",
            "\t AuxLogits.conv0.bn.bias\n",
            "\t AuxLogits.conv1.conv.weight\n",
            "\t AuxLogits.conv1.bn.weight\n",
            "\t AuxLogits.conv1.bn.bias\n",
            "\t AuxLogits.fc.weight\n",
            "\t AuxLogits.fc.bias\n",
            "\t Mixed_7a.branch3x3_1.conv.weight\n",
            "\t Mixed_7a.branch3x3_1.bn.weight\n",
            "\t Mixed_7a.branch3x3_1.bn.bias\n",
            "\t Mixed_7a.branch3x3_2.conv.weight\n",
            "\t Mixed_7a.branch3x3_2.bn.weight\n",
            "\t Mixed_7a.branch3x3_2.bn.bias\n",
            "\t Mixed_7a.branch7x7x3_1.conv.weight\n",
            "\t Mixed_7a.branch7x7x3_1.bn.weight\n",
            "\t Mixed_7a.branch7x7x3_1.bn.bias\n",
            "\t Mixed_7a.branch7x7x3_2.conv.weight\n",
            "\t Mixed_7a.branch7x7x3_2.bn.weight\n",
            "\t Mixed_7a.branch7x7x3_2.bn.bias\n",
            "\t Mixed_7a.branch7x7x3_3.conv.weight\n",
            "\t Mixed_7a.branch7x7x3_3.bn.weight\n",
            "\t Mixed_7a.branch7x7x3_3.bn.bias\n",
            "\t Mixed_7a.branch7x7x3_4.conv.weight\n",
            "\t Mixed_7a.branch7x7x3_4.bn.weight\n",
            "\t Mixed_7a.branch7x7x3_4.bn.bias\n",
            "\t Mixed_7b.branch1x1.conv.weight\n",
            "\t Mixed_7b.branch1x1.bn.weight\n",
            "\t Mixed_7b.branch1x1.bn.bias\n",
            "\t Mixed_7b.branch3x3_1.conv.weight\n",
            "\t Mixed_7b.branch3x3_1.bn.weight\n",
            "\t Mixed_7b.branch3x3_1.bn.bias\n",
            "\t Mixed_7b.branch3x3_2a.conv.weight\n",
            "\t Mixed_7b.branch3x3_2a.bn.weight\n",
            "\t Mixed_7b.branch3x3_2a.bn.bias\n",
            "\t Mixed_7b.branch3x3_2b.conv.weight\n",
            "\t Mixed_7b.branch3x3_2b.bn.weight\n",
            "\t Mixed_7b.branch3x3_2b.bn.bias\n",
            "\t Mixed_7b.branch3x3dbl_1.conv.weight\n",
            "\t Mixed_7b.branch3x3dbl_1.bn.weight\n",
            "\t Mixed_7b.branch3x3dbl_1.bn.bias\n",
            "\t Mixed_7b.branch3x3dbl_2.conv.weight\n",
            "\t Mixed_7b.branch3x3dbl_2.bn.weight\n",
            "\t Mixed_7b.branch3x3dbl_2.bn.bias\n",
            "\t Mixed_7b.branch3x3dbl_3a.conv.weight\n",
            "\t Mixed_7b.branch3x3dbl_3a.bn.weight\n",
            "\t Mixed_7b.branch3x3dbl_3a.bn.bias\n",
            "\t Mixed_7b.branch3x3dbl_3b.conv.weight\n",
            "\t Mixed_7b.branch3x3dbl_3b.bn.weight\n",
            "\t Mixed_7b.branch3x3dbl_3b.bn.bias\n",
            "\t Mixed_7b.branch_pool.conv.weight\n",
            "\t Mixed_7b.branch_pool.bn.weight\n",
            "\t Mixed_7b.branch_pool.bn.bias\n",
            "\t Mixed_7c.branch1x1.conv.weight\n",
            "\t Mixed_7c.branch1x1.bn.weight\n",
            "\t Mixed_7c.branch1x1.bn.bias\n",
            "\t Mixed_7c.branch3x3_1.conv.weight\n",
            "\t Mixed_7c.branch3x3_1.bn.weight\n",
            "\t Mixed_7c.branch3x3_1.bn.bias\n",
            "\t Mixed_7c.branch3x3_2a.conv.weight\n",
            "\t Mixed_7c.branch3x3_2a.bn.weight\n",
            "\t Mixed_7c.branch3x3_2a.bn.bias\n",
            "\t Mixed_7c.branch3x3_2b.conv.weight\n",
            "\t Mixed_7c.branch3x3_2b.bn.weight\n",
            "\t Mixed_7c.branch3x3_2b.bn.bias\n",
            "\t Mixed_7c.branch3x3dbl_1.conv.weight\n",
            "\t Mixed_7c.branch3x3dbl_1.bn.weight\n",
            "\t Mixed_7c.branch3x3dbl_1.bn.bias\n",
            "\t Mixed_7c.branch3x3dbl_2.conv.weight\n",
            "\t Mixed_7c.branch3x3dbl_2.bn.weight\n",
            "\t Mixed_7c.branch3x3dbl_2.bn.bias\n",
            "\t Mixed_7c.branch3x3dbl_3a.conv.weight\n",
            "\t Mixed_7c.branch3x3dbl_3a.bn.weight\n",
            "\t Mixed_7c.branch3x3dbl_3a.bn.bias\n",
            "\t Mixed_7c.branch3x3dbl_3b.conv.weight\n",
            "\t Mixed_7c.branch3x3dbl_3b.bn.weight\n",
            "\t Mixed_7c.branch3x3dbl_3b.bn.bias\n",
            "\t Mixed_7c.branch_pool.conv.weight\n",
            "\t Mixed_7c.branch_pool.bn.weight\n",
            "\t Mixed_7c.branch_pool.bn.bias\n",
            "\t fc.weight\n",
            "\t fc.bias\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXg5BAG1oo-f",
        "outputId": "94faf38c-7275-46e5-c67b-6cdd6034ea7b"
      },
      "source": [
        "# Setup the loss fxn\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Train and evaluate\n",
        "model_ft, hist = train_model(model_ft, dataloaders, criterion, optimizer_ft, num_epochs=num_epochs, is_inception=(model_name==\"inception\"))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/9\n",
            "----------\n",
            "train Loss: 0.2843 Acc: 0.9537\n",
            "val Loss: 1.2114 Acc: 0.7231\n",
            "\n",
            "Epoch 1/9\n",
            "----------\n",
            "train Loss: 0.0127 Acc: 0.9871\n",
            "val Loss: 1.6767 Acc: 0.7231\n",
            "\n",
            "Epoch 2/9\n",
            "----------\n",
            "train Loss: 0.0037 Acc: 0.9871\n",
            "val Loss: 1.7711 Acc: 0.7231\n",
            "\n",
            "Epoch 3/9\n",
            "----------\n",
            "train Loss: 0.0025 Acc: 0.9871\n",
            "val Loss: 1.8033 Acc: 0.7231\n",
            "\n",
            "Epoch 4/9\n",
            "----------\n",
            "train Loss: 0.0020 Acc: 0.9871\n",
            "val Loss: 1.8237 Acc: 0.7231\n",
            "\n",
            "Epoch 5/9\n",
            "----------\n",
            "train Loss: 0.0020 Acc: 0.9871\n",
            "val Loss: 1.8359 Acc: 0.7231\n",
            "\n",
            "Epoch 6/9\n",
            "----------\n",
            "train Loss: 0.0303 Acc: 0.9846\n",
            "val Loss: 1.8416 Acc: 0.7231\n",
            "\n",
            "Epoch 7/9\n",
            "----------\n",
            "train Loss: 0.0018 Acc: 0.9871\n",
            "val Loss: 1.8285 Acc: 0.7231\n",
            "\n",
            "Epoch 8/9\n",
            "----------\n",
            "train Loss: 0.0018 Acc: 0.9871\n",
            "val Loss: 1.8289 Acc: 0.7231\n",
            "\n",
            "Epoch 9/9\n",
            "----------\n",
            "train Loss: 0.0244 Acc: 0.9846\n",
            "val Loss: 1.8258 Acc: 0.7231\n",
            "\n",
            "Training complete in 2m 9s\n",
            "Best val Acc: 0.723077\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgYraiAjiys8"
      },
      "source": [
        "torch.save(model_ft,'/content/drive/MyDrive/saved_models/kaggle_recropped_disk.h5')"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpGRminVjRIY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "outputId": "70abee28-9f64-4750-facf-6758967ee6e5"
      },
      "source": [
        "import seaborn as sns\n",
        "nb_classes = num_classes\n",
        "confusion_matrix = np.zeros((nb_classes, nb_classes))\n",
        "with torch.no_grad():\n",
        "    for i, (inputs, classes) in enumerate(dataloaders['test']):\n",
        "        inputs = inputs.to(device)\n",
        "        classes = classes.to(device)\n",
        "        outputs = model_ft(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        for t, p in zip(classes.view(-1), preds.view(-1)):\n",
        "                confusion_matrix[t.long(), p.long()] += 1\n",
        "\n",
        "plt.figure(figsize=(15,10))\n",
        "\n",
        "class_names = ['Normal', 'Glaucoma']\n",
        "df_cm = pd.DataFrame(confusion_matrix, index=class_names, columns=class_names).astype(int)\n",
        "heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
        "\n",
        "heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right',fontsize=15)\n",
        "heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right',fontsize=15)\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 69.0, 'Predicted label')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x720 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EyL4HDhTKDa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "outputId": "111ba03f-0196-4ec5-8f2a-552ea3f9ef36"
      },
      "source": [
        "confusion_matrix = np.zeros((nb_classes, nb_classes))\n",
        "with torch.no_grad():\n",
        "    for i, (inputs, classes) in enumerate(dataloaders['train']):\n",
        "        inputs = inputs.to(device)\n",
        "        classes = classes.to(device)\n",
        "        outputs = model_ft(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        for t, p in zip(classes.view(-1), preds.view(-1)):\n",
        "                confusion_matrix[t.long(), p.long()] += 1\n",
        "\n",
        "plt.figure(figsize=(15,10))\n",
        "\n",
        "class_names = ['Normal', 'Glaucoma']\n",
        "df_cm = pd.DataFrame(confusion_matrix, index=class_names, columns=class_names).astype(int)\n",
        "heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
        "\n",
        "heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right',fontsize=15)\n",
        "heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right',fontsize=15)\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 69.0, 'Predicted label')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x720 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FN3TbKIu7mZ"
      },
      "source": [
        ""
      ],
      "execution_count": 36,
      "outputs": []
    }
  ]
}