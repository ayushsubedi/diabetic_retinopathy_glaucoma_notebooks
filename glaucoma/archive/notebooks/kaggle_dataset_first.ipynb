{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "inceptionv3_ben.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqHnaptr-kuA",
        "outputId": "841ef5ee-cacc-4bd8-8f21-66f02912dfe3"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon May 10 02:11:59 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   69C    P0    31W /  70W |   5522MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7-9XFsaZnKQ"
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oGJ2hstm39V"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from imutils import contours\n",
        "from skimage import measure\n",
        "import imutils\n",
        "import os\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import copy\n",
        "import time\n",
        "\n",
        "import torch\n",
        "from torchvision import datasets, models, transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader, Dataset, TensorDataset, Subset, WeightedRandomSampler\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import pickle"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u899MaWr-ZF0"
      },
      "source": [
        "# Top level data directory. Here we assume the format of the directory conforms\n",
        "#   to the ImageFolder structure\n",
        "data_dir = '/content/drive/MyDrive/kaggle_dataset'\n",
        "\n",
        "# Models to choose from [resnet, alexnet, vgg, squeezenet, densenet, inception]\n",
        "model_name = \"inception\"\n",
        "# inception\n",
        "input_size = 299\n",
        "\n",
        "# Number of classes in the dataset\n",
        "num_classes = 2\n",
        "\n",
        "# Batch size for training (change depending on how much memory you have)\n",
        "batch_size = 32\n",
        "\n",
        "# Number of epochs to train for\n",
        "num_epochs = 10\n",
        "\n",
        "# Flag for feature extracting. When False, we finetune the whole model,\n",
        "#   when True we only update the reshaped layer params\n",
        "feature_extract = False\n",
        "\n",
        "num_workers = 2\n",
        "\n",
        "train_size = 0.60\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYnO7mxJZywE"
      },
      "source": [
        "\n",
        "class ben_color(object):\n",
        "    def __call__(self, img, sigmaX=10):\n",
        "        \"\"\"\n",
        "        :param img: PIL): Image \n",
        "\n",
        "        :return: Normalized image\n",
        "        \"\"\"\n",
        "\n",
        "        img = np.asarray(img)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        img = self.crop_image_from_gray(img)\n",
        "        img = cv2.resize(img, (input_size, input_size))\n",
        "        img = cv2.addWeighted (img, 4, cv2.GaussianBlur(img, (0,0), sigmaX), -4, 128)\n",
        "        return Image.fromarray(img)\n",
        "\n",
        "    def crop_image_from_gray(self, img, tol=7):\n",
        "        if img.ndim ==2:\n",
        "            mask = img>tol\n",
        "            return img[np.ix_(mask.any(1),mask.any(0))]\n",
        "        elif img.ndim==3:\n",
        "            gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "            mask = gray_img>tol\n",
        "            \n",
        "            check_shape = img[:,:,0][np.ix_(mask.any(1),mask.any(0))].shape[0]\n",
        "            if (check_shape == 0):\n",
        "                return img \n",
        "            else:\n",
        "                img1=img[:,:,0][np.ix_(mask.any(1),mask.any(0))]\n",
        "                img2=img[:,:,1][np.ix_(mask.any(1),mask.any(0))]\n",
        "                img3=img[:,:,2][np.ix_(mask.any(1),mask.any(0))]\n",
        "                img = np.stack([img1,img2,img3],axis=-1)\n",
        "            return img\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__+'()'"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jj74frLDrZd"
      },
      "source": [
        "# Todos: shuffle in validation set\n",
        "# add more augmentations  \n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "        # ben_color(),\n",
        "        transforms.RandomRotation(degrees=(0, 360)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.Resize((input_size, input_size)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "\n",
        "\n",
        "valid_transform = transforms.Compose([\n",
        "        # ben_color(),\n",
        "        transforms.Resize((input_size, input_size)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "\n",
        "\n",
        "class DR(Dataset):\n",
        "    def __init__(self, dataset, transform=None):\n",
        "        self.dataset = dataset\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        if self.transform:\n",
        "            x = self.transform(dataset[index][0])\n",
        "        else:\n",
        "            x = dataset[index][0]\n",
        "        y = dataset[index][1]\n",
        "        return x, y\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(dataset)\n",
        "    \n",
        "\n",
        "dataset = ImageFolder(data_dir)\n",
        "\n",
        "traindataset = DR(dataset, train_transform)\n",
        "valdataset = DR(dataset, valid_transform)\n",
        "testdataset = DR(dataset, valid_transform)\n",
        "\n",
        "# Create the index splits for training, validation and test\n",
        "\n",
        "num_train = len(dataset)\n",
        "indices = list(range(num_train))\n",
        "split = int(np.floor(train_size * num_train))\n",
        "split2 = int(np.floor((train_size+(1-train_size)/2) * num_train))\n",
        "np.random.shuffle(indices)\n",
        "train_idx, valid_idx, test_idx = indices[:split], indices[split:split2], indices[split2:]\n",
        "\n",
        "traindata = Subset(traindataset, indices=train_idx)\n",
        "valdata = Subset(valdataset, indices=valid_idx)\n",
        "testdata = Subset(testdataset, indices=test_idx)\n",
        "\n",
        "class_weights = []\n",
        "for root, subdir, files in os.walk(data_dir):\n",
        "  if len(files)>0:\n",
        "    class_weights.append(1/len(files))\n",
        "\n",
        "sample_weights = [0] * len(traindata)\n",
        "\n",
        "for idx, (data, label) in enumerate(traindata):\n",
        "  class_weight = class_weights[label]\n",
        "  sample_weights[idx] = class_weight\n",
        "\n",
        "\n",
        "with open('/content/drive/MyDrive/clean_weights.pkl', 'wb') as f:\n",
        "  pickle.dump(sample_weights, f)\n",
        "\n",
        "with open('/content/drive/MyDrive/clean_weights.pkl', 'rb') as f:\n",
        "  sample_weights = pickle.load(f)\n",
        "\n",
        "sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)\n",
        "\n",
        "trainLoader = torch.utils.data.DataLoader(traindata, sampler=sampler, batch_size=batch_size, \n",
        "                                          num_workers=num_workers, drop_last=True)\n",
        "valLoader = torch.utils.data.DataLoader(valdata, batch_size=batch_size, \n",
        "                                          num_workers=num_workers, drop_last=True)\n",
        "testLoader = torch.utils.data.DataLoader(testdata, batch_size=batch_size,\n",
        "                                          num_workers=num_workers, drop_last=True)\n",
        "dataloaders = {'train': trainLoader, 'val': valLoader, 'test': testLoader}"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyThMaR4nbLF"
      },
      "source": [
        "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False):\n",
        "    since = time.time()\n",
        "\n",
        "    val_acc_history = []\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    # Get model outputs and calculate loss\n",
        "                    # Special case for inception because in training it has an auxiliary output. In train\n",
        "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
        "                    #   but in testing we only consider the final output.\n",
        "                    if is_inception and phase == 'train':\n",
        "                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
        "                        outputs, aux_outputs = model(inputs)\n",
        "                        loss1 = criterion(outputs, labels)\n",
        "                        loss2 = criterion(aux_outputs, labels)\n",
        "                        loss = loss1 + 0.4*loss2\n",
        "                    else:\n",
        "                        outputs = model(inputs)\n",
        "                        loss = criterion(outputs, labels)\n",
        "\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
        "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            if phase == 'val':\n",
        "                val_acc_history.append(epoch_acc)\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, val_acc_history"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75VdlQ8ln1a9"
      },
      "source": [
        "def set_parameter_requires_grad(model, feature_extracting):\n",
        "    if feature_extracting:\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4O8Uqptn8Sb",
        "outputId": "0643c26d-2b21-462d-a9eb-53c2436625ca"
      },
      "source": [
        "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
        "    # Initialize these variables which will be set in this if statement. Each of these\n",
        "    #   variables is model specific.\n",
        "    model_ft = None\n",
        "    input_size = 0\n",
        "\n",
        "    if model_name == \"resnet\":\n",
        "        \"\"\" Resnet18\n",
        "        \"\"\"\n",
        "        model_ft = models.resnet18(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.fc.in_features\n",
        "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"alexnet\":\n",
        "        \"\"\" Alexnet\n",
        "        \"\"\"\n",
        "        model_ft = models.alexnet(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.classifier[6].in_features\n",
        "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"vgg\":\n",
        "        \"\"\" VGG11_bn\n",
        "        \"\"\"\n",
        "        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.classifier[6].in_features\n",
        "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"squeezenet\":\n",
        "        \"\"\" Squeezenet\n",
        "        \"\"\"\n",
        "        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
        "        model_ft.num_classes = num_classes\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"densenet\":\n",
        "        \"\"\" Densenet\n",
        "        \"\"\"\n",
        "        model_ft = models.densenet121(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.classifier.in_features\n",
        "        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"inception\":\n",
        "        \"\"\" Inception v3\n",
        "        Be careful, expects (299,299) sized images and has auxiliary output\n",
        "        \"\"\"\n",
        "        model_ft = models.inception_v3(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        # Handle the auxilary net\n",
        "        num_ftrs = model_ft.AuxLogits.fc.in_features\n",
        "        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n",
        "        # Handle the primary net\n",
        "        num_ftrs = model_ft.fc.in_features\n",
        "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
        "        input_size = 299\n",
        "\n",
        "    else:\n",
        "        print(\"Invalid model name, exiting...\")\n",
        "        exit()\n",
        "\n",
        "    return model_ft, input_size\n",
        "\n",
        "# Initialize the model for this run\n",
        "model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n",
        "\n",
        "# Print the model we just instantiated\n",
        "print(model_ft)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Inception3(\n",
            "  (Conv2d_1a_3x3): BasicConv2d(\n",
            "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
            "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (Conv2d_2a_3x3): BasicConv2d(\n",
            "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (Conv2d_2b_3x3): BasicConv2d(\n",
            "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (Conv2d_3b_1x1): BasicConv2d(\n",
            "    (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (Conv2d_4a_3x3): BasicConv2d(\n",
            "    (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (Mixed_5b): InceptionA(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_1): BasicConv2d(\n",
            "      (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_2): BasicConv2d(\n",
            "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_5c): InceptionA(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_1): BasicConv2d(\n",
            "      (conv): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_2): BasicConv2d(\n",
            "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_5d): InceptionA(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_1): BasicConv2d(\n",
            "      (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_2): BasicConv2d(\n",
            "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_6a): InceptionB(\n",
            "    (branch3x3): BasicConv2d(\n",
            "      (conv): Conv2d(288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_6b): InceptionC(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_2): BasicConv2d(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_3): BasicConv2d(\n",
            "      (conv): Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_4): BasicConv2d(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_5): BasicConv2d(\n",
            "      (conv): Conv2d(128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_6c): InceptionC(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_2): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_3): BasicConv2d(\n",
            "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_4): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_5): BasicConv2d(\n",
            "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_6d): InceptionC(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_2): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_3): BasicConv2d(\n",
            "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_4): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_5): BasicConv2d(\n",
            "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_6e): InceptionC(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_2): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_3): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_4): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_5): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (AuxLogits): InceptionAux(\n",
            "    (conv0): BasicConv2d(\n",
            "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (conv1): BasicConv2d(\n",
            "      (conv): Conv2d(128, 768, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fc): Linear(in_features=768, out_features=2, bias=True)\n",
            "  )\n",
            "  (Mixed_7a): InceptionD(\n",
            "    (branch3x3_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_2): BasicConv2d(\n",
            "      (conv): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7x3_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7x3_2): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7x3_3): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7x3_4): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_7b): InceptionE(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_1): BasicConv2d(\n",
            "      (conv): Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_2a): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_2b): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3a): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3b): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_7c): InceptionE(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_1): BasicConv2d(\n",
            "      (conv): Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_2a): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_2b): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3a): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3b): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (fc): Linear(in_features=2048, out_features=2, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6151ULNdzuq",
        "outputId": "b8f862da-60f2-424e-ce3b-7487986aeb6e"
      },
      "source": [
        "# Send the model to GPU\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "# Gather the parameters to be optimized/updated in this run. If we are\n",
        "#  finetuning we will be updating all parameters. However, if we are\n",
        "#  doing feature extract method, we will only update the parameters\n",
        "#  that we have just initialized, i.e. the parameters with requires_grad\n",
        "#  is True.\n",
        "params_to_update = model_ft.parameters()\n",
        "print(\"Params to learn:\")\n",
        "if feature_extract:\n",
        "    params_to_update = []\n",
        "    for name,param in model_ft.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            params_to_update.append(param)\n",
        "            print(\"\\t\",name)\n",
        "else:\n",
        "    for name,param in model_ft.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            print(\"\\t\",name)\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Params to learn:\n",
            "\t Conv2d_1a_3x3.conv.weight\n",
            "\t Conv2d_1a_3x3.bn.weight\n",
            "\t Conv2d_1a_3x3.bn.bias\n",
            "\t Conv2d_2a_3x3.conv.weight\n",
            "\t Conv2d_2a_3x3.bn.weight\n",
            "\t Conv2d_2a_3x3.bn.bias\n",
            "\t Conv2d_2b_3x3.conv.weight\n",
            "\t Conv2d_2b_3x3.bn.weight\n",
            "\t Conv2d_2b_3x3.bn.bias\n",
            "\t Conv2d_3b_1x1.conv.weight\n",
            "\t Conv2d_3b_1x1.bn.weight\n",
            "\t Conv2d_3b_1x1.bn.bias\n",
            "\t Conv2d_4a_3x3.conv.weight\n",
            "\t Conv2d_4a_3x3.bn.weight\n",
            "\t Conv2d_4a_3x3.bn.bias\n",
            "\t Mixed_5b.branch1x1.conv.weight\n",
            "\t Mixed_5b.branch1x1.bn.weight\n",
            "\t Mixed_5b.branch1x1.bn.bias\n",
            "\t Mixed_5b.branch5x5_1.conv.weight\n",
            "\t Mixed_5b.branch5x5_1.bn.weight\n",
            "\t Mixed_5b.branch5x5_1.bn.bias\n",
            "\t Mixed_5b.branch5x5_2.conv.weight\n",
            "\t Mixed_5b.branch5x5_2.bn.weight\n",
            "\t Mixed_5b.branch5x5_2.bn.bias\n",
            "\t Mixed_5b.branch3x3dbl_1.conv.weight\n",
            "\t Mixed_5b.branch3x3dbl_1.bn.weight\n",
            "\t Mixed_5b.branch3x3dbl_1.bn.bias\n",
            "\t Mixed_5b.branch3x3dbl_2.conv.weight\n",
            "\t Mixed_5b.branch3x3dbl_2.bn.weight\n",
            "\t Mixed_5b.branch3x3dbl_2.bn.bias\n",
            "\t Mixed_5b.branch3x3dbl_3.conv.weight\n",
            "\t Mixed_5b.branch3x3dbl_3.bn.weight\n",
            "\t Mixed_5b.branch3x3dbl_3.bn.bias\n",
            "\t Mixed_5b.branch_pool.conv.weight\n",
            "\t Mixed_5b.branch_pool.bn.weight\n",
            "\t Mixed_5b.branch_pool.bn.bias\n",
            "\t Mixed_5c.branch1x1.conv.weight\n",
            "\t Mixed_5c.branch1x1.bn.weight\n",
            "\t Mixed_5c.branch1x1.bn.bias\n",
            "\t Mixed_5c.branch5x5_1.conv.weight\n",
            "\t Mixed_5c.branch5x5_1.bn.weight\n",
            "\t Mixed_5c.branch5x5_1.bn.bias\n",
            "\t Mixed_5c.branch5x5_2.conv.weight\n",
            "\t Mixed_5c.branch5x5_2.bn.weight\n",
            "\t Mixed_5c.branch5x5_2.bn.bias\n",
            "\t Mixed_5c.branch3x3dbl_1.conv.weight\n",
            "\t Mixed_5c.branch3x3dbl_1.bn.weight\n",
            "\t Mixed_5c.branch3x3dbl_1.bn.bias\n",
            "\t Mixed_5c.branch3x3dbl_2.conv.weight\n",
            "\t Mixed_5c.branch3x3dbl_2.bn.weight\n",
            "\t Mixed_5c.branch3x3dbl_2.bn.bias\n",
            "\t Mixed_5c.branch3x3dbl_3.conv.weight\n",
            "\t Mixed_5c.branch3x3dbl_3.bn.weight\n",
            "\t Mixed_5c.branch3x3dbl_3.bn.bias\n",
            "\t Mixed_5c.branch_pool.conv.weight\n",
            "\t Mixed_5c.branch_pool.bn.weight\n",
            "\t Mixed_5c.branch_pool.bn.bias\n",
            "\t Mixed_5d.branch1x1.conv.weight\n",
            "\t Mixed_5d.branch1x1.bn.weight\n",
            "\t Mixed_5d.branch1x1.bn.bias\n",
            "\t Mixed_5d.branch5x5_1.conv.weight\n",
            "\t Mixed_5d.branch5x5_1.bn.weight\n",
            "\t Mixed_5d.branch5x5_1.bn.bias\n",
            "\t Mixed_5d.branch5x5_2.conv.weight\n",
            "\t Mixed_5d.branch5x5_2.bn.weight\n",
            "\t Mixed_5d.branch5x5_2.bn.bias\n",
            "\t Mixed_5d.branch3x3dbl_1.conv.weight\n",
            "\t Mixed_5d.branch3x3dbl_1.bn.weight\n",
            "\t Mixed_5d.branch3x3dbl_1.bn.bias\n",
            "\t Mixed_5d.branch3x3dbl_2.conv.weight\n",
            "\t Mixed_5d.branch3x3dbl_2.bn.weight\n",
            "\t Mixed_5d.branch3x3dbl_2.bn.bias\n",
            "\t Mixed_5d.branch3x3dbl_3.conv.weight\n",
            "\t Mixed_5d.branch3x3dbl_3.bn.weight\n",
            "\t Mixed_5d.branch3x3dbl_3.bn.bias\n",
            "\t Mixed_5d.branch_pool.conv.weight\n",
            "\t Mixed_5d.branch_pool.bn.weight\n",
            "\t Mixed_5d.branch_pool.bn.bias\n",
            "\t Mixed_6a.branch3x3.conv.weight\n",
            "\t Mixed_6a.branch3x3.bn.weight\n",
            "\t Mixed_6a.branch3x3.bn.bias\n",
            "\t Mixed_6a.branch3x3dbl_1.conv.weight\n",
            "\t Mixed_6a.branch3x3dbl_1.bn.weight\n",
            "\t Mixed_6a.branch3x3dbl_1.bn.bias\n",
            "\t Mixed_6a.branch3x3dbl_2.conv.weight\n",
            "\t Mixed_6a.branch3x3dbl_2.bn.weight\n",
            "\t Mixed_6a.branch3x3dbl_2.bn.bias\n",
            "\t Mixed_6a.branch3x3dbl_3.conv.weight\n",
            "\t Mixed_6a.branch3x3dbl_3.bn.weight\n",
            "\t Mixed_6a.branch3x3dbl_3.bn.bias\n",
            "\t Mixed_6b.branch1x1.conv.weight\n",
            "\t Mixed_6b.branch1x1.bn.weight\n",
            "\t Mixed_6b.branch1x1.bn.bias\n",
            "\t Mixed_6b.branch7x7_1.conv.weight\n",
            "\t Mixed_6b.branch7x7_1.bn.weight\n",
            "\t Mixed_6b.branch7x7_1.bn.bias\n",
            "\t Mixed_6b.branch7x7_2.conv.weight\n",
            "\t Mixed_6b.branch7x7_2.bn.weight\n",
            "\t Mixed_6b.branch7x7_2.bn.bias\n",
            "\t Mixed_6b.branch7x7_3.conv.weight\n",
            "\t Mixed_6b.branch7x7_3.bn.weight\n",
            "\t Mixed_6b.branch7x7_3.bn.bias\n",
            "\t Mixed_6b.branch7x7dbl_1.conv.weight\n",
            "\t Mixed_6b.branch7x7dbl_1.bn.weight\n",
            "\t Mixed_6b.branch7x7dbl_1.bn.bias\n",
            "\t Mixed_6b.branch7x7dbl_2.conv.weight\n",
            "\t Mixed_6b.branch7x7dbl_2.bn.weight\n",
            "\t Mixed_6b.branch7x7dbl_2.bn.bias\n",
            "\t Mixed_6b.branch7x7dbl_3.conv.weight\n",
            "\t Mixed_6b.branch7x7dbl_3.bn.weight\n",
            "\t Mixed_6b.branch7x7dbl_3.bn.bias\n",
            "\t Mixed_6b.branch7x7dbl_4.conv.weight\n",
            "\t Mixed_6b.branch7x7dbl_4.bn.weight\n",
            "\t Mixed_6b.branch7x7dbl_4.bn.bias\n",
            "\t Mixed_6b.branch7x7dbl_5.conv.weight\n",
            "\t Mixed_6b.branch7x7dbl_5.bn.weight\n",
            "\t Mixed_6b.branch7x7dbl_5.bn.bias\n",
            "\t Mixed_6b.branch_pool.conv.weight\n",
            "\t Mixed_6b.branch_pool.bn.weight\n",
            "\t Mixed_6b.branch_pool.bn.bias\n",
            "\t Mixed_6c.branch1x1.conv.weight\n",
            "\t Mixed_6c.branch1x1.bn.weight\n",
            "\t Mixed_6c.branch1x1.bn.bias\n",
            "\t Mixed_6c.branch7x7_1.conv.weight\n",
            "\t Mixed_6c.branch7x7_1.bn.weight\n",
            "\t Mixed_6c.branch7x7_1.bn.bias\n",
            "\t Mixed_6c.branch7x7_2.conv.weight\n",
            "\t Mixed_6c.branch7x7_2.bn.weight\n",
            "\t Mixed_6c.branch7x7_2.bn.bias\n",
            "\t Mixed_6c.branch7x7_3.conv.weight\n",
            "\t Mixed_6c.branch7x7_3.bn.weight\n",
            "\t Mixed_6c.branch7x7_3.bn.bias\n",
            "\t Mixed_6c.branch7x7dbl_1.conv.weight\n",
            "\t Mixed_6c.branch7x7dbl_1.bn.weight\n",
            "\t Mixed_6c.branch7x7dbl_1.bn.bias\n",
            "\t Mixed_6c.branch7x7dbl_2.conv.weight\n",
            "\t Mixed_6c.branch7x7dbl_2.bn.weight\n",
            "\t Mixed_6c.branch7x7dbl_2.bn.bias\n",
            "\t Mixed_6c.branch7x7dbl_3.conv.weight\n",
            "\t Mixed_6c.branch7x7dbl_3.bn.weight\n",
            "\t Mixed_6c.branch7x7dbl_3.bn.bias\n",
            "\t Mixed_6c.branch7x7dbl_4.conv.weight\n",
            "\t Mixed_6c.branch7x7dbl_4.bn.weight\n",
            "\t Mixed_6c.branch7x7dbl_4.bn.bias\n",
            "\t Mixed_6c.branch7x7dbl_5.conv.weight\n",
            "\t Mixed_6c.branch7x7dbl_5.bn.weight\n",
            "\t Mixed_6c.branch7x7dbl_5.bn.bias\n",
            "\t Mixed_6c.branch_pool.conv.weight\n",
            "\t Mixed_6c.branch_pool.bn.weight\n",
            "\t Mixed_6c.branch_pool.bn.bias\n",
            "\t Mixed_6d.branch1x1.conv.weight\n",
            "\t Mixed_6d.branch1x1.bn.weight\n",
            "\t Mixed_6d.branch1x1.bn.bias\n",
            "\t Mixed_6d.branch7x7_1.conv.weight\n",
            "\t Mixed_6d.branch7x7_1.bn.weight\n",
            "\t Mixed_6d.branch7x7_1.bn.bias\n",
            "\t Mixed_6d.branch7x7_2.conv.weight\n",
            "\t Mixed_6d.branch7x7_2.bn.weight\n",
            "\t Mixed_6d.branch7x7_2.bn.bias\n",
            "\t Mixed_6d.branch7x7_3.conv.weight\n",
            "\t Mixed_6d.branch7x7_3.bn.weight\n",
            "\t Mixed_6d.branch7x7_3.bn.bias\n",
            "\t Mixed_6d.branch7x7dbl_1.conv.weight\n",
            "\t Mixed_6d.branch7x7dbl_1.bn.weight\n",
            "\t Mixed_6d.branch7x7dbl_1.bn.bias\n",
            "\t Mixed_6d.branch7x7dbl_2.conv.weight\n",
            "\t Mixed_6d.branch7x7dbl_2.bn.weight\n",
            "\t Mixed_6d.branch7x7dbl_2.bn.bias\n",
            "\t Mixed_6d.branch7x7dbl_3.conv.weight\n",
            "\t Mixed_6d.branch7x7dbl_3.bn.weight\n",
            "\t Mixed_6d.branch7x7dbl_3.bn.bias\n",
            "\t Mixed_6d.branch7x7dbl_4.conv.weight\n",
            "\t Mixed_6d.branch7x7dbl_4.bn.weight\n",
            "\t Mixed_6d.branch7x7dbl_4.bn.bias\n",
            "\t Mixed_6d.branch7x7dbl_5.conv.weight\n",
            "\t Mixed_6d.branch7x7dbl_5.bn.weight\n",
            "\t Mixed_6d.branch7x7dbl_5.bn.bias\n",
            "\t Mixed_6d.branch_pool.conv.weight\n",
            "\t Mixed_6d.branch_pool.bn.weight\n",
            "\t Mixed_6d.branch_pool.bn.bias\n",
            "\t Mixed_6e.branch1x1.conv.weight\n",
            "\t Mixed_6e.branch1x1.bn.weight\n",
            "\t Mixed_6e.branch1x1.bn.bias\n",
            "\t Mixed_6e.branch7x7_1.conv.weight\n",
            "\t Mixed_6e.branch7x7_1.bn.weight\n",
            "\t Mixed_6e.branch7x7_1.bn.bias\n",
            "\t Mixed_6e.branch7x7_2.conv.weight\n",
            "\t Mixed_6e.branch7x7_2.bn.weight\n",
            "\t Mixed_6e.branch7x7_2.bn.bias\n",
            "\t Mixed_6e.branch7x7_3.conv.weight\n",
            "\t Mixed_6e.branch7x7_3.bn.weight\n",
            "\t Mixed_6e.branch7x7_3.bn.bias\n",
            "\t Mixed_6e.branch7x7dbl_1.conv.weight\n",
            "\t Mixed_6e.branch7x7dbl_1.bn.weight\n",
            "\t Mixed_6e.branch7x7dbl_1.bn.bias\n",
            "\t Mixed_6e.branch7x7dbl_2.conv.weight\n",
            "\t Mixed_6e.branch7x7dbl_2.bn.weight\n",
            "\t Mixed_6e.branch7x7dbl_2.bn.bias\n",
            "\t Mixed_6e.branch7x7dbl_3.conv.weight\n",
            "\t Mixed_6e.branch7x7dbl_3.bn.weight\n",
            "\t Mixed_6e.branch7x7dbl_3.bn.bias\n",
            "\t Mixed_6e.branch7x7dbl_4.conv.weight\n",
            "\t Mixed_6e.branch7x7dbl_4.bn.weight\n",
            "\t Mixed_6e.branch7x7dbl_4.bn.bias\n",
            "\t Mixed_6e.branch7x7dbl_5.conv.weight\n",
            "\t Mixed_6e.branch7x7dbl_5.bn.weight\n",
            "\t Mixed_6e.branch7x7dbl_5.bn.bias\n",
            "\t Mixed_6e.branch_pool.conv.weight\n",
            "\t Mixed_6e.branch_pool.bn.weight\n",
            "\t Mixed_6e.branch_pool.bn.bias\n",
            "\t AuxLogits.conv0.conv.weight\n",
            "\t AuxLogits.conv0.bn.weight\n",
            "\t AuxLogits.conv0.bn.bias\n",
            "\t AuxLogits.conv1.conv.weight\n",
            "\t AuxLogits.conv1.bn.weight\n",
            "\t AuxLogits.conv1.bn.bias\n",
            "\t AuxLogits.fc.weight\n",
            "\t AuxLogits.fc.bias\n",
            "\t Mixed_7a.branch3x3_1.conv.weight\n",
            "\t Mixed_7a.branch3x3_1.bn.weight\n",
            "\t Mixed_7a.branch3x3_1.bn.bias\n",
            "\t Mixed_7a.branch3x3_2.conv.weight\n",
            "\t Mixed_7a.branch3x3_2.bn.weight\n",
            "\t Mixed_7a.branch3x3_2.bn.bias\n",
            "\t Mixed_7a.branch7x7x3_1.conv.weight\n",
            "\t Mixed_7a.branch7x7x3_1.bn.weight\n",
            "\t Mixed_7a.branch7x7x3_1.bn.bias\n",
            "\t Mixed_7a.branch7x7x3_2.conv.weight\n",
            "\t Mixed_7a.branch7x7x3_2.bn.weight\n",
            "\t Mixed_7a.branch7x7x3_2.bn.bias\n",
            "\t Mixed_7a.branch7x7x3_3.conv.weight\n",
            "\t Mixed_7a.branch7x7x3_3.bn.weight\n",
            "\t Mixed_7a.branch7x7x3_3.bn.bias\n",
            "\t Mixed_7a.branch7x7x3_4.conv.weight\n",
            "\t Mixed_7a.branch7x7x3_4.bn.weight\n",
            "\t Mixed_7a.branch7x7x3_4.bn.bias\n",
            "\t Mixed_7b.branch1x1.conv.weight\n",
            "\t Mixed_7b.branch1x1.bn.weight\n",
            "\t Mixed_7b.branch1x1.bn.bias\n",
            "\t Mixed_7b.branch3x3_1.conv.weight\n",
            "\t Mixed_7b.branch3x3_1.bn.weight\n",
            "\t Mixed_7b.branch3x3_1.bn.bias\n",
            "\t Mixed_7b.branch3x3_2a.conv.weight\n",
            "\t Mixed_7b.branch3x3_2a.bn.weight\n",
            "\t Mixed_7b.branch3x3_2a.bn.bias\n",
            "\t Mixed_7b.branch3x3_2b.conv.weight\n",
            "\t Mixed_7b.branch3x3_2b.bn.weight\n",
            "\t Mixed_7b.branch3x3_2b.bn.bias\n",
            "\t Mixed_7b.branch3x3dbl_1.conv.weight\n",
            "\t Mixed_7b.branch3x3dbl_1.bn.weight\n",
            "\t Mixed_7b.branch3x3dbl_1.bn.bias\n",
            "\t Mixed_7b.branch3x3dbl_2.conv.weight\n",
            "\t Mixed_7b.branch3x3dbl_2.bn.weight\n",
            "\t Mixed_7b.branch3x3dbl_2.bn.bias\n",
            "\t Mixed_7b.branch3x3dbl_3a.conv.weight\n",
            "\t Mixed_7b.branch3x3dbl_3a.bn.weight\n",
            "\t Mixed_7b.branch3x3dbl_3a.bn.bias\n",
            "\t Mixed_7b.branch3x3dbl_3b.conv.weight\n",
            "\t Mixed_7b.branch3x3dbl_3b.bn.weight\n",
            "\t Mixed_7b.branch3x3dbl_3b.bn.bias\n",
            "\t Mixed_7b.branch_pool.conv.weight\n",
            "\t Mixed_7b.branch_pool.bn.weight\n",
            "\t Mixed_7b.branch_pool.bn.bias\n",
            "\t Mixed_7c.branch1x1.conv.weight\n",
            "\t Mixed_7c.branch1x1.bn.weight\n",
            "\t Mixed_7c.branch1x1.bn.bias\n",
            "\t Mixed_7c.branch3x3_1.conv.weight\n",
            "\t Mixed_7c.branch3x3_1.bn.weight\n",
            "\t Mixed_7c.branch3x3_1.bn.bias\n",
            "\t Mixed_7c.branch3x3_2a.conv.weight\n",
            "\t Mixed_7c.branch3x3_2a.bn.weight\n",
            "\t Mixed_7c.branch3x3_2a.bn.bias\n",
            "\t Mixed_7c.branch3x3_2b.conv.weight\n",
            "\t Mixed_7c.branch3x3_2b.bn.weight\n",
            "\t Mixed_7c.branch3x3_2b.bn.bias\n",
            "\t Mixed_7c.branch3x3dbl_1.conv.weight\n",
            "\t Mixed_7c.branch3x3dbl_1.bn.weight\n",
            "\t Mixed_7c.branch3x3dbl_1.bn.bias\n",
            "\t Mixed_7c.branch3x3dbl_2.conv.weight\n",
            "\t Mixed_7c.branch3x3dbl_2.bn.weight\n",
            "\t Mixed_7c.branch3x3dbl_2.bn.bias\n",
            "\t Mixed_7c.branch3x3dbl_3a.conv.weight\n",
            "\t Mixed_7c.branch3x3dbl_3a.bn.weight\n",
            "\t Mixed_7c.branch3x3dbl_3a.bn.bias\n",
            "\t Mixed_7c.branch3x3dbl_3b.conv.weight\n",
            "\t Mixed_7c.branch3x3dbl_3b.bn.weight\n",
            "\t Mixed_7c.branch3x3dbl_3b.bn.bias\n",
            "\t Mixed_7c.branch_pool.conv.weight\n",
            "\t Mixed_7c.branch_pool.bn.weight\n",
            "\t Mixed_7c.branch_pool.bn.bias\n",
            "\t fc.weight\n",
            "\t fc.bias\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXg5BAG1oo-f",
        "outputId": "1d0c9413-94c0-4f49-c7bd-b3a9b9608b41"
      },
      "source": [
        "# Setup the loss fxn\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Train and evaluate\n",
        "model_ft, hist = train_model(model_ft, dataloaders, criterion, optimizer_ft, num_epochs=num_epochs, is_inception=(model_name==\"inception\"))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/9\n",
            "----------\n",
            "train Loss: 0.9839 Acc: 0.4667\n",
            "val Loss: 0.7153 Acc: 0.3231\n",
            "\n",
            "Epoch 1/9\n",
            "----------\n",
            "train Loss: 0.9071 Acc: 0.5821\n",
            "val Loss: 0.6641 Acc: 0.5538\n",
            "\n",
            "Epoch 2/9\n",
            "----------\n",
            "train Loss: 0.8434 Acc: 0.6231\n",
            "val Loss: 0.6444 Acc: 0.6538\n",
            "\n",
            "Epoch 3/9\n",
            "----------\n",
            "train Loss: 0.8344 Acc: 0.6590\n",
            "val Loss: 0.6478 Acc: 0.6692\n",
            "\n",
            "Epoch 4/9\n",
            "----------\n",
            "train Loss: 0.7994 Acc: 0.6769\n",
            "val Loss: 0.6522 Acc: 0.6000\n",
            "\n",
            "Epoch 5/9\n",
            "----------\n",
            "train Loss: 0.7800 Acc: 0.6949\n",
            "val Loss: 0.5245 Acc: 0.7308\n",
            "\n",
            "Epoch 6/9\n",
            "----------\n",
            "train Loss: 0.7097 Acc: 0.7385\n",
            "val Loss: 0.7904 Acc: 0.5538\n",
            "\n",
            "Epoch 7/9\n",
            "----------\n",
            "train Loss: 0.6900 Acc: 0.7538\n",
            "val Loss: 0.6841 Acc: 0.6308\n",
            "\n",
            "Epoch 8/9\n",
            "----------\n",
            "train Loss: 0.6726 Acc: 0.7333\n",
            "val Loss: 0.8165 Acc: 0.5385\n",
            "\n",
            "Epoch 9/9\n",
            "----------\n",
            "train Loss: 0.6428 Acc: 0.7795\n",
            "val Loss: 0.5280 Acc: 0.7308\n",
            "\n",
            "Training complete in 15m 1s\n",
            "Best val Acc: 0.730769\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgYraiAjiys8"
      },
      "source": [
        "torch.save(model_ft,'/content/drive/MyDrive/saved_models/'+model_name+'glaucoma_ben_inception_kaggle.h5')"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpGRminVjRIY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "outputId": "f909f7e0-4c1e-42d3-c90c-01618de9ba98"
      },
      "source": [
        "import seaborn as sns\n",
        "nb_classes = num_classes\n",
        "confusion_matrix = np.zeros((nb_classes, nb_classes))\n",
        "with torch.no_grad():\n",
        "    for i, (inputs, classes) in enumerate(dataloaders['test']):\n",
        "        inputs = inputs.to(device)\n",
        "        classes = classes.to(device)\n",
        "        outputs = model_ft(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        for t, p in zip(classes.view(-1), preds.view(-1)):\n",
        "                confusion_matrix[t.long(), p.long()] += 1\n",
        "\n",
        "plt.figure(figsize=(15,10))\n",
        "\n",
        "class_names = ['Normal', 'Glaucoma']\n",
        "df_cm = pd.DataFrame(confusion_matrix, index=class_names, columns=class_names).astype(int)\n",
        "heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
        "\n",
        "heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right',fontsize=15)\n",
        "heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right',fontsize=15)\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 69.0, 'Predicted label')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x720 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Emzn5VAnJKU"
      },
      "source": [
        ""
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EyL4HDhTKDa"
      },
      "source": [
        ""
      ],
      "execution_count": 49,
      "outputs": []
    }
  ]
}