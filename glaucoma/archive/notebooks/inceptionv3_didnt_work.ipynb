{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "inceptionv3_ben.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqHnaptr-kuA",
        "outputId": "13bb636c-5984-411a-d49a-ad6c41ac7f90"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri May  7 08:37:40 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   60C    P0    56W / 149W |   4062MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7-9XFsaZnKQ"
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oGJ2hstm39V"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from imutils import contours\n",
        "from skimage import measure\n",
        "import imutils\n",
        "import os\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import copy\n",
        "import time\n",
        "\n",
        "import torch\n",
        "from torchvision import datasets, models, transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader, Dataset, TensorDataset, Subset, WeightedRandomSampler\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import pickle"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMzw_DRLY1VG"
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u899MaWr-ZF0"
      },
      "source": [
        "# Top level data directory. Here we assume the format of the directory conforms\n",
        "#   to the ImageFolder structure\n",
        "data_dir = '/content/drive/MyDrive/disk_dataset'\n",
        "\n",
        "# Models to choose from [resnet, alexnet, vgg, squeezenet, densenet, inception]\n",
        "model_name = \"inception\"\n",
        "# inception\n",
        "input_size = 299\n",
        "\n",
        "# Number of classes in the dataset\n",
        "num_classes = 2\n",
        "\n",
        "# Batch size for training (change depending on how much memory you have)\n",
        "batch_size = 16\n",
        "\n",
        "# Number of epochs to train for\n",
        "num_epochs = 10\n",
        "\n",
        "# Flag for feature extracting. When False, we finetune the whole model,\n",
        "#   when True we only update the reshaped layer params\n",
        "feature_extract = False\n",
        "\n",
        "num_workers = 2\n",
        "\n",
        "train_size = 0.60\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYnO7mxJZywE"
      },
      "source": [
        "\n",
        "class ben_color(object):\n",
        "    def __call__(self, img, sigmaX=10):\n",
        "        \"\"\"\n",
        "        :param img: PIL): Image \n",
        "\n",
        "        :return: Normalized image\n",
        "        \"\"\"\n",
        "\n",
        "        img = np.asarray(img)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        img = self.crop_image_from_gray(img)\n",
        "        img = cv2.resize(img, (input_size, input_size))\n",
        "        img = cv2.addWeighted (img, 4, cv2.GaussianBlur(img, (0,0), sigmaX), -4, 128)\n",
        "        return Image.fromarray(img)\n",
        "\n",
        "    def crop_image_from_gray(self, img, tol=7):\n",
        "        if img.ndim ==2:\n",
        "            mask = img>tol\n",
        "            return img[np.ix_(mask.any(1),mask.any(0))]\n",
        "        elif img.ndim==3:\n",
        "            gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "            mask = gray_img>tol\n",
        "            \n",
        "            check_shape = img[:,:,0][np.ix_(mask.any(1),mask.any(0))].shape[0]\n",
        "            if (check_shape == 0):\n",
        "                return img \n",
        "            else:\n",
        "                img1=img[:,:,0][np.ix_(mask.any(1),mask.any(0))]\n",
        "                img2=img[:,:,1][np.ix_(mask.any(1),mask.any(0))]\n",
        "                img3=img[:,:,2][np.ix_(mask.any(1),mask.any(0))]\n",
        "                img = np.stack([img1,img2,img3],axis=-1)\n",
        "            return img\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__+'()'"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jj74frLDrZd"
      },
      "source": [
        "# Todos: shuffle in validation set\n",
        "# add more augmentations  \n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "        # ben_color(),\n",
        "        transforms.RandomRotation(degrees=(0, 360)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.Resize((input_size, input_size)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "\n",
        "\n",
        "valid_transform = transforms.Compose([\n",
        "        # ben_color(),\n",
        "        transforms.Resize((input_size, input_size)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "\n",
        "\n",
        "class DR(Dataset):\n",
        "    def __init__(self, dataset, transform=None):\n",
        "        self.dataset = dataset\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        if self.transform:\n",
        "            x = self.transform(dataset[index][0])\n",
        "        else:\n",
        "            x = dataset[index][0]\n",
        "        y = dataset[index][1]\n",
        "        return x, y\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(dataset)\n",
        "    \n",
        "\n",
        "dataset = ImageFolder(data_dir)\n",
        "\n",
        "traindataset = DR(dataset, train_transform)\n",
        "valdataset = DR(dataset, valid_transform)\n",
        "testdataset = DR(dataset, valid_transform)\n",
        "\n",
        "# Create the index splits for training, validation and test\n",
        "\n",
        "num_train = len(dataset)\n",
        "indices = list(range(num_train))\n",
        "split = int(np.floor(train_size * num_train))\n",
        "split2 = int(np.floor((train_size+(1-train_size)/2) * num_train))\n",
        "np.random.shuffle(indices)\n",
        "train_idx, valid_idx, test_idx = indices[:split], indices[split:split2], indices[split2:]\n",
        "\n",
        "traindata = Subset(traindataset, indices=train_idx)\n",
        "valdata = Subset(valdataset, indices=valid_idx)\n",
        "testdata = Subset(testdataset, indices=test_idx)\n",
        "\n",
        "class_weights = []\n",
        "for root, subdir, files in os.walk(data_dir):\n",
        "  if len(files)>0:\n",
        "    class_weights.append(1/len(files))\n",
        "\n",
        "sample_weights = [0] * len(traindata)\n",
        "\n",
        "for idx, (data, label) in enumerate(traindata):\n",
        "  class_weight = class_weights[label]\n",
        "  sample_weights[idx] = class_weight\n",
        "\n",
        "\n",
        "with open('/content/drive/MyDrive/clean_weights.pkl', 'wb') as f:\n",
        "  pickle.dump(sample_weights, f)\n",
        "\n",
        "with open('/content/drive/MyDrive/clean_weights.pkl', 'rb') as f:\n",
        "  sample_weights = pickle.load(f)\n",
        "\n",
        "sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)\n",
        "\n",
        "trainLoader = torch.utils.data.DataLoader(traindata, batch_size=batch_size, \n",
        "                                          num_workers=num_workers, drop_last=True)\n",
        "valLoader = torch.utils.data.DataLoader(valdata, batch_size=batch_size, \n",
        "                                          num_workers=num_workers, drop_last=True)\n",
        "testLoader = torch.utils.data.DataLoader(testdata, batch_size=batch_size,\n",
        "                                          num_workers=num_workers, drop_last=True)\n",
        "dataloaders = {'train': trainLoader, 'val': valLoader, 'test': testLoader}"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyThMaR4nbLF"
      },
      "source": [
        "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False):\n",
        "    since = time.time()\n",
        "\n",
        "    val_acc_history = []\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    # Get model outputs and calculate loss\n",
        "                    # Special case for inception because in training it has an auxiliary output. In train\n",
        "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
        "                    #   but in testing we only consider the final output.\n",
        "                    if is_inception and phase == 'train':\n",
        "                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
        "                        outputs, aux_outputs = model(inputs)\n",
        "                        loss1 = criterion(outputs, labels)\n",
        "                        loss2 = criterion(aux_outputs, labels)\n",
        "                        loss = loss1 + 0.4*loss2\n",
        "                    else:\n",
        "                        outputs = model(inputs)\n",
        "                        loss = criterion(outputs, labels)\n",
        "\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
        "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            if phase == 'val':\n",
        "                val_acc_history.append(epoch_acc)\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, val_acc_history"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75VdlQ8ln1a9"
      },
      "source": [
        "def set_parameter_requires_grad(model, feature_extracting):\n",
        "    if feature_extracting:\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4O8Uqptn8Sb",
        "outputId": "cd0447ea-dd95-4636-e24f-657fe3866c55"
      },
      "source": [
        "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
        "    # Initialize these variables which will be set in this if statement. Each of these\n",
        "    #   variables is model specific.\n",
        "    model_ft = None\n",
        "    input_size = 0\n",
        "\n",
        "    if model_name == \"resnet\":\n",
        "        \"\"\" Resnet18\n",
        "        \"\"\"\n",
        "        model_ft = models.resnet18(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.fc.in_features\n",
        "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"alexnet\":\n",
        "        \"\"\" Alexnet\n",
        "        \"\"\"\n",
        "        model_ft = models.alexnet(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.classifier[6].in_features\n",
        "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"vgg\":\n",
        "        \"\"\" VGG11_bn\n",
        "        \"\"\"\n",
        "        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.classifier[6].in_features\n",
        "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"squeezenet\":\n",
        "        \"\"\" Squeezenet\n",
        "        \"\"\"\n",
        "        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
        "        model_ft.num_classes = num_classes\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"densenet\":\n",
        "        \"\"\" Densenet\n",
        "        \"\"\"\n",
        "        model_ft = models.densenet121(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.classifier.in_features\n",
        "        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"inception\":\n",
        "        \"\"\" Inception v3\n",
        "        Be careful, expects (299,299) sized images and has auxiliary output\n",
        "        \"\"\"\n",
        "        model_ft = models.inception_v3(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        # Handle the auxilary net\n",
        "        num_ftrs = model_ft.AuxLogits.fc.in_features\n",
        "        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n",
        "        # Handle the primary net\n",
        "        num_ftrs = model_ft.fc.in_features\n",
        "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
        "        input_size = 299\n",
        "\n",
        "    else:\n",
        "        print(\"Invalid model name, exiting...\")\n",
        "        exit()\n",
        "\n",
        "    return model_ft, input_size\n",
        "\n",
        "# Initialize the model for this run\n",
        "model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n",
        "\n",
        "# Print the model we just instantiated\n",
        "print(model_ft)"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Inception3(\n",
            "  (Conv2d_1a_3x3): BasicConv2d(\n",
            "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
            "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (Conv2d_2a_3x3): BasicConv2d(\n",
            "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (Conv2d_2b_3x3): BasicConv2d(\n",
            "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (Conv2d_3b_1x1): BasicConv2d(\n",
            "    (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (Conv2d_4a_3x3): BasicConv2d(\n",
            "    (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (Mixed_5b): InceptionA(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_1): BasicConv2d(\n",
            "      (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_2): BasicConv2d(\n",
            "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_5c): InceptionA(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_1): BasicConv2d(\n",
            "      (conv): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_2): BasicConv2d(\n",
            "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_5d): InceptionA(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_1): BasicConv2d(\n",
            "      (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_2): BasicConv2d(\n",
            "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_6a): InceptionB(\n",
            "    (branch3x3): BasicConv2d(\n",
            "      (conv): Conv2d(288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_6b): InceptionC(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_2): BasicConv2d(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_3): BasicConv2d(\n",
            "      (conv): Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_4): BasicConv2d(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_5): BasicConv2d(\n",
            "      (conv): Conv2d(128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_6c): InceptionC(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_2): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_3): BasicConv2d(\n",
            "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_4): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_5): BasicConv2d(\n",
            "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_6d): InceptionC(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_2): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_3): BasicConv2d(\n",
            "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_4): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_5): BasicConv2d(\n",
            "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_6e): InceptionC(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_2): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_3): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_4): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_5): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (AuxLogits): InceptionAux(\n",
            "    (conv0): BasicConv2d(\n",
            "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (conv1): BasicConv2d(\n",
            "      (conv): Conv2d(128, 768, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fc): Linear(in_features=768, out_features=2, bias=True)\n",
            "  )\n",
            "  (Mixed_7a): InceptionD(\n",
            "    (branch3x3_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_2): BasicConv2d(\n",
            "      (conv): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7x3_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7x3_2): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7x3_3): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7x3_4): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_7b): InceptionE(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_1): BasicConv2d(\n",
            "      (conv): Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_2a): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_2b): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3a): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3b): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_7c): InceptionE(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_1): BasicConv2d(\n",
            "      (conv): Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_2a): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_2b): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3a): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3b): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (fc): Linear(in_features=2048, out_features=2, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6151ULNdzuq",
        "outputId": "2f0040d4-0543-4449-e0ec-da46cc144b05"
      },
      "source": [
        "# Send the model to GPU\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "# Gather the parameters to be optimized/updated in this run. If we are\n",
        "#  finetuning we will be updating all parameters. However, if we are\n",
        "#  doing feature extract method, we will only update the parameters\n",
        "#  that we have just initialized, i.e. the parameters with requires_grad\n",
        "#  is True.\n",
        "params_to_update = model_ft.parameters()\n",
        "print(\"Params to learn:\")\n",
        "if feature_extract:\n",
        "    params_to_update = []\n",
        "    for name,param in model_ft.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            params_to_update.append(param)\n",
        "            print(\"\\t\",name)\n",
        "else:\n",
        "    for name,param in model_ft.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            print(\"\\t\",name)\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Params to learn:\n",
            "\t Conv2d_1a_3x3.conv.weight\n",
            "\t Conv2d_1a_3x3.bn.weight\n",
            "\t Conv2d_1a_3x3.bn.bias\n",
            "\t Conv2d_2a_3x3.conv.weight\n",
            "\t Conv2d_2a_3x3.bn.weight\n",
            "\t Conv2d_2a_3x3.bn.bias\n",
            "\t Conv2d_2b_3x3.conv.weight\n",
            "\t Conv2d_2b_3x3.bn.weight\n",
            "\t Conv2d_2b_3x3.bn.bias\n",
            "\t Conv2d_3b_1x1.conv.weight\n",
            "\t Conv2d_3b_1x1.bn.weight\n",
            "\t Conv2d_3b_1x1.bn.bias\n",
            "\t Conv2d_4a_3x3.conv.weight\n",
            "\t Conv2d_4a_3x3.bn.weight\n",
            "\t Conv2d_4a_3x3.bn.bias\n",
            "\t Mixed_5b.branch1x1.conv.weight\n",
            "\t Mixed_5b.branch1x1.bn.weight\n",
            "\t Mixed_5b.branch1x1.bn.bias\n",
            "\t Mixed_5b.branch5x5_1.conv.weight\n",
            "\t Mixed_5b.branch5x5_1.bn.weight\n",
            "\t Mixed_5b.branch5x5_1.bn.bias\n",
            "\t Mixed_5b.branch5x5_2.conv.weight\n",
            "\t Mixed_5b.branch5x5_2.bn.weight\n",
            "\t Mixed_5b.branch5x5_2.bn.bias\n",
            "\t Mixed_5b.branch3x3dbl_1.conv.weight\n",
            "\t Mixed_5b.branch3x3dbl_1.bn.weight\n",
            "\t Mixed_5b.branch3x3dbl_1.bn.bias\n",
            "\t Mixed_5b.branch3x3dbl_2.conv.weight\n",
            "\t Mixed_5b.branch3x3dbl_2.bn.weight\n",
            "\t Mixed_5b.branch3x3dbl_2.bn.bias\n",
            "\t Mixed_5b.branch3x3dbl_3.conv.weight\n",
            "\t Mixed_5b.branch3x3dbl_3.bn.weight\n",
            "\t Mixed_5b.branch3x3dbl_3.bn.bias\n",
            "\t Mixed_5b.branch_pool.conv.weight\n",
            "\t Mixed_5b.branch_pool.bn.weight\n",
            "\t Mixed_5b.branch_pool.bn.bias\n",
            "\t Mixed_5c.branch1x1.conv.weight\n",
            "\t Mixed_5c.branch1x1.bn.weight\n",
            "\t Mixed_5c.branch1x1.bn.bias\n",
            "\t Mixed_5c.branch5x5_1.conv.weight\n",
            "\t Mixed_5c.branch5x5_1.bn.weight\n",
            "\t Mixed_5c.branch5x5_1.bn.bias\n",
            "\t Mixed_5c.branch5x5_2.conv.weight\n",
            "\t Mixed_5c.branch5x5_2.bn.weight\n",
            "\t Mixed_5c.branch5x5_2.bn.bias\n",
            "\t Mixed_5c.branch3x3dbl_1.conv.weight\n",
            "\t Mixed_5c.branch3x3dbl_1.bn.weight\n",
            "\t Mixed_5c.branch3x3dbl_1.bn.bias\n",
            "\t Mixed_5c.branch3x3dbl_2.conv.weight\n",
            "\t Mixed_5c.branch3x3dbl_2.bn.weight\n",
            "\t Mixed_5c.branch3x3dbl_2.bn.bias\n",
            "\t Mixed_5c.branch3x3dbl_3.conv.weight\n",
            "\t Mixed_5c.branch3x3dbl_3.bn.weight\n",
            "\t Mixed_5c.branch3x3dbl_3.bn.bias\n",
            "\t Mixed_5c.branch_pool.conv.weight\n",
            "\t Mixed_5c.branch_pool.bn.weight\n",
            "\t Mixed_5c.branch_pool.bn.bias\n",
            "\t Mixed_5d.branch1x1.conv.weight\n",
            "\t Mixed_5d.branch1x1.bn.weight\n",
            "\t Mixed_5d.branch1x1.bn.bias\n",
            "\t Mixed_5d.branch5x5_1.conv.weight\n",
            "\t Mixed_5d.branch5x5_1.bn.weight\n",
            "\t Mixed_5d.branch5x5_1.bn.bias\n",
            "\t Mixed_5d.branch5x5_2.conv.weight\n",
            "\t Mixed_5d.branch5x5_2.bn.weight\n",
            "\t Mixed_5d.branch5x5_2.bn.bias\n",
            "\t Mixed_5d.branch3x3dbl_1.conv.weight\n",
            "\t Mixed_5d.branch3x3dbl_1.bn.weight\n",
            "\t Mixed_5d.branch3x3dbl_1.bn.bias\n",
            "\t Mixed_5d.branch3x3dbl_2.conv.weight\n",
            "\t Mixed_5d.branch3x3dbl_2.bn.weight\n",
            "\t Mixed_5d.branch3x3dbl_2.bn.bias\n",
            "\t Mixed_5d.branch3x3dbl_3.conv.weight\n",
            "\t Mixed_5d.branch3x3dbl_3.bn.weight\n",
            "\t Mixed_5d.branch3x3dbl_3.bn.bias\n",
            "\t Mixed_5d.branch_pool.conv.weight\n",
            "\t Mixed_5d.branch_pool.bn.weight\n",
            "\t Mixed_5d.branch_pool.bn.bias\n",
            "\t Mixed_6a.branch3x3.conv.weight\n",
            "\t Mixed_6a.branch3x3.bn.weight\n",
            "\t Mixed_6a.branch3x3.bn.bias\n",
            "\t Mixed_6a.branch3x3dbl_1.conv.weight\n",
            "\t Mixed_6a.branch3x3dbl_1.bn.weight\n",
            "\t Mixed_6a.branch3x3dbl_1.bn.bias\n",
            "\t Mixed_6a.branch3x3dbl_2.conv.weight\n",
            "\t Mixed_6a.branch3x3dbl_2.bn.weight\n",
            "\t Mixed_6a.branch3x3dbl_2.bn.bias\n",
            "\t Mixed_6a.branch3x3dbl_3.conv.weight\n",
            "\t Mixed_6a.branch3x3dbl_3.bn.weight\n",
            "\t Mixed_6a.branch3x3dbl_3.bn.bias\n",
            "\t Mixed_6b.branch1x1.conv.weight\n",
            "\t Mixed_6b.branch1x1.bn.weight\n",
            "\t Mixed_6b.branch1x1.bn.bias\n",
            "\t Mixed_6b.branch7x7_1.conv.weight\n",
            "\t Mixed_6b.branch7x7_1.bn.weight\n",
            "\t Mixed_6b.branch7x7_1.bn.bias\n",
            "\t Mixed_6b.branch7x7_2.conv.weight\n",
            "\t Mixed_6b.branch7x7_2.bn.weight\n",
            "\t Mixed_6b.branch7x7_2.bn.bias\n",
            "\t Mixed_6b.branch7x7_3.conv.weight\n",
            "\t Mixed_6b.branch7x7_3.bn.weight\n",
            "\t Mixed_6b.branch7x7_3.bn.bias\n",
            "\t Mixed_6b.branch7x7dbl_1.conv.weight\n",
            "\t Mixed_6b.branch7x7dbl_1.bn.weight\n",
            "\t Mixed_6b.branch7x7dbl_1.bn.bias\n",
            "\t Mixed_6b.branch7x7dbl_2.conv.weight\n",
            "\t Mixed_6b.branch7x7dbl_2.bn.weight\n",
            "\t Mixed_6b.branch7x7dbl_2.bn.bias\n",
            "\t Mixed_6b.branch7x7dbl_3.conv.weight\n",
            "\t Mixed_6b.branch7x7dbl_3.bn.weight\n",
            "\t Mixed_6b.branch7x7dbl_3.bn.bias\n",
            "\t Mixed_6b.branch7x7dbl_4.conv.weight\n",
            "\t Mixed_6b.branch7x7dbl_4.bn.weight\n",
            "\t Mixed_6b.branch7x7dbl_4.bn.bias\n",
            "\t Mixed_6b.branch7x7dbl_5.conv.weight\n",
            "\t Mixed_6b.branch7x7dbl_5.bn.weight\n",
            "\t Mixed_6b.branch7x7dbl_5.bn.bias\n",
            "\t Mixed_6b.branch_pool.conv.weight\n",
            "\t Mixed_6b.branch_pool.bn.weight\n",
            "\t Mixed_6b.branch_pool.bn.bias\n",
            "\t Mixed_6c.branch1x1.conv.weight\n",
            "\t Mixed_6c.branch1x1.bn.weight\n",
            "\t Mixed_6c.branch1x1.bn.bias\n",
            "\t Mixed_6c.branch7x7_1.conv.weight\n",
            "\t Mixed_6c.branch7x7_1.bn.weight\n",
            "\t Mixed_6c.branch7x7_1.bn.bias\n",
            "\t Mixed_6c.branch7x7_2.conv.weight\n",
            "\t Mixed_6c.branch7x7_2.bn.weight\n",
            "\t Mixed_6c.branch7x7_2.bn.bias\n",
            "\t Mixed_6c.branch7x7_3.conv.weight\n",
            "\t Mixed_6c.branch7x7_3.bn.weight\n",
            "\t Mixed_6c.branch7x7_3.bn.bias\n",
            "\t Mixed_6c.branch7x7dbl_1.conv.weight\n",
            "\t Mixed_6c.branch7x7dbl_1.bn.weight\n",
            "\t Mixed_6c.branch7x7dbl_1.bn.bias\n",
            "\t Mixed_6c.branch7x7dbl_2.conv.weight\n",
            "\t Mixed_6c.branch7x7dbl_2.bn.weight\n",
            "\t Mixed_6c.branch7x7dbl_2.bn.bias\n",
            "\t Mixed_6c.branch7x7dbl_3.conv.weight\n",
            "\t Mixed_6c.branch7x7dbl_3.bn.weight\n",
            "\t Mixed_6c.branch7x7dbl_3.bn.bias\n",
            "\t Mixed_6c.branch7x7dbl_4.conv.weight\n",
            "\t Mixed_6c.branch7x7dbl_4.bn.weight\n",
            "\t Mixed_6c.branch7x7dbl_4.bn.bias\n",
            "\t Mixed_6c.branch7x7dbl_5.conv.weight\n",
            "\t Mixed_6c.branch7x7dbl_5.bn.weight\n",
            "\t Mixed_6c.branch7x7dbl_5.bn.bias\n",
            "\t Mixed_6c.branch_pool.conv.weight\n",
            "\t Mixed_6c.branch_pool.bn.weight\n",
            "\t Mixed_6c.branch_pool.bn.bias\n",
            "\t Mixed_6d.branch1x1.conv.weight\n",
            "\t Mixed_6d.branch1x1.bn.weight\n",
            "\t Mixed_6d.branch1x1.bn.bias\n",
            "\t Mixed_6d.branch7x7_1.conv.weight\n",
            "\t Mixed_6d.branch7x7_1.bn.weight\n",
            "\t Mixed_6d.branch7x7_1.bn.bias\n",
            "\t Mixed_6d.branch7x7_2.conv.weight\n",
            "\t Mixed_6d.branch7x7_2.bn.weight\n",
            "\t Mixed_6d.branch7x7_2.bn.bias\n",
            "\t Mixed_6d.branch7x7_3.conv.weight\n",
            "\t Mixed_6d.branch7x7_3.bn.weight\n",
            "\t Mixed_6d.branch7x7_3.bn.bias\n",
            "\t Mixed_6d.branch7x7dbl_1.conv.weight\n",
            "\t Mixed_6d.branch7x7dbl_1.bn.weight\n",
            "\t Mixed_6d.branch7x7dbl_1.bn.bias\n",
            "\t Mixed_6d.branch7x7dbl_2.conv.weight\n",
            "\t Mixed_6d.branch7x7dbl_2.bn.weight\n",
            "\t Mixed_6d.branch7x7dbl_2.bn.bias\n",
            "\t Mixed_6d.branch7x7dbl_3.conv.weight\n",
            "\t Mixed_6d.branch7x7dbl_3.bn.weight\n",
            "\t Mixed_6d.branch7x7dbl_3.bn.bias\n",
            "\t Mixed_6d.branch7x7dbl_4.conv.weight\n",
            "\t Mixed_6d.branch7x7dbl_4.bn.weight\n",
            "\t Mixed_6d.branch7x7dbl_4.bn.bias\n",
            "\t Mixed_6d.branch7x7dbl_5.conv.weight\n",
            "\t Mixed_6d.branch7x7dbl_5.bn.weight\n",
            "\t Mixed_6d.branch7x7dbl_5.bn.bias\n",
            "\t Mixed_6d.branch_pool.conv.weight\n",
            "\t Mixed_6d.branch_pool.bn.weight\n",
            "\t Mixed_6d.branch_pool.bn.bias\n",
            "\t Mixed_6e.branch1x1.conv.weight\n",
            "\t Mixed_6e.branch1x1.bn.weight\n",
            "\t Mixed_6e.branch1x1.bn.bias\n",
            "\t Mixed_6e.branch7x7_1.conv.weight\n",
            "\t Mixed_6e.branch7x7_1.bn.weight\n",
            "\t Mixed_6e.branch7x7_1.bn.bias\n",
            "\t Mixed_6e.branch7x7_2.conv.weight\n",
            "\t Mixed_6e.branch7x7_2.bn.weight\n",
            "\t Mixed_6e.branch7x7_2.bn.bias\n",
            "\t Mixed_6e.branch7x7_3.conv.weight\n",
            "\t Mixed_6e.branch7x7_3.bn.weight\n",
            "\t Mixed_6e.branch7x7_3.bn.bias\n",
            "\t Mixed_6e.branch7x7dbl_1.conv.weight\n",
            "\t Mixed_6e.branch7x7dbl_1.bn.weight\n",
            "\t Mixed_6e.branch7x7dbl_1.bn.bias\n",
            "\t Mixed_6e.branch7x7dbl_2.conv.weight\n",
            "\t Mixed_6e.branch7x7dbl_2.bn.weight\n",
            "\t Mixed_6e.branch7x7dbl_2.bn.bias\n",
            "\t Mixed_6e.branch7x7dbl_3.conv.weight\n",
            "\t Mixed_6e.branch7x7dbl_3.bn.weight\n",
            "\t Mixed_6e.branch7x7dbl_3.bn.bias\n",
            "\t Mixed_6e.branch7x7dbl_4.conv.weight\n",
            "\t Mixed_6e.branch7x7dbl_4.bn.weight\n",
            "\t Mixed_6e.branch7x7dbl_4.bn.bias\n",
            "\t Mixed_6e.branch7x7dbl_5.conv.weight\n",
            "\t Mixed_6e.branch7x7dbl_5.bn.weight\n",
            "\t Mixed_6e.branch7x7dbl_5.bn.bias\n",
            "\t Mixed_6e.branch_pool.conv.weight\n",
            "\t Mixed_6e.branch_pool.bn.weight\n",
            "\t Mixed_6e.branch_pool.bn.bias\n",
            "\t AuxLogits.conv0.conv.weight\n",
            "\t AuxLogits.conv0.bn.weight\n",
            "\t AuxLogits.conv0.bn.bias\n",
            "\t AuxLogits.conv1.conv.weight\n",
            "\t AuxLogits.conv1.bn.weight\n",
            "\t AuxLogits.conv1.bn.bias\n",
            "\t AuxLogits.fc.weight\n",
            "\t AuxLogits.fc.bias\n",
            "\t Mixed_7a.branch3x3_1.conv.weight\n",
            "\t Mixed_7a.branch3x3_1.bn.weight\n",
            "\t Mixed_7a.branch3x3_1.bn.bias\n",
            "\t Mixed_7a.branch3x3_2.conv.weight\n",
            "\t Mixed_7a.branch3x3_2.bn.weight\n",
            "\t Mixed_7a.branch3x3_2.bn.bias\n",
            "\t Mixed_7a.branch7x7x3_1.conv.weight\n",
            "\t Mixed_7a.branch7x7x3_1.bn.weight\n",
            "\t Mixed_7a.branch7x7x3_1.bn.bias\n",
            "\t Mixed_7a.branch7x7x3_2.conv.weight\n",
            "\t Mixed_7a.branch7x7x3_2.bn.weight\n",
            "\t Mixed_7a.branch7x7x3_2.bn.bias\n",
            "\t Mixed_7a.branch7x7x3_3.conv.weight\n",
            "\t Mixed_7a.branch7x7x3_3.bn.weight\n",
            "\t Mixed_7a.branch7x7x3_3.bn.bias\n",
            "\t Mixed_7a.branch7x7x3_4.conv.weight\n",
            "\t Mixed_7a.branch7x7x3_4.bn.weight\n",
            "\t Mixed_7a.branch7x7x3_4.bn.bias\n",
            "\t Mixed_7b.branch1x1.conv.weight\n",
            "\t Mixed_7b.branch1x1.bn.weight\n",
            "\t Mixed_7b.branch1x1.bn.bias\n",
            "\t Mixed_7b.branch3x3_1.conv.weight\n",
            "\t Mixed_7b.branch3x3_1.bn.weight\n",
            "\t Mixed_7b.branch3x3_1.bn.bias\n",
            "\t Mixed_7b.branch3x3_2a.conv.weight\n",
            "\t Mixed_7b.branch3x3_2a.bn.weight\n",
            "\t Mixed_7b.branch3x3_2a.bn.bias\n",
            "\t Mixed_7b.branch3x3_2b.conv.weight\n",
            "\t Mixed_7b.branch3x3_2b.bn.weight\n",
            "\t Mixed_7b.branch3x3_2b.bn.bias\n",
            "\t Mixed_7b.branch3x3dbl_1.conv.weight\n",
            "\t Mixed_7b.branch3x3dbl_1.bn.weight\n",
            "\t Mixed_7b.branch3x3dbl_1.bn.bias\n",
            "\t Mixed_7b.branch3x3dbl_2.conv.weight\n",
            "\t Mixed_7b.branch3x3dbl_2.bn.weight\n",
            "\t Mixed_7b.branch3x3dbl_2.bn.bias\n",
            "\t Mixed_7b.branch3x3dbl_3a.conv.weight\n",
            "\t Mixed_7b.branch3x3dbl_3a.bn.weight\n",
            "\t Mixed_7b.branch3x3dbl_3a.bn.bias\n",
            "\t Mixed_7b.branch3x3dbl_3b.conv.weight\n",
            "\t Mixed_7b.branch3x3dbl_3b.bn.weight\n",
            "\t Mixed_7b.branch3x3dbl_3b.bn.bias\n",
            "\t Mixed_7b.branch_pool.conv.weight\n",
            "\t Mixed_7b.branch_pool.bn.weight\n",
            "\t Mixed_7b.branch_pool.bn.bias\n",
            "\t Mixed_7c.branch1x1.conv.weight\n",
            "\t Mixed_7c.branch1x1.bn.weight\n",
            "\t Mixed_7c.branch1x1.bn.bias\n",
            "\t Mixed_7c.branch3x3_1.conv.weight\n",
            "\t Mixed_7c.branch3x3_1.bn.weight\n",
            "\t Mixed_7c.branch3x3_1.bn.bias\n",
            "\t Mixed_7c.branch3x3_2a.conv.weight\n",
            "\t Mixed_7c.branch3x3_2a.bn.weight\n",
            "\t Mixed_7c.branch3x3_2a.bn.bias\n",
            "\t Mixed_7c.branch3x3_2b.conv.weight\n",
            "\t Mixed_7c.branch3x3_2b.bn.weight\n",
            "\t Mixed_7c.branch3x3_2b.bn.bias\n",
            "\t Mixed_7c.branch3x3dbl_1.conv.weight\n",
            "\t Mixed_7c.branch3x3dbl_1.bn.weight\n",
            "\t Mixed_7c.branch3x3dbl_1.bn.bias\n",
            "\t Mixed_7c.branch3x3dbl_2.conv.weight\n",
            "\t Mixed_7c.branch3x3dbl_2.bn.weight\n",
            "\t Mixed_7c.branch3x3dbl_2.bn.bias\n",
            "\t Mixed_7c.branch3x3dbl_3a.conv.weight\n",
            "\t Mixed_7c.branch3x3dbl_3a.bn.weight\n",
            "\t Mixed_7c.branch3x3dbl_3a.bn.bias\n",
            "\t Mixed_7c.branch3x3dbl_3b.conv.weight\n",
            "\t Mixed_7c.branch3x3dbl_3b.bn.weight\n",
            "\t Mixed_7c.branch3x3dbl_3b.bn.bias\n",
            "\t Mixed_7c.branch_pool.conv.weight\n",
            "\t Mixed_7c.branch_pool.bn.weight\n",
            "\t Mixed_7c.branch_pool.bn.bias\n",
            "\t fc.weight\n",
            "\t fc.bias\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXg5BAG1oo-f",
        "outputId": "d85e5e2e-c476-4c8a-a0d3-37e47d26b70b"
      },
      "source": [
        "# Setup the loss fxn\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Train and evaluate\n",
        "model_ft, hist = train_model(model_ft, dataloaders, criterion, optimizer_ft, num_epochs=num_epochs, is_inception=(model_name==\"inception\"))"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/9\n",
            "----------\n",
            "train Loss: 0.3744 Acc: 0.9127\n",
            "val Loss: 0.2625 Acc: 0.9020\n",
            "\n",
            "Epoch 1/9\n",
            "----------\n",
            "train Loss: 0.2527 Acc: 0.9314\n",
            "val Loss: 0.2268 Acc: 0.9020\n",
            "\n",
            "Epoch 2/9\n",
            "----------\n",
            "train Loss: 0.2135 Acc: 0.9314\n",
            "val Loss: 0.2128 Acc: 0.9020\n",
            "\n",
            "Epoch 3/9\n",
            "----------\n",
            "train Loss: 0.1955 Acc: 0.9363\n",
            "val Loss: 0.1987 Acc: 0.9020\n",
            "\n",
            "Epoch 4/9\n",
            "----------\n",
            "train Loss: 0.1756 Acc: 0.9396\n",
            "val Loss: 0.2014 Acc: 0.9069\n",
            "\n",
            "Epoch 5/9\n",
            "----------\n",
            "train Loss: 0.1468 Acc: 0.9502\n",
            "val Loss: 0.2188 Acc: 0.8922\n",
            "\n",
            "Epoch 6/9\n",
            "----------\n",
            "train Loss: 0.1330 Acc: 0.9551\n",
            "val Loss: 0.2450 Acc: 0.9020\n",
            "\n",
            "Epoch 7/9\n",
            "----------\n",
            "train Loss: 0.1283 Acc: 0.9592\n",
            "val Loss: 0.2379 Acc: 0.8995\n",
            "\n",
            "Epoch 8/9\n",
            "----------\n",
            "train Loss: 0.1093 Acc: 0.9649\n",
            "val Loss: 0.2168 Acc: 0.8971\n",
            "\n",
            "Epoch 9/9\n",
            "----------\n",
            "train Loss: 0.0890 Acc: 0.9706\n",
            "val Loss: 0.2453 Acc: 0.9020\n",
            "\n",
            "Training complete in 8m 48s\n",
            "Best val Acc: 0.906863\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgYraiAjiys8"
      },
      "source": [
        "torch.save(model_ft,'/content/drive/MyDrive/saved_models/'+model_name+'no_ben_disk.h5')"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpGRminVjRIY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "outputId": "909a3b0b-81b1-4758-ae9e-4612e594a29c"
      },
      "source": [
        "import seaborn as sns\n",
        "nb_classes = num_classes\n",
        "confusion_matrix = np.zeros((nb_classes, nb_classes))\n",
        "with torch.no_grad():\n",
        "    for i, (inputs, classes) in enumerate(dataloaders['test']):\n",
        "        inputs = inputs.to(device)\n",
        "        classes = classes.to(device)\n",
        "        outputs = model_ft(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        for t, p in zip(classes.view(-1), preds.view(-1)):\n",
        "                confusion_matrix[t.long(), p.long()] += 1\n",
        "\n",
        "plt.figure(figsize=(15,10))\n",
        "\n",
        "class_names = ['Normal', 'Glaucoma']\n",
        "df_cm = pd.DataFrame(confusion_matrix, index=class_names, columns=class_names).astype(int)\n",
        "heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
        "\n",
        "heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right',fontsize=15)\n",
        "heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right',fontsize=15)\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 69.0, 'Predicted label')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x720 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Emzn5VAnJKU"
      },
      "source": [
        ""
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EyL4HDhTKDa"
      },
      "source": [
        ""
      ],
      "execution_count": 104,
      "outputs": []
    }
  ]
}