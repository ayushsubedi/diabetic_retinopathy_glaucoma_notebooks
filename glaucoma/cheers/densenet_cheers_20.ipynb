{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "densenet_cheers.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqHnaptr-kuA",
        "outputId": "30a1b9bf-30b1-4bed-97d3-f8165378fb2c"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri May 28 09:03:42 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   46C    P0    61W / 149W |   5198MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7-9XFsaZnKQ"
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oGJ2hstm39V"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from imutils import contours\n",
        "from skimage import measure\n",
        "import imutils\n",
        "import os\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import copy\n",
        "import time\n",
        "\n",
        "import torch\n",
        "from torchvision import datasets, models, transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader, Dataset, TensorDataset, Subset, WeightedRandomSampler\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import pickle\n",
        "from collections import OrderedDict"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u899MaWr-ZF0"
      },
      "source": [
        "# Top level data directory. Here we assume the format of the directory conforms\n",
        "#   to the ImageFolder structure\n",
        "data_dir = '/content/drive/MyDrive/CHEERS_Glaucoma_DataSet'\n",
        "\n",
        "# Models to choose from [resnet, alexnet, vgg, squeezenet, densenet, inception]\n",
        "model_name = \"densenet\"\n",
        "# inception\n",
        "input_size = 224\n",
        "\n",
        "# Number of classes in the dataset\n",
        "num_classes = 2\n",
        "\n",
        "# Batch size for training (change depending on how much memory you have)\n",
        "batch_size = 32\n",
        "\n",
        "# Number of epochs to train for\n",
        "num_epochs = 20\n",
        "\n",
        "# Flag for feature extracting. When False, we finetune the whole model,\n",
        "#   when True we only update the reshaped layer params\n",
        "feature_extract = False\n",
        "\n",
        "num_workers = 2\n",
        "\n",
        "train_size = 0.60\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYnO7mxJZywE"
      },
      "source": [
        "\n",
        "class ben_color(object):\n",
        "    def __call__(self, img, sigmaX=10):\n",
        "        \"\"\"\n",
        "        :param img: PIL): Image \n",
        "\n",
        "        :return: Normalized image\n",
        "        \"\"\"\n",
        "\n",
        "        img = np.asarray(img)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        img = self.crop_image_from_gray(img)\n",
        "        img = cv2.resize(img, (input_size, input_size))\n",
        "        img = cv2.addWeighted (img, 4, cv2.GaussianBlur(img, (0,0), sigmaX), -4, 128)\n",
        "        return Image.fromarray(img)\n",
        "\n",
        "    def crop_image_from_gray(self, img, tol=7):\n",
        "        if img.ndim ==2:\n",
        "            mask = img>tol\n",
        "            return img[np.ix_(mask.any(1),mask.any(0))]\n",
        "        elif img.ndim==3:\n",
        "            gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "            mask = gray_img>tol\n",
        "            \n",
        "            check_shape = img[:,:,0][np.ix_(mask.any(1),mask.any(0))].shape[0]\n",
        "            if (check_shape == 0):\n",
        "                return img \n",
        "            else:\n",
        "                img1=img[:,:,0][np.ix_(mask.any(1),mask.any(0))]\n",
        "                img2=img[:,:,1][np.ix_(mask.any(1),mask.any(0))]\n",
        "                img3=img[:,:,2][np.ix_(mask.any(1),mask.any(0))]\n",
        "                img = np.stack([img1,img2,img3],axis=-1)\n",
        "            return img\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__+'()'"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jj74frLDrZd"
      },
      "source": [
        "# Todos: shuffle in validation set\n",
        "# add more augmentations  \n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "        ben_color(),\n",
        "        transforms.RandomRotation(degrees=(0, 360)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.Resize((input_size, input_size)),\n",
        "        transforms.ToTensor(),\n",
        "        # transforms.Normalize((0.5,), (0.5,))])\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "\n",
        "\n",
        "valid_transform = transforms.Compose([\n",
        "        ben_color(),\n",
        "        transforms.Resize((input_size, input_size)),\n",
        "        transforms.ToTensor(),\n",
        "        # transforms.Normalize((0.5,), (0.5,))])\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "\n",
        "\n",
        "class DR(Dataset):\n",
        "    def __init__(self, dataset, transform=None):\n",
        "        self.dataset = dataset\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        if self.transform:\n",
        "            x = self.transform(dataset[index][0])\n",
        "        else:\n",
        "            x = dataset[index][0]\n",
        "        y = dataset[index][1]\n",
        "        return x, y\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(dataset)\n",
        "    \n",
        "\n",
        "dataset = ImageFolder(data_dir)\n",
        "\n",
        "traindataset = DR(dataset, train_transform)\n",
        "valdataset = DR(dataset, valid_transform)\n",
        "testdataset = DR(dataset, valid_transform)\n",
        "\n",
        "# Create the index splits for training, validation and test\n",
        "\n",
        "num_train = len(dataset)\n",
        "indices = list(range(num_train))\n",
        "split = int(np.floor(train_size * num_train))\n",
        "split2 = int(np.floor((train_size+(1-train_size)/2) * num_train))\n",
        "np.random.shuffle(indices)\n",
        "train_idx, valid_idx, test_idx = indices[:split], indices[split:split2], indices[split2:]\n",
        "\n",
        "traindata = Subset(traindataset, indices=train_idx)\n",
        "valdata = Subset(valdataset, indices=valid_idx)\n",
        "testdata = Subset(testdataset, indices=test_idx)\n",
        "\n",
        "# class_weights = []\n",
        "# for root, subdir, files in os.walk(data_dir):\n",
        "#   if len(files)>0:\n",
        "#     class_weights.append(1/len(files))\n",
        "\n",
        "# sample_weights = [0] * len(traindata)\n",
        "\n",
        "# for idx, (data, label) in enumerate(traindata):\n",
        "#   class_weight = class_weights[label]\n",
        "#   sample_weights[idx] = class_weight\n",
        "\n",
        "\n",
        "# with open('/content/drive/MyDrive/cheers.pkl', 'wb') as f:\n",
        "#   pickle.dump(sample_weights, f)\n",
        "\n",
        "with open('/content/drive/MyDrive/cheers.pkl', 'rb') as f:\n",
        "  sample_weights = pickle.load(f)\n",
        "\n",
        "sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)\n",
        "\n",
        "trainLoader = torch.utils.data.DataLoader(traindata, sampler=sampler, batch_size=batch_size, \n",
        "                                          num_workers=num_workers, drop_last=True)\n",
        "valLoader = torch.utils.data.DataLoader(valdata, batch_size=batch_size, \n",
        "                                          num_workers=num_workers, drop_last=True)\n",
        "testLoader = torch.utils.data.DataLoader(testdata, batch_size=batch_size,\n",
        "                                          num_workers=num_workers, drop_last=True)\n",
        "dataloaders = {'train': trainLoader, 'val': valLoader, 'test': testLoader}"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyThMaR4nbLF"
      },
      "source": [
        "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False):\n",
        "    since = time.time()\n",
        "\n",
        "    val_acc_history = []\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    # Get model outputs and calculate loss\n",
        "                    # Special case for inception because in training it has an auxiliary output. In train\n",
        "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
        "                    #   but in testing we only consider the final output.\n",
        "                    if is_inception and phase == 'train':\n",
        "                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
        "                        outputs, aux_outputs = model(inputs)\n",
        "                        loss1 = criterion(outputs, labels)\n",
        "                        loss2 = criterion(aux_outputs, labels)\n",
        "                        loss = loss1 + 0.4*loss2\n",
        "                    else:\n",
        "                        outputs = model(inputs)\n",
        "                        loss = criterion(outputs, labels)\n",
        "\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
        "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            if phase == 'val':\n",
        "                val_acc_history.append(epoch_acc)\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, val_acc_history"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75VdlQ8ln1a9"
      },
      "source": [
        "def set_parameter_requires_grad(model, feature_extracting):\n",
        "    if feature_extracting:\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4O8Uqptn8Sb",
        "outputId": "cfefb23b-1c02-49a7-ce04-cab750004b22"
      },
      "source": [
        "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
        "    # Initialize these variables which will be set in this if statement. Each of these\n",
        "    #   variables is model specific.\n",
        "    model_ft = None\n",
        "    input_size = 0\n",
        "\n",
        "    if model_name == \"resnet\":\n",
        "        \"\"\" Resnet18\n",
        "        \"\"\"\n",
        "        model_ft = models.resnet18(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.fc.in_features\n",
        "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"alexnet\":\n",
        "        \"\"\" Alexnet\n",
        "        \"\"\"\n",
        "        model_ft = models.alexnet(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.classifier[6].in_features\n",
        "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"vgg\":\n",
        "        \"\"\" VGG11_bn\n",
        "        \"\"\"\n",
        "        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.classifier[6].in_features\n",
        "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"squeezenet\":\n",
        "        \"\"\" Squeezenet\n",
        "        \"\"\"\n",
        "        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
        "        model_ft.num_classes = num_classes\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"densenet\":\n",
        "        \"\"\" Densenet\n",
        "        \"\"\"\n",
        "        model_ft = models.densenet121(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.classifier.in_features\n",
        "        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n",
        "        input_size = 224\n",
        "        classifier_dict = OrderedDict([\n",
        "            ('fc1', nn.Linear(1024, 512)),\n",
        "            ('relu1', nn.ReLU()),\n",
        "            ('dropout1', nn.Dropout(p=0.2)),\n",
        "            ('fc2', nn.Linear(512, 128)),\n",
        "            ('relu2', nn.ReLU()),\n",
        "            ('dropout2', nn.Dropout(p=0.2)),\n",
        "            ('fc3', nn.Linear(128, num_classes)),\n",
        "            ('output', nn.LogSoftmax(dim=1)),\n",
        "            ])\n",
        "            \n",
        "        # # creating the classifier for our usage using the ordered dictionary\n",
        "        classifier = nn.Sequential(classifier_dict)\n",
        "\n",
        "        # # replacing the pretrained model classifier with our classifier\n",
        "        model_ft.classifier = classifier\n",
        "\n",
        "    elif model_name == \"inception\":\n",
        "        \"\"\" Inception v3\n",
        "        Be careful, expects (299,299) sized images and has auxiliary output\n",
        "        \"\"\"\n",
        "        model_ft = models.inception_v3(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        # Handle the auxilary net\n",
        "        num_ftrs = model_ft.AuxLogits.fc.in_features\n",
        "        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n",
        "        # Handle the primary net\n",
        "        num_ftrs = model_ft.fc.in_features\n",
        "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
        "        input_size = 299\n",
        "\n",
        "    else:\n",
        "        print(\"Invalid model name, exiting...\")\n",
        "        exit()\n",
        "\n",
        "    return model_ft, input_size\n",
        "\n",
        "# Initialize the model for this run\n",
        "model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n",
        "\n",
        "# Print the model we just instantiated\n",
        "print(model_ft)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DenseNet(\n",
            "  (features): Sequential(\n",
            "    (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "    (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu0): ReLU(inplace=True)\n",
            "    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (denseblock1): _DenseBlock(\n",
            "      (denselayer1): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer2): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer3): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer4): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer5): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer6): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (transition1): _Transition(\n",
            "      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "    )\n",
            "    (denseblock2): _DenseBlock(\n",
            "      (denselayer1): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer2): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer3): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer4): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer5): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer6): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer7): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer8): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer9): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer10): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer11): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer12): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (transition2): _Transition(\n",
            "      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "    )\n",
            "    (denseblock3): _DenseBlock(\n",
            "      (denselayer1): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer2): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer3): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer4): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer5): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer6): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer7): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer8): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer9): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer10): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer11): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer12): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer13): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer14): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer15): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer16): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer17): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer18): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer19): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer20): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer21): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer22): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer23): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer24): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (transition3): _Transition(\n",
            "      (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "    )\n",
            "    (denseblock4): _DenseBlock(\n",
            "      (denselayer1): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer2): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer3): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer4): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer5): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer6): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer7): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer8): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer9): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer10): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer11): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer12): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer13): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer14): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer15): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer16): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (fc1): Linear(in_features=1024, out_features=512, bias=True)\n",
            "    (relu1): ReLU()\n",
            "    (dropout1): Dropout(p=0.2, inplace=False)\n",
            "    (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
            "    (relu2): ReLU()\n",
            "    (dropout2): Dropout(p=0.2, inplace=False)\n",
            "    (fc3): Linear(in_features=128, out_features=2, bias=True)\n",
            "    (output): LogSoftmax(dim=1)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6151ULNdzuq",
        "outputId": "6cb37f76-ec5e-47ee-e233-8691d46598e3"
      },
      "source": [
        "# Send the model to GPU\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "# Gather the parameters to be optimized/updated in this run. If we are\n",
        "#  finetuning we will be updating all parameters. However, if we are\n",
        "#  doing feature extract method, we will only update the parameters\n",
        "#  that we have just initialized, i.e. the parameters with requires_grad\n",
        "#  is True.\n",
        "params_to_update = model_ft.parameters()\n",
        "print(\"Params to learn:\")\n",
        "if feature_extract:\n",
        "    params_to_update = []\n",
        "    for name,param in model_ft.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            params_to_update.append(param)\n",
        "            print(\"\\t\",name)\n",
        "else:\n",
        "    for name,param in model_ft.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            print(\"\\t\",name)\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Params to learn:\n",
            "\t features.conv0.weight\n",
            "\t features.norm0.weight\n",
            "\t features.norm0.bias\n",
            "\t features.denseblock1.denselayer1.norm1.weight\n",
            "\t features.denseblock1.denselayer1.norm1.bias\n",
            "\t features.denseblock1.denselayer1.conv1.weight\n",
            "\t features.denseblock1.denselayer1.norm2.weight\n",
            "\t features.denseblock1.denselayer1.norm2.bias\n",
            "\t features.denseblock1.denselayer1.conv2.weight\n",
            "\t features.denseblock1.denselayer2.norm1.weight\n",
            "\t features.denseblock1.denselayer2.norm1.bias\n",
            "\t features.denseblock1.denselayer2.conv1.weight\n",
            "\t features.denseblock1.denselayer2.norm2.weight\n",
            "\t features.denseblock1.denselayer2.norm2.bias\n",
            "\t features.denseblock1.denselayer2.conv2.weight\n",
            "\t features.denseblock1.denselayer3.norm1.weight\n",
            "\t features.denseblock1.denselayer3.norm1.bias\n",
            "\t features.denseblock1.denselayer3.conv1.weight\n",
            "\t features.denseblock1.denselayer3.norm2.weight\n",
            "\t features.denseblock1.denselayer3.norm2.bias\n",
            "\t features.denseblock1.denselayer3.conv2.weight\n",
            "\t features.denseblock1.denselayer4.norm1.weight\n",
            "\t features.denseblock1.denselayer4.norm1.bias\n",
            "\t features.denseblock1.denselayer4.conv1.weight\n",
            "\t features.denseblock1.denselayer4.norm2.weight\n",
            "\t features.denseblock1.denselayer4.norm2.bias\n",
            "\t features.denseblock1.denselayer4.conv2.weight\n",
            "\t features.denseblock1.denselayer5.norm1.weight\n",
            "\t features.denseblock1.denselayer5.norm1.bias\n",
            "\t features.denseblock1.denselayer5.conv1.weight\n",
            "\t features.denseblock1.denselayer5.norm2.weight\n",
            "\t features.denseblock1.denselayer5.norm2.bias\n",
            "\t features.denseblock1.denselayer5.conv2.weight\n",
            "\t features.denseblock1.denselayer6.norm1.weight\n",
            "\t features.denseblock1.denselayer6.norm1.bias\n",
            "\t features.denseblock1.denselayer6.conv1.weight\n",
            "\t features.denseblock1.denselayer6.norm2.weight\n",
            "\t features.denseblock1.denselayer6.norm2.bias\n",
            "\t features.denseblock1.denselayer6.conv2.weight\n",
            "\t features.transition1.norm.weight\n",
            "\t features.transition1.norm.bias\n",
            "\t features.transition1.conv.weight\n",
            "\t features.denseblock2.denselayer1.norm1.weight\n",
            "\t features.denseblock2.denselayer1.norm1.bias\n",
            "\t features.denseblock2.denselayer1.conv1.weight\n",
            "\t features.denseblock2.denselayer1.norm2.weight\n",
            "\t features.denseblock2.denselayer1.norm2.bias\n",
            "\t features.denseblock2.denselayer1.conv2.weight\n",
            "\t features.denseblock2.denselayer2.norm1.weight\n",
            "\t features.denseblock2.denselayer2.norm1.bias\n",
            "\t features.denseblock2.denselayer2.conv1.weight\n",
            "\t features.denseblock2.denselayer2.norm2.weight\n",
            "\t features.denseblock2.denselayer2.norm2.bias\n",
            "\t features.denseblock2.denselayer2.conv2.weight\n",
            "\t features.denseblock2.denselayer3.norm1.weight\n",
            "\t features.denseblock2.denselayer3.norm1.bias\n",
            "\t features.denseblock2.denselayer3.conv1.weight\n",
            "\t features.denseblock2.denselayer3.norm2.weight\n",
            "\t features.denseblock2.denselayer3.norm2.bias\n",
            "\t features.denseblock2.denselayer3.conv2.weight\n",
            "\t features.denseblock2.denselayer4.norm1.weight\n",
            "\t features.denseblock2.denselayer4.norm1.bias\n",
            "\t features.denseblock2.denselayer4.conv1.weight\n",
            "\t features.denseblock2.denselayer4.norm2.weight\n",
            "\t features.denseblock2.denselayer4.norm2.bias\n",
            "\t features.denseblock2.denselayer4.conv2.weight\n",
            "\t features.denseblock2.denselayer5.norm1.weight\n",
            "\t features.denseblock2.denselayer5.norm1.bias\n",
            "\t features.denseblock2.denselayer5.conv1.weight\n",
            "\t features.denseblock2.denselayer5.norm2.weight\n",
            "\t features.denseblock2.denselayer5.norm2.bias\n",
            "\t features.denseblock2.denselayer5.conv2.weight\n",
            "\t features.denseblock2.denselayer6.norm1.weight\n",
            "\t features.denseblock2.denselayer6.norm1.bias\n",
            "\t features.denseblock2.denselayer6.conv1.weight\n",
            "\t features.denseblock2.denselayer6.norm2.weight\n",
            "\t features.denseblock2.denselayer6.norm2.bias\n",
            "\t features.denseblock2.denselayer6.conv2.weight\n",
            "\t features.denseblock2.denselayer7.norm1.weight\n",
            "\t features.denseblock2.denselayer7.norm1.bias\n",
            "\t features.denseblock2.denselayer7.conv1.weight\n",
            "\t features.denseblock2.denselayer7.norm2.weight\n",
            "\t features.denseblock2.denselayer7.norm2.bias\n",
            "\t features.denseblock2.denselayer7.conv2.weight\n",
            "\t features.denseblock2.denselayer8.norm1.weight\n",
            "\t features.denseblock2.denselayer8.norm1.bias\n",
            "\t features.denseblock2.denselayer8.conv1.weight\n",
            "\t features.denseblock2.denselayer8.norm2.weight\n",
            "\t features.denseblock2.denselayer8.norm2.bias\n",
            "\t features.denseblock2.denselayer8.conv2.weight\n",
            "\t features.denseblock2.denselayer9.norm1.weight\n",
            "\t features.denseblock2.denselayer9.norm1.bias\n",
            "\t features.denseblock2.denselayer9.conv1.weight\n",
            "\t features.denseblock2.denselayer9.norm2.weight\n",
            "\t features.denseblock2.denselayer9.norm2.bias\n",
            "\t features.denseblock2.denselayer9.conv2.weight\n",
            "\t features.denseblock2.denselayer10.norm1.weight\n",
            "\t features.denseblock2.denselayer10.norm1.bias\n",
            "\t features.denseblock2.denselayer10.conv1.weight\n",
            "\t features.denseblock2.denselayer10.norm2.weight\n",
            "\t features.denseblock2.denselayer10.norm2.bias\n",
            "\t features.denseblock2.denselayer10.conv2.weight\n",
            "\t features.denseblock2.denselayer11.norm1.weight\n",
            "\t features.denseblock2.denselayer11.norm1.bias\n",
            "\t features.denseblock2.denselayer11.conv1.weight\n",
            "\t features.denseblock2.denselayer11.norm2.weight\n",
            "\t features.denseblock2.denselayer11.norm2.bias\n",
            "\t features.denseblock2.denselayer11.conv2.weight\n",
            "\t features.denseblock2.denselayer12.norm1.weight\n",
            "\t features.denseblock2.denselayer12.norm1.bias\n",
            "\t features.denseblock2.denselayer12.conv1.weight\n",
            "\t features.denseblock2.denselayer12.norm2.weight\n",
            "\t features.denseblock2.denselayer12.norm2.bias\n",
            "\t features.denseblock2.denselayer12.conv2.weight\n",
            "\t features.transition2.norm.weight\n",
            "\t features.transition2.norm.bias\n",
            "\t features.transition2.conv.weight\n",
            "\t features.denseblock3.denselayer1.norm1.weight\n",
            "\t features.denseblock3.denselayer1.norm1.bias\n",
            "\t features.denseblock3.denselayer1.conv1.weight\n",
            "\t features.denseblock3.denselayer1.norm2.weight\n",
            "\t features.denseblock3.denselayer1.norm2.bias\n",
            "\t features.denseblock3.denselayer1.conv2.weight\n",
            "\t features.denseblock3.denselayer2.norm1.weight\n",
            "\t features.denseblock3.denselayer2.norm1.bias\n",
            "\t features.denseblock3.denselayer2.conv1.weight\n",
            "\t features.denseblock3.denselayer2.norm2.weight\n",
            "\t features.denseblock3.denselayer2.norm2.bias\n",
            "\t features.denseblock3.denselayer2.conv2.weight\n",
            "\t features.denseblock3.denselayer3.norm1.weight\n",
            "\t features.denseblock3.denselayer3.norm1.bias\n",
            "\t features.denseblock3.denselayer3.conv1.weight\n",
            "\t features.denseblock3.denselayer3.norm2.weight\n",
            "\t features.denseblock3.denselayer3.norm2.bias\n",
            "\t features.denseblock3.denselayer3.conv2.weight\n",
            "\t features.denseblock3.denselayer4.norm1.weight\n",
            "\t features.denseblock3.denselayer4.norm1.bias\n",
            "\t features.denseblock3.denselayer4.conv1.weight\n",
            "\t features.denseblock3.denselayer4.norm2.weight\n",
            "\t features.denseblock3.denselayer4.norm2.bias\n",
            "\t features.denseblock3.denselayer4.conv2.weight\n",
            "\t features.denseblock3.denselayer5.norm1.weight\n",
            "\t features.denseblock3.denselayer5.norm1.bias\n",
            "\t features.denseblock3.denselayer5.conv1.weight\n",
            "\t features.denseblock3.denselayer5.norm2.weight\n",
            "\t features.denseblock3.denselayer5.norm2.bias\n",
            "\t features.denseblock3.denselayer5.conv2.weight\n",
            "\t features.denseblock3.denselayer6.norm1.weight\n",
            "\t features.denseblock3.denselayer6.norm1.bias\n",
            "\t features.denseblock3.denselayer6.conv1.weight\n",
            "\t features.denseblock3.denselayer6.norm2.weight\n",
            "\t features.denseblock3.denselayer6.norm2.bias\n",
            "\t features.denseblock3.denselayer6.conv2.weight\n",
            "\t features.denseblock3.denselayer7.norm1.weight\n",
            "\t features.denseblock3.denselayer7.norm1.bias\n",
            "\t features.denseblock3.denselayer7.conv1.weight\n",
            "\t features.denseblock3.denselayer7.norm2.weight\n",
            "\t features.denseblock3.denselayer7.norm2.bias\n",
            "\t features.denseblock3.denselayer7.conv2.weight\n",
            "\t features.denseblock3.denselayer8.norm1.weight\n",
            "\t features.denseblock3.denselayer8.norm1.bias\n",
            "\t features.denseblock3.denselayer8.conv1.weight\n",
            "\t features.denseblock3.denselayer8.norm2.weight\n",
            "\t features.denseblock3.denselayer8.norm2.bias\n",
            "\t features.denseblock3.denselayer8.conv2.weight\n",
            "\t features.denseblock3.denselayer9.norm1.weight\n",
            "\t features.denseblock3.denselayer9.norm1.bias\n",
            "\t features.denseblock3.denselayer9.conv1.weight\n",
            "\t features.denseblock3.denselayer9.norm2.weight\n",
            "\t features.denseblock3.denselayer9.norm2.bias\n",
            "\t features.denseblock3.denselayer9.conv2.weight\n",
            "\t features.denseblock3.denselayer10.norm1.weight\n",
            "\t features.denseblock3.denselayer10.norm1.bias\n",
            "\t features.denseblock3.denselayer10.conv1.weight\n",
            "\t features.denseblock3.denselayer10.norm2.weight\n",
            "\t features.denseblock3.denselayer10.norm2.bias\n",
            "\t features.denseblock3.denselayer10.conv2.weight\n",
            "\t features.denseblock3.denselayer11.norm1.weight\n",
            "\t features.denseblock3.denselayer11.norm1.bias\n",
            "\t features.denseblock3.denselayer11.conv1.weight\n",
            "\t features.denseblock3.denselayer11.norm2.weight\n",
            "\t features.denseblock3.denselayer11.norm2.bias\n",
            "\t features.denseblock3.denselayer11.conv2.weight\n",
            "\t features.denseblock3.denselayer12.norm1.weight\n",
            "\t features.denseblock3.denselayer12.norm1.bias\n",
            "\t features.denseblock3.denselayer12.conv1.weight\n",
            "\t features.denseblock3.denselayer12.norm2.weight\n",
            "\t features.denseblock3.denselayer12.norm2.bias\n",
            "\t features.denseblock3.denselayer12.conv2.weight\n",
            "\t features.denseblock3.denselayer13.norm1.weight\n",
            "\t features.denseblock3.denselayer13.norm1.bias\n",
            "\t features.denseblock3.denselayer13.conv1.weight\n",
            "\t features.denseblock3.denselayer13.norm2.weight\n",
            "\t features.denseblock3.denselayer13.norm2.bias\n",
            "\t features.denseblock3.denselayer13.conv2.weight\n",
            "\t features.denseblock3.denselayer14.norm1.weight\n",
            "\t features.denseblock3.denselayer14.norm1.bias\n",
            "\t features.denseblock3.denselayer14.conv1.weight\n",
            "\t features.denseblock3.denselayer14.norm2.weight\n",
            "\t features.denseblock3.denselayer14.norm2.bias\n",
            "\t features.denseblock3.denselayer14.conv2.weight\n",
            "\t features.denseblock3.denselayer15.norm1.weight\n",
            "\t features.denseblock3.denselayer15.norm1.bias\n",
            "\t features.denseblock3.denselayer15.conv1.weight\n",
            "\t features.denseblock3.denselayer15.norm2.weight\n",
            "\t features.denseblock3.denselayer15.norm2.bias\n",
            "\t features.denseblock3.denselayer15.conv2.weight\n",
            "\t features.denseblock3.denselayer16.norm1.weight\n",
            "\t features.denseblock3.denselayer16.norm1.bias\n",
            "\t features.denseblock3.denselayer16.conv1.weight\n",
            "\t features.denseblock3.denselayer16.norm2.weight\n",
            "\t features.denseblock3.denselayer16.norm2.bias\n",
            "\t features.denseblock3.denselayer16.conv2.weight\n",
            "\t features.denseblock3.denselayer17.norm1.weight\n",
            "\t features.denseblock3.denselayer17.norm1.bias\n",
            "\t features.denseblock3.denselayer17.conv1.weight\n",
            "\t features.denseblock3.denselayer17.norm2.weight\n",
            "\t features.denseblock3.denselayer17.norm2.bias\n",
            "\t features.denseblock3.denselayer17.conv2.weight\n",
            "\t features.denseblock3.denselayer18.norm1.weight\n",
            "\t features.denseblock3.denselayer18.norm1.bias\n",
            "\t features.denseblock3.denselayer18.conv1.weight\n",
            "\t features.denseblock3.denselayer18.norm2.weight\n",
            "\t features.denseblock3.denselayer18.norm2.bias\n",
            "\t features.denseblock3.denselayer18.conv2.weight\n",
            "\t features.denseblock3.denselayer19.norm1.weight\n",
            "\t features.denseblock3.denselayer19.norm1.bias\n",
            "\t features.denseblock3.denselayer19.conv1.weight\n",
            "\t features.denseblock3.denselayer19.norm2.weight\n",
            "\t features.denseblock3.denselayer19.norm2.bias\n",
            "\t features.denseblock3.denselayer19.conv2.weight\n",
            "\t features.denseblock3.denselayer20.norm1.weight\n",
            "\t features.denseblock3.denselayer20.norm1.bias\n",
            "\t features.denseblock3.denselayer20.conv1.weight\n",
            "\t features.denseblock3.denselayer20.norm2.weight\n",
            "\t features.denseblock3.denselayer20.norm2.bias\n",
            "\t features.denseblock3.denselayer20.conv2.weight\n",
            "\t features.denseblock3.denselayer21.norm1.weight\n",
            "\t features.denseblock3.denselayer21.norm1.bias\n",
            "\t features.denseblock3.denselayer21.conv1.weight\n",
            "\t features.denseblock3.denselayer21.norm2.weight\n",
            "\t features.denseblock3.denselayer21.norm2.bias\n",
            "\t features.denseblock3.denselayer21.conv2.weight\n",
            "\t features.denseblock3.denselayer22.norm1.weight\n",
            "\t features.denseblock3.denselayer22.norm1.bias\n",
            "\t features.denseblock3.denselayer22.conv1.weight\n",
            "\t features.denseblock3.denselayer22.norm2.weight\n",
            "\t features.denseblock3.denselayer22.norm2.bias\n",
            "\t features.denseblock3.denselayer22.conv2.weight\n",
            "\t features.denseblock3.denselayer23.norm1.weight\n",
            "\t features.denseblock3.denselayer23.norm1.bias\n",
            "\t features.denseblock3.denselayer23.conv1.weight\n",
            "\t features.denseblock3.denselayer23.norm2.weight\n",
            "\t features.denseblock3.denselayer23.norm2.bias\n",
            "\t features.denseblock3.denselayer23.conv2.weight\n",
            "\t features.denseblock3.denselayer24.norm1.weight\n",
            "\t features.denseblock3.denselayer24.norm1.bias\n",
            "\t features.denseblock3.denselayer24.conv1.weight\n",
            "\t features.denseblock3.denselayer24.norm2.weight\n",
            "\t features.denseblock3.denselayer24.norm2.bias\n",
            "\t features.denseblock3.denselayer24.conv2.weight\n",
            "\t features.transition3.norm.weight\n",
            "\t features.transition3.norm.bias\n",
            "\t features.transition3.conv.weight\n",
            "\t features.denseblock4.denselayer1.norm1.weight\n",
            "\t features.denseblock4.denselayer1.norm1.bias\n",
            "\t features.denseblock4.denselayer1.conv1.weight\n",
            "\t features.denseblock4.denselayer1.norm2.weight\n",
            "\t features.denseblock4.denselayer1.norm2.bias\n",
            "\t features.denseblock4.denselayer1.conv2.weight\n",
            "\t features.denseblock4.denselayer2.norm1.weight\n",
            "\t features.denseblock4.denselayer2.norm1.bias\n",
            "\t features.denseblock4.denselayer2.conv1.weight\n",
            "\t features.denseblock4.denselayer2.norm2.weight\n",
            "\t features.denseblock4.denselayer2.norm2.bias\n",
            "\t features.denseblock4.denselayer2.conv2.weight\n",
            "\t features.denseblock4.denselayer3.norm1.weight\n",
            "\t features.denseblock4.denselayer3.norm1.bias\n",
            "\t features.denseblock4.denselayer3.conv1.weight\n",
            "\t features.denseblock4.denselayer3.norm2.weight\n",
            "\t features.denseblock4.denselayer3.norm2.bias\n",
            "\t features.denseblock4.denselayer3.conv2.weight\n",
            "\t features.denseblock4.denselayer4.norm1.weight\n",
            "\t features.denseblock4.denselayer4.norm1.bias\n",
            "\t features.denseblock4.denselayer4.conv1.weight\n",
            "\t features.denseblock4.denselayer4.norm2.weight\n",
            "\t features.denseblock4.denselayer4.norm2.bias\n",
            "\t features.denseblock4.denselayer4.conv2.weight\n",
            "\t features.denseblock4.denselayer5.norm1.weight\n",
            "\t features.denseblock4.denselayer5.norm1.bias\n",
            "\t features.denseblock4.denselayer5.conv1.weight\n",
            "\t features.denseblock4.denselayer5.norm2.weight\n",
            "\t features.denseblock4.denselayer5.norm2.bias\n",
            "\t features.denseblock4.denselayer5.conv2.weight\n",
            "\t features.denseblock4.denselayer6.norm1.weight\n",
            "\t features.denseblock4.denselayer6.norm1.bias\n",
            "\t features.denseblock4.denselayer6.conv1.weight\n",
            "\t features.denseblock4.denselayer6.norm2.weight\n",
            "\t features.denseblock4.denselayer6.norm2.bias\n",
            "\t features.denseblock4.denselayer6.conv2.weight\n",
            "\t features.denseblock4.denselayer7.norm1.weight\n",
            "\t features.denseblock4.denselayer7.norm1.bias\n",
            "\t features.denseblock4.denselayer7.conv1.weight\n",
            "\t features.denseblock4.denselayer7.norm2.weight\n",
            "\t features.denseblock4.denselayer7.norm2.bias\n",
            "\t features.denseblock4.denselayer7.conv2.weight\n",
            "\t features.denseblock4.denselayer8.norm1.weight\n",
            "\t features.denseblock4.denselayer8.norm1.bias\n",
            "\t features.denseblock4.denselayer8.conv1.weight\n",
            "\t features.denseblock4.denselayer8.norm2.weight\n",
            "\t features.denseblock4.denselayer8.norm2.bias\n",
            "\t features.denseblock4.denselayer8.conv2.weight\n",
            "\t features.denseblock4.denselayer9.norm1.weight\n",
            "\t features.denseblock4.denselayer9.norm1.bias\n",
            "\t features.denseblock4.denselayer9.conv1.weight\n",
            "\t features.denseblock4.denselayer9.norm2.weight\n",
            "\t features.denseblock4.denselayer9.norm2.bias\n",
            "\t features.denseblock4.denselayer9.conv2.weight\n",
            "\t features.denseblock4.denselayer10.norm1.weight\n",
            "\t features.denseblock4.denselayer10.norm1.bias\n",
            "\t features.denseblock4.denselayer10.conv1.weight\n",
            "\t features.denseblock4.denselayer10.norm2.weight\n",
            "\t features.denseblock4.denselayer10.norm2.bias\n",
            "\t features.denseblock4.denselayer10.conv2.weight\n",
            "\t features.denseblock4.denselayer11.norm1.weight\n",
            "\t features.denseblock4.denselayer11.norm1.bias\n",
            "\t features.denseblock4.denselayer11.conv1.weight\n",
            "\t features.denseblock4.denselayer11.norm2.weight\n",
            "\t features.denseblock4.denselayer11.norm2.bias\n",
            "\t features.denseblock4.denselayer11.conv2.weight\n",
            "\t features.denseblock4.denselayer12.norm1.weight\n",
            "\t features.denseblock4.denselayer12.norm1.bias\n",
            "\t features.denseblock4.denselayer12.conv1.weight\n",
            "\t features.denseblock4.denselayer12.norm2.weight\n",
            "\t features.denseblock4.denselayer12.norm2.bias\n",
            "\t features.denseblock4.denselayer12.conv2.weight\n",
            "\t features.denseblock4.denselayer13.norm1.weight\n",
            "\t features.denseblock4.denselayer13.norm1.bias\n",
            "\t features.denseblock4.denselayer13.conv1.weight\n",
            "\t features.denseblock4.denselayer13.norm2.weight\n",
            "\t features.denseblock4.denselayer13.norm2.bias\n",
            "\t features.denseblock4.denselayer13.conv2.weight\n",
            "\t features.denseblock4.denselayer14.norm1.weight\n",
            "\t features.denseblock4.denselayer14.norm1.bias\n",
            "\t features.denseblock4.denselayer14.conv1.weight\n",
            "\t features.denseblock4.denselayer14.norm2.weight\n",
            "\t features.denseblock4.denselayer14.norm2.bias\n",
            "\t features.denseblock4.denselayer14.conv2.weight\n",
            "\t features.denseblock4.denselayer15.norm1.weight\n",
            "\t features.denseblock4.denselayer15.norm1.bias\n",
            "\t features.denseblock4.denselayer15.conv1.weight\n",
            "\t features.denseblock4.denselayer15.norm2.weight\n",
            "\t features.denseblock4.denselayer15.norm2.bias\n",
            "\t features.denseblock4.denselayer15.conv2.weight\n",
            "\t features.denseblock4.denselayer16.norm1.weight\n",
            "\t features.denseblock4.denselayer16.norm1.bias\n",
            "\t features.denseblock4.denselayer16.conv1.weight\n",
            "\t features.denseblock4.denselayer16.norm2.weight\n",
            "\t features.denseblock4.denselayer16.norm2.bias\n",
            "\t features.denseblock4.denselayer16.conv2.weight\n",
            "\t features.norm5.weight\n",
            "\t features.norm5.bias\n",
            "\t classifier.fc1.weight\n",
            "\t classifier.fc1.bias\n",
            "\t classifier.fc2.weight\n",
            "\t classifier.fc2.bias\n",
            "\t classifier.fc3.weight\n",
            "\t classifier.fc3.bias\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXg5BAG1oo-f",
        "outputId": "a0b49278-0340-4177-a4d6-d19b159c1ea2"
      },
      "source": [
        "# # Setup the loss fxn\n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# NLLLoss because our output is LogSoftmax\n",
        "criterion = nn.NLLLoss()\n",
        "\n",
        "# Adam optimizer with a learning rate\n",
        "optimizer_ft = optim.Adam(model_ft.classifier.parameters(), lr = 0.001)\n",
        "\n",
        "\n",
        "# Train and evaluate\n",
        "model_ft, hist = train_model(model_ft, dataloaders, criterion, optimizer_ft, num_epochs=num_epochs, is_inception=(model_name==\"inception\"))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/19\n",
            "----------\n",
            "train Loss: 0.4612 Acc: 0.6750\n",
            "val Loss: 0.3443 Acc: 0.6452\n",
            "\n",
            "Epoch 1/19\n",
            "----------\n",
            "train Loss: 0.4150 Acc: 0.7143\n",
            "val Loss: 0.2039 Acc: 0.6559\n",
            "\n",
            "Epoch 2/19\n",
            "----------\n",
            "train Loss: 0.2274 Acc: 0.8357\n",
            "val Loss: 0.1479 Acc: 0.6452\n",
            "\n",
            "Epoch 3/19\n",
            "----------\n",
            "train Loss: 0.1887 Acc: 0.8393\n",
            "val Loss: 0.0969 Acc: 0.6452\n",
            "\n",
            "Epoch 4/19\n",
            "----------\n",
            "train Loss: 0.2262 Acc: 0.8429\n",
            "val Loss: 0.1333 Acc: 0.6559\n",
            "\n",
            "Epoch 5/19\n",
            "----------\n",
            "train Loss: 0.1164 Acc: 0.8643\n",
            "val Loss: 0.0794 Acc: 0.6559\n",
            "\n",
            "Epoch 6/19\n",
            "----------\n",
            "train Loss: 0.1528 Acc: 0.8429\n",
            "val Loss: 0.1183 Acc: 0.6452\n",
            "\n",
            "Epoch 7/19\n",
            "----------\n",
            "train Loss: 0.1759 Acc: 0.8500\n",
            "val Loss: 0.1484 Acc: 0.6452\n",
            "\n",
            "Epoch 8/19\n",
            "----------\n",
            "train Loss: 0.1290 Acc: 0.8536\n",
            "val Loss: 0.0640 Acc: 0.6559\n",
            "\n",
            "Epoch 9/19\n",
            "----------\n",
            "train Loss: 0.1115 Acc: 0.8643\n",
            "val Loss: 0.0571 Acc: 0.6667\n",
            "\n",
            "Epoch 10/19\n",
            "----------\n",
            "train Loss: 0.1024 Acc: 0.8714\n",
            "val Loss: 0.0666 Acc: 0.6667\n",
            "\n",
            "Epoch 11/19\n",
            "----------\n",
            "train Loss: 0.1044 Acc: 0.8643\n",
            "val Loss: 0.1152 Acc: 0.6559\n",
            "\n",
            "Epoch 12/19\n",
            "----------\n",
            "train Loss: 0.1386 Acc: 0.8607\n",
            "val Loss: 0.1124 Acc: 0.6559\n",
            "\n",
            "Epoch 13/19\n",
            "----------\n",
            "train Loss: 0.0896 Acc: 0.8857\n",
            "val Loss: 0.0611 Acc: 0.6452\n",
            "\n",
            "Epoch 14/19\n",
            "----------\n",
            "train Loss: 0.0979 Acc: 0.8714\n",
            "val Loss: 0.1349 Acc: 0.6452\n",
            "\n",
            "Epoch 15/19\n",
            "----------\n",
            "train Loss: 0.0898 Acc: 0.8750\n",
            "val Loss: 0.0404 Acc: 0.6774\n",
            "\n",
            "Epoch 16/19\n",
            "----------\n",
            "train Loss: 0.1108 Acc: 0.8643\n",
            "val Loss: 0.0590 Acc: 0.6667\n",
            "\n",
            "Epoch 17/19\n",
            "----------\n",
            "train Loss: 0.0991 Acc: 0.8750\n",
            "val Loss: 0.0377 Acc: 0.6774\n",
            "\n",
            "Epoch 18/19\n",
            "----------\n",
            "train Loss: 0.1359 Acc: 0.8679\n",
            "val Loss: 0.1128 Acc: 0.6237\n",
            "\n",
            "Epoch 19/19\n",
            "----------\n",
            "train Loss: 0.1677 Acc: 0.8464\n",
            "val Loss: 0.2083 Acc: 0.5914\n",
            "\n",
            "Training complete in 30m 1s\n",
            "Best val Acc: 0.677419\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgYraiAjiys8"
      },
      "source": [
        "torch.save(model_ft,'/content/drive/MyDrive/saved_models/densenet_cheers_20.h5')"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpGRminVjRIY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660
        },
        "outputId": "eb74f2ae-ccf9-477c-940e-3a210065a542"
      },
      "source": [
        "import seaborn as sns\n",
        "nb_classes = num_classes\n",
        "confusion_matrix = np.zeros((nb_classes, nb_classes))\n",
        "with torch.no_grad():\n",
        "    for i, (inputs, classes) in enumerate(dataloaders['test']):\n",
        "        inputs = inputs.to(device)\n",
        "        classes = classes.to(device)\n",
        "        outputs = model_ft(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        print (preds)\n",
        "        for t, p in zip(classes.view(-1), preds.view(-1)):\n",
        "                confusion_matrix[t.long(), p.long()] += 1\n",
        "\n",
        "plt.figure(figsize=(15,10))\n",
        "\n",
        "class_names = ['Normal', 'Glaucoma']\n",
        "df_cm = pd.DataFrame(confusion_matrix, index=class_names, columns=class_names).astype(int)\n",
        "heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
        "\n",
        "heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right',fontsize=15)\n",
        "heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right',fontsize=15)\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0,\n",
            "        0, 1, 1, 1, 0, 1, 0, 0], device='cuda:0')\n",
            "tensor([1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 1, 0, 0, 1, 0, 1, 0], device='cuda:0')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 69.0, 'Predicted label')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x720 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EyL4HDhTKDa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        },
        "outputId": "457c7740-1f58-4978-ebbb-d59171112e62"
      },
      "source": [
        "confusion_matrix = np.zeros((nb_classes, nb_classes))\n",
        "with torch.no_grad():\n",
        "    for i, (inputs, classes) in enumerate(dataloaders['train']):\n",
        "        inputs = inputs.to(device)\n",
        "        classes = classes.to(device)\n",
        "        outputs = model_ft(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        for t, p in zip(classes.view(-1), preds.view(-1)):\n",
        "                confusion_matrix[t.long(), p.long()] += 1\n",
        "\n",
        "plt.figure(figsize=(15,10))\n",
        "\n",
        "class_names = ['Normal', 'Glaucoma']\n",
        "df_cm = pd.DataFrame(confusion_matrix, index=class_names, columns=class_names).astype(int)\n",
        "heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
        "\n",
        "heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right',fontsize=15)\n",
        "heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right',fontsize=15)\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 69.0, 'Predicted label')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x720 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pryRZOM_O64w"
      },
      "source": [
        ""
      ],
      "execution_count": 39,
      "outputs": []
    }
  ]
}