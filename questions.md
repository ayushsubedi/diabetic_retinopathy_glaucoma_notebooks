1. We have data from APTOS and IPACS merged together from https://www.kaggle.com/benjaminwarner/resized-2015-2019-blindness-detection-images Each image has been resized and cropped to have a maximum size of 1024px.
2. The data is still noisy. 
3. After balancing the datasets for each class to have the same number of images, we have a total of 2209 in for each class.
4. 20% of this is reserved for validation. Therefore, to train we have ~1765 for each class.
5. 




1. what is the accuracy that we can target? 
